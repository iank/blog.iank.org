<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Ian Kilgore's blog</title><link href="http://blog.iank.org/" rel="alternate"></link><link href="http://blog.iank.org/feeds/machine-learning.atom.xml" rel="self"></link><id>http://blog.iank.org/</id><updated>2015-07-11T21:58:00-04:00</updated><entry><title>Feature Generation and Selection for Single Character Recognition</title><link href="http://blog.iank.org/feature-generation-and-selection-for-single-character-recognition.html" rel="alternate"></link><updated>2015-07-11T21:58:00-04:00</updated><author><name>Ian Kilgore</name></author><id>tag:blog.iank.org,2015-07-11:feature-generation-and-selection-for-single-character-recognition.html</id><summary type="html">&lt;ul&gt;
&lt;li&gt;&lt;a href="#background"&gt;Background: Single-character recognition&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#data"&gt;Dataset&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#solns"&gt;Solutions&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#template"&gt;Template matching w/ LSPC (brute force benchmark)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#hu"&gt;Hu moments (feature benchmark)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#receptors"&gt;Receptors&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#fs"&gt;Feature selection&lt;/a&gt;:&lt;ul&gt;
&lt;li&gt;&lt;a href="#theory"&gt;Theoretical bound and PCA&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#entropy"&gt;Entropy (H(Y=1|X), H(X|Y=1))&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#redundancy"&gt;Redundancy (K-L divergence)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#hill"&gt;Greedy hill-climbing &amp;amp; pruning&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#results"&gt;Results&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#summary"&gt;Summary&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#refs"&gt;References/Notes&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a name="background"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Background: Single-character recognition&lt;/h3&gt;
&lt;p&gt;In my &lt;a href="/playing-capitals-with-opencv-and-python.html"&gt;&lt;em&gt;Capitals&lt;/em&gt;-playing project&lt;/a&gt; I used the &lt;a href="https://en.wikipedia.org/wiki/Tesseract_(software)"&gt;Tesseract&lt;/a&gt; OCR engine to read the letters in each tile after segmenting tiles with OpenCV.&lt;/p&gt;
&lt;p&gt;Although my segmentation is consistent, presenting Tesseract with a single character from a single font on a white background, I noticed some performance problems. For example, the letter 'W' is never recognized correctly, and occasionally other letters are misclassified. Whether this is due to my using Tesseract incorrectly (i.e. possibly this could improve with &lt;a href="https://code.google.com/p/tesseract-ocr/wiki/TrainingTesseract3"&gt;training&lt;/a&gt;), complications from using it in single character mode, or because Tesseract is &lt;a href="https://en.wikipedia.org/wiki/Waste"&gt;garbage&lt;/a&gt;, I'm not sure.&lt;/p&gt;
&lt;p&gt;Also, Tesseract is a powerful OCR engine, but I only need single-character recognition. Invoking Tesseract for each tile in a screenshot takes a significant portion of the total runtime of &lt;a href="https://github.com/iank/capitals-solver"&gt;capitals-solver&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I decided to write my own classifier for the relatively trivial problem of classifying consistently-rendered single character tiles. All of the code used is available on &lt;a href="https://github.com/iank/receptor-ocr"&gt;github/receptor-ocr&lt;/a&gt;. I have tried to note when I used different revisions of the same code in this article.&lt;/p&gt;
&lt;p&gt;&lt;a name="data"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Dataset&lt;/h3&gt;
&lt;p&gt;I generated training/test data by segmenting &lt;a href="https://github.com/iank/receptor-ocr/tree/master/training_data"&gt;several screenshots&lt;/a&gt; from &lt;a href="https://itunes.apple.com/us/app/capitals-free-word-battle/id968456900?mt=8"&gt;Capitals&lt;/a&gt; using &lt;a href="https://github.com/iank/receptor-ocr/blob/fe602f7fdac611c31f08d357131cf7d6ca0f7a17/gen_training_data.py"&gt;gen_training_data.py&lt;/a&gt; and labeled them manually using &lt;a href="https://github.com/iank/receptor-ocr/blob/9c94bc1f0f3644a97a17bc1871908b196e206c60/label_seg.py"&gt;label_seg.py&lt;/a&gt;. This &lt;a href="https://github.com/iank/receptor-ocr/tree/9c94bc1f0f3644a97a17bc1871908b196e206c60/training_data"&gt;training data is available here&lt;/a&gt;, and is the same dataset I use throughout this article. A scaled example image is below.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Example Q image" src="/images/receptors/E.png.cx_contour_12.png" /&gt;&lt;/p&gt;
&lt;p&gt;This is a $c=28$ class problem: A-Z, blank, and "capital" (an arbitrary icon specific to the game &lt;em&gt;Capitals&lt;/em&gt;). I have a small dataset with $n=346$ examples. I have at least 4 examples of each class, except for 'J', of which there are only 3. The images are 500px by 500px binary images, or nominally $d=250,000$ dimensions. Throughout the article I use 75% of the data (259 instances) for training, and the remaining 25% (87 instances) for testing.&lt;/p&gt;
&lt;p&gt;Note the small $n$ means that there is significant variability in performance, depending on how the training/test sets are (randomly) split. It's not improbable that there could be no 'J's present in the training set in one run, for example. Where error has varied significantly I have done several runs and presented a typical value.&lt;/p&gt;
&lt;p&gt;Also note that since this is a multinomial problem, the 'chance' error rate is not 50%, but approximately 90%, obtained by always guessing the most frequent class, 'A'.&lt;/p&gt;
&lt;p&gt;&lt;a name="solns"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Solutions&lt;/h3&gt;
&lt;p&gt;&lt;a name="template"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h4&gt;Template matching w/ LSPC (brute force benchmark)&lt;/h4&gt;
&lt;p&gt;&lt;em&gt;Note: Throughout this article I use LSPC[&lt;sup id="fnref:lspc"&gt;&lt;a class="footnote-ref" href="#fn:lspc" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt;]. It is a kernel-based nonlinear classifier, approximately as accurate as SVM or KLR, but blindingly fast (it has a closed form solution), allowing me to evaluate hundreds of models in the time it would take to train a single KLR. It is also natively multi-class and produces probabilistic outputs.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;A na√Øve approach is to encode each image as a vector of pixel values and use these as inputs to a nonlinear classifier, such as a neural network, support vector machine, or &lt;a href="http://web.stanford.edu/~hastie/Papers/svmtalk.pdf"&gt;KLR&lt;/a&gt;. This is essentially template matching.&lt;/p&gt;
&lt;p&gt;Template matching can be effective when images are consistent within classes (i.e. all "f"s look the same). On more difficult problems, template matching can be effective with some application-specific preprocessing, such as deskewing[&lt;sup id="fnref:deskewing"&gt;&lt;a class="footnote-ref" href="#fn:deskewing" rel="footnote"&gt;2&lt;/a&gt;&lt;/sup&gt;], and other normalization.&lt;/p&gt;
&lt;p&gt;Encoding entire images as vectors can lead to dimensionality problems, even after reducing image resolution. Also, template matching models cannot make more "perceptual" decisions ("two straight lines at right angles, plus a curving part might be a five"). Part of the allure of deep neural networks is that their heirarchical structure may be enabling this type of decision making.&lt;/p&gt;
&lt;p&gt;Since all character examples in my application come from a single font and are consistently oriented, template matching is a good benchmark.&lt;/p&gt;
&lt;p&gt;Using &lt;a href="https://github.com/iank/receptor-ocr/blob/master/template_match.py"&gt;template_match.py&lt;/a&gt; I generated the $n=346$, $d=250,000$ vectors and classified using LSPC by passing the resulting 165 megabyte CSV to &lt;a href="https://github.com/iank/receptor-ocr/blob/master/matlab/template.m"&gt;template.m&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The resulting data is unwieldy, and clearly redundant (as a back-of-the-envelope measure of information content, note that it gzips to 1.2M)&lt;/p&gt;
&lt;p&gt;&lt;a href="/images/receptors/template_data.png"&gt;&lt;img alt="raw image data" src="/images/receptors/template_data_s.png" /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Test error obtained with LSPC for template matching was 31.03%, significantly better than chance but not useful.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Test error for template matching: 31.03%&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a name="hu"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h4&gt;Hu moments (feature benchmark)&lt;/h4&gt;
&lt;p&gt;&lt;a href="https://en.wikipedia.org/wiki/Image_moment#Rotation_invariant_moments"&gt;Hu invariant moments&lt;/a&gt; are image moments which are invariant under translation, scaling, and rotation. They are not meant as pattern recognition features, however I use them here to provide another benchmark. This can be thought of as a slightly more sophisticated, image processing-specific version of classifying data based on their summary statistics (mean, variance, etc).&lt;/p&gt;
&lt;p&gt;This isn't completely off the rails, for example in this representation blank spaces are all zeros, and it's easy to imagine that some more patterns will be separable.&lt;/p&gt;
&lt;p&gt;Using &lt;a href="https://github.com/iank/receptor-ocr/blob/master/hu_moments.py"&gt;hu_moments.py&lt;/a&gt; I generated the $n=346$, $d=7$ vectors and classified using the same MATLAB code as above.&lt;/p&gt;
&lt;p&gt;Test error obtained with LSPC for Hu features was 10.34%, showing even rudimentary features can outperform template matching. Less is more. Small Data! &lt;sup id="fnref:smalldata"&gt;&lt;a class="footnote-ref" href="#fn:smalldata" rel="footnote"&gt;3&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Test error for Hu features: 10.34%&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a name="receptors"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h4&gt;Receptors&lt;/h4&gt;
&lt;p&gt;With better feature design, we can generate smaller models, achieve better classification, and possibly gain insight into the data by producing more &lt;em&gt;explainable&lt;/em&gt; models. The disadvantage to this approach over a more general method is that the features produced are often domain-specific, design can be labor-intensive, and approaches can be non-obvious or unknown in some domains.&lt;/p&gt;
&lt;p&gt;Example features for character recognition could be:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;counting connected components&lt;/li&gt;
&lt;li&gt;drawing regularly-spaced horizontal and vertical lines over the image and counting intersections for each&lt;/li&gt;
&lt;li&gt;statistics gleaned from approximating edges as lower-degree polygons&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;As an interesting compromise between manual feature design and automatic feature extraction, I found this &lt;a href="http://www.codeproject.com/Articles/11285/Neural-Network-OCR"&gt;codeproject post by Andrew Kirillov&lt;/a&gt;, who uses "receptors" (scroll to "Another Approach")&lt;sup id="fnref:receptors"&gt;&lt;a class="footnote-ref" href="#fn:receptors" rel="footnote"&gt;4&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;p&gt;The idea is to project the same set of small line segments on each image, and generate a vector of receptor activation (crossing the letter / not crossing the letter) for each image.&lt;/p&gt;
&lt;p&gt;I construct receptors by generating a set of midpoints, lengths, and angles. The midpoint positions are normalized so the image centroid is $(0.5,0.5)$, and distances (length, offset from centroid) are normalized by the image diagonal. So these features should not depend on scale or translation (although significant variation in whitespace padding could break my implementation).&lt;/p&gt;
&lt;p&gt;Midpoints have a Gaussian distribution $N(\mu = [0.5, 0.5], \sigma^2 = 0.2)$, and lengths are Rayleigh distributed ($\sigma = 0.08$). Angles are uniform between $0$ and $2\pi$.&lt;/p&gt;
&lt;p&gt;With &lt;a href="https://github.com/iank/receptor-ocr/blob/master/gen_receptors.py"&gt;gen_receptors.py&lt;/a&gt; I generated 2500 receptors, and produced a CSV using &lt;a href="https://github.com/iank/receptor-ocr/blob/master/gen_training_csv.py"&gt;gen_training_csv.py&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;At first, I tried to improve upon the receptor model by making receptor activation a real number (the average pixel intensity across the receptor) rather than a binary activation. Test error obtained with LSPC for 2500 real-valued receptors was 22%. By clamping receptor values to binary 0/1, I obtained perfect classification.&lt;/p&gt;
&lt;p&gt;In the codeproject post, the author is using a neural network, and training time can be greatly improved by reducing the number of features. He uses empirical estimates of entropy to attempt to select the most useful features.&lt;/p&gt;
&lt;p&gt;Here, $n=2500$ receptors are more than enough to perfectly classify my dataset, and training time with LSPC is a fraction of a second, making feature selection unnecessary. However requiring so many receptors for such an easy classification task seems wasteful, so I discuss feature selection below.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Test error for 2500 binary receptors: 0.00%&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a name="fs"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Feature selection&lt;/h3&gt;
&lt;p&gt;&lt;a name="theory"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h4&gt;Theoretical bound and PCA&lt;/h4&gt;
&lt;p&gt;While 2500 binary features perfectly separates the data, $c=28$ classes should be separable with $\lceil log_2(28) \rceil = 5$ binary features&lt;sup id="fnref:log2"&gt;&lt;a class="footnote-ref" href="#fn:log2" rel="footnote"&gt;5&lt;/a&gt;&lt;/sup&gt;, if five features can be found which:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;are consistent within-class (i.e. feature is &lt;em&gt;always&lt;/em&gt; or &lt;em&gt;never&lt;/em&gt; on whenever it is shown an example of an 'S')&lt;/li&gt;
&lt;li&gt;usefully separate the space (e.g. a feature that is always on for A-M and always off for N-Z. a second feature is on for A, C, E, ... and off for B, D, F, ...)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;These qualities can be measured statistically with &lt;a href="https://en.wikipedia.org/wiki/Entropy_(information_theory)"&gt;entropy&lt;/a&gt;, but I the idea is fixed in my intuition from playing &lt;a href="https://boardgamegeek.com/boardgame/4143/guess-who"&gt;Guess Who?&lt;/a&gt; as a kid. In the game, players attempt to select an individual from an array of faces by asking their opponent yes/no questions. "Is the person I am looking for female?" is a good first question to ask, because it splits the game space about evenly. "Does the person have green eyeglasses" is highly-specific and could pay off, but it's more likely to eliminate only one or two faces, so it is not a great first question. I'll discuss this more in the next section.&lt;/p&gt;
&lt;p&gt;Although I know that only five binary features could separate 28 classes, I don't yet know that these features can be modeled with receptors (I have strong evidence that such features &lt;em&gt;exist&lt;/em&gt;, however, since I have separated the space using 2500 receptors).&lt;/p&gt;
&lt;p&gt;More evidence that I can use significantly fewer than 2500 receptors: I used &lt;a href="https://en.wikipedia.org/wiki/Principal_component_analysis"&gt;Principal Component Analysis&lt;/a&gt;, which I have written about &lt;a href="http://blog.iank.org/pca-on-x-plane-images.html"&gt;previously&lt;/a&gt;, on the receptor activation data. Using PCA I can project the data along the first $k$ principal components, which is like re-shaping the data along a new set of axes which are uncorrelated.&lt;/p&gt;
&lt;p&gt;It's in part a way to get at the underlying dimensionality of the data: a $d \times d$ matrix will have $d$ principal components, but only a few may be large. In my test with 4841 receptors only about 10 principal componennts were significantly larger than zero, suggesting that a low-dimensional representation will be sufficient to represent most of the information.&lt;/p&gt;
&lt;p&gt;I used &lt;a href="https://github.com/iank/receptor-ocr/blob/master/matlab/rocr_pca.m"&gt;rocr_pca.m&lt;/a&gt; to do PCA on the receptor activation data. Using the first $k$ principal components&lt;sup id="fnref:pcacont"&gt;&lt;a class="footnote-ref" href="#fn:pcacont" rel="footnote"&gt;6&lt;/a&gt;&lt;/sup&gt;:&lt;/p&gt;
&lt;table&gt;
&lt;tr&gt;&lt;th&gt;k&lt;/th&gt;&lt;th&gt;LSPC test error&lt;/th&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;24.14%&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;2&lt;/td&gt;&lt;td&gt;5.75%&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;3&lt;/td&gt;&lt;td&gt;1.15%&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;4&lt;/td&gt;&lt;td&gt;0.00%&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;5&lt;/td&gt;&lt;td&gt;0.00%&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;

&lt;p&gt;(Note that fewer than five principal components were needed. This is because the projection along these components is real-valued, not binary).&lt;/p&gt;
&lt;p&gt;With, for example, 5 principal components, I still need to compute the activation for all 4841 receptors before projecting in order to classify an image&lt;sup id="fnref:pca"&gt;&lt;a class="footnote-ref" href="#fn:pca" rel="footnote"&gt;7&lt;/a&gt;&lt;/sup&gt;. But this experiment shows that the underlying information is not nearly 4841-dimensional and far fewer receptors should be needed. Selecting useful receptors is explored in the following section.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Test error for 4 principal components (from 4841 binary receptors): 0.00%&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a name="entropy"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h4&gt;Entropy&lt;/h4&gt;
&lt;p&gt;&lt;a href="http://www.codeproject.com/Articles/11285/Neural-Network-OCR"&gt;Andrew Kirillov&lt;/a&gt; uses entropy to do feature selection. I reimplemented this approach at first, and I'll summarize it here. The upshot is that it can reduce the number of features required, but not as dramatically as hill-climbing (below).&lt;/p&gt;
&lt;h5&gt;Probability&lt;/h5&gt;
&lt;p&gt;I know that only a few receptors should be required. I generate a field of 5,000 receptors, which should be large enough to contain a few useful features. Receptor activation (binary on/off)  I model with a random variable $Y_k \in \{0,1\}$ (where k represents the particular receptor in question, 1 to 5,000). A random variable $X \in \{A, B, C, ...\}$ models which class a given image is.&lt;/p&gt;
&lt;p&gt;Some quantities, which I empirically estimate from my training images:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$p(X)$: class frequency distribution, e.g. $p(A) = 0.1069$, $p(W) = 0.0173$&lt;/li&gt;
&lt;li&gt;$p(Y_k=1)$: probability that receptor $k$ is on (across all images)&lt;/li&gt;
&lt;li&gt;$p(Y_k=1|X=x)$: probability that receptor $k$ is on, &lt;strong&gt;given&lt;/strong&gt; that the image is a specific letter $x$&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For example, if receptor 903 is always on when the letter is 'Q', then $p(Y_{903}=1|X=q) = 1$. This means that all 'Q's trigger receptor 903, which is good, but it does not mean that receptor 903 is a good indication that the letter is a 'Q'. &lt;/p&gt;
&lt;p&gt;Using Bayes rule, I can compute $p(X=x|Y_k=1)$, the probability that an image is a specific letter given that receptor $k$ is on:&lt;/p&gt;
&lt;p&gt;\begin{equation}
p(X=x|Y=1) = \frac{p(Y=1|X=x) \cdot p(X=x)}{P(Y=1)}
\end{equation}&lt;/p&gt;
&lt;p&gt;Receptor 903 may light up for W's and A's also (or for every letter! In other words, $p(X=q|Y_{903}=1)$ may still be small).&lt;/p&gt;
&lt;h5&gt;H(Y|X)&lt;/h5&gt;
&lt;p&gt;So two quantities are interesting. We want receptors which are consistent within their classes. We can measure this by the entropy $H(Y_k|X)$. This is the average of the conditional entropy $H(Y_k|X=x)$ across all X. For example, if $H(Y_{k}|X=q)$ is large, then there is uncertainty about whether receptor k will turn on for a 'Q'. If it is zero, then receptor k is either &lt;em&gt;always&lt;/em&gt; on or &lt;em&gt;always&lt;/em&gt; off when presented with a 'Q'.&lt;/p&gt;
&lt;h5&gt;H(X|Y)&lt;/h5&gt;
&lt;p&gt;More interesting is how well a receptor determines class. This is $H(X|Y_k=1)$, which captures the uncertainty in $X$ given that $Y_k$ is on. It is minimized by certainty (if $p(X=x|Y=1) = 1$ for some $x$), and maximized ($-log_2(1/C)$) by a uniform distribution, indicating complete uncertanty.&lt;sup id="fnref:goodquestion"&gt;&lt;a class="footnote-ref" href="#fn:goodquestion" rel="footnote"&gt;8&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;I select receptors which are consistent and divide the space by selecting small $H(Y_k|X)$ and large $H(X|Y_k=1)$. This is done by assigning to each receptor a 'usefulness' score defined by the product:&lt;/p&gt;
&lt;p&gt;\begin{equation}
H(X|Y_k=1) \cdot (1 - H(Y_k|X)),
\end{equation}&lt;/p&gt;
&lt;p&gt;and selecting the receptors with the $N$ highest values. By classifying using LSPC with the first $N$ receptors, I plot test error vs $N$, showing how many receptors are required for successful classification (from an initial set of 2500):&lt;/p&gt;
&lt;p&gt;&lt;img alt="err_vs_n.png" src="/images/receptors/err_vs_n.png" /&gt;&lt;/p&gt;
&lt;p&gt;So only about 600 receptors are required for perfect classification which is an improvement, but this image shows that the first nearly 200 receptors are completely useless! &lt;/p&gt;
&lt;p&gt;I also tried selecting for receptor specificity, i.e. recomputing usefulness as:&lt;/p&gt;
&lt;p&gt;\begin{equation}
(-log_2(1/C) - H(X|Y_k=1)) \cdot (1 - H(Y_k|X)),
\end{equation}&lt;/p&gt;
&lt;p&gt;&lt;img alt="err_vs_n_2.png" src="/images/receptors/err_vs_n_2.png" /&gt;&lt;/p&gt;
&lt;p&gt;Note the larger horizontal axis here. With this method, the first few receptors were more immediately useful, but it took longer to converge. Also, this is from an initial set of 5000. This is evidence that there is a balance between initial set size (larger = more likely to generate useful receptors) and redundancy.&lt;/p&gt;
&lt;p&gt;(This method used revisions 2fb264a9a0e759eaa06e0c0a9cc263c655f78f17 and 3706c08a1d067cf13a3d2efd3c4317fc76071e44 of gen_receptors.py).&lt;/p&gt;
&lt;p&gt;Both methods are a clear improvement over 2,500 or 5,000, but it seems too many. This is addressed in the next section.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Test error for first 600 features selected using entropy: 0.00%&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a name="redundancy"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h4&gt;Redundancy (K-L divergence)&lt;/h4&gt;
&lt;p&gt;The entropy-based selection described above has a certain information-theoretic appeal, but it does not look for receptors which split the class space &lt;em&gt;differently&lt;/em&gt;. A receptor which separates A-N from M-Z has high 'usefulness' as calculated above, but so do 200 receptors which separate A-N from M-Z, and these do not add information beyond the first. In the image below, the first 1,000 or so receptors (shown in green) very specifically identify a capital. Only after 1,000 do we get receptors which activate for other letters (red).&lt;/p&gt;
&lt;p&gt;&lt;img alt="c1000.png" src="/images/receptors/c1000.png" /&gt;&lt;/p&gt;
&lt;p&gt;I attempted to address this by augmenting the usefulness score with a measure of redundancy&lt;sup id="fnref:mrmr"&gt;&lt;a class="footnote-ref" href="#fn:mrmr" rel="footnote"&gt;9&lt;/a&gt;&lt;/sup&gt;. The &lt;a href="https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence"&gt;Kullback-Leibler divergence&lt;/a&gt; is a nonnegative measure of difference between probability distributions, closely related to mutual information and entropy. $D_{KL}(P||Q)$ is not symmetric, but $D_{KL}(P||Q) + D_{KL}(Q||P)$ is. So I use the following algorithm to score receptors:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Compute usefulness for all receptors as above&lt;/li&gt;
&lt;li&gt;Until no receptors are remaining:&lt;ul&gt;
&lt;li&gt;Add most useful receptor to an ordered set $S$&lt;/li&gt;
&lt;li&gt;Recompute usefulness for all receptors, multiplying by the average symmetric K-L divergence from receptors in $S$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Take the first $N$ receptors from $S$, these are the $N$ most 'useful' receptors&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;(This method used revision e5be113fbe1dccdad865c78ccdf5cfef10eae127 of gen_receptors.py).&lt;/p&gt;
&lt;p&gt;The result of this approach, from an initial set of 5000, is shown below (here I am minimizing $H(X|Y)$, as in the previous plot).&lt;/p&gt;
&lt;p&gt;&lt;img alt="err_vs_n_3.png" src="/images/receptors/err_vs_n_3.png" /&gt;&lt;/p&gt;
&lt;p&gt;Initially, this is a clear improvement over the last, but it has not succeeded in eliminating many features in the end. This leads me to abandon the information-theoretic approach entirely in favour of a simple method discussed in the next section.&lt;/p&gt;
&lt;p&gt;&lt;a name="hill"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h4&gt;Greedy hill-climbing &amp;amp; pruning&lt;/h4&gt;
&lt;p&gt;A simple feature selection strategy is greedy hill-climbing. Start with an empty set of features, $S$, and a set of remaining features, $R$.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Until $R$ is empty &lt;strong&gt;or&lt;/strong&gt; the test error has not improved in a few iterations:&lt;ul&gt;
&lt;li&gt;For every feature $k \in R$, train a classifier with features $S + k$.&lt;/li&gt;
&lt;li&gt;Add whichever feature decreased test error the most to $S$&lt;/li&gt;
&lt;li&gt;Remove it from $R$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This involves training an astonishing number of classifiers, like a &lt;a href="http://mathworld.wolfram.com/TriangularNumber.html"&gt;triangular number&lt;/a&gt; $T_n$ for $n$ initial features. Fortunately this is possible in a reasonable period of time with LSPC, and even fast if I add the five best features at each iteration instead of proceeding one at a time.&lt;/p&gt;
&lt;p&gt;The "greedy" aspect of this algorithm is that it never un-selects a feature. It is descending&lt;sup id="fnref:hillclimb"&gt;&lt;a class="footnote-ref" href="#fn:hillclimb" rel="footnote"&gt;10&lt;/a&gt;&lt;/sup&gt; an objective function (test error) by taking the steepest immediate step at every iteration. A complete search would be the power set of features, $2^{5000}$ of them, but that is too many and the greedy hill climb works well enough.&lt;/p&gt;
&lt;p&gt;Since I added five features at a time, hill climbing is followed by a pruning step, which is much the same but in reverse. One feature is removed at a time. Code is &lt;a href="https://github.com/iank/receptor-ocr/blob/master/matlab/rocr_hill.m"&gt;rocr_hill.m&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a name="results"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Results&lt;/h3&gt;
&lt;p&gt;In a test with 5000 initial receptors, 45 were added and then pruned to 20 while maintaining perfect classification. These receptors are shown below on a blank image and two letters:&lt;/p&gt;
&lt;p&gt;&lt;img alt="field_labels.png" src="/images/receptors/field_labels.png" /&gt;
&lt;img alt="field_s.png" src="/images/receptors/field_s.png" /&gt;
&lt;img alt="field_w.png" src="/images/receptors/field_w.png" /&gt;&lt;/p&gt;
&lt;p&gt;The features are shown below, along with their entropies and probabilities of activation $p(Y_k=1|X=x)$. This helps illustrate how each feature breaks up the space:&lt;/p&gt;
&lt;table style="border-collapse: collapse;"&gt;
&lt;tr&gt;&lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;On (&amp;gt; 90%)&lt;/td&gt;
    &lt;td style="padding: 0; margin: 0; background-color:#ADD8E6"&gt;Mid (15% - 90%)&lt;/td&gt;
    &lt;td style="padding: 0; margin: 0; background-color:#FFE3EB"&gt;Low (1% - 15%)&lt;/td&gt;
    &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;Off (&amp;lt; 1%)&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;

&lt;table style="border-collapse: collapse;"&gt;
&lt;tr&gt;&lt;th&gt;#&lt;/th&gt;&lt;th&gt;Hyx&lt;/th&gt;&lt;th&gt;Hxy&lt;/th&gt;&lt;th&gt;_&lt;/th&gt;&lt;th&gt;1&lt;/th&gt;&lt;th&gt;A&lt;/th&gt;&lt;th&gt;B&lt;/th&gt;&lt;th&gt;C&lt;/th&gt;&lt;th&gt;D&lt;/th&gt;&lt;th&gt;E&lt;/th&gt;&lt;th&gt;F&lt;/th&gt;&lt;th&gt;G&lt;/th&gt;&lt;th&gt;H&lt;/th&gt;&lt;th&gt;I&lt;/th&gt;&lt;th&gt;J&lt;/th&gt;&lt;th&gt;K&lt;/th&gt;&lt;th&gt;L&lt;/th&gt;&lt;th&gt;M&lt;/th&gt;&lt;th&gt;N&lt;/th&gt;&lt;th&gt;O&lt;/th&gt;&lt;th&gt;P&lt;/th&gt;&lt;th&gt;Q&lt;/th&gt;&lt;th&gt;R&lt;/th&gt;&lt;th&gt;S&lt;/th&gt;&lt;th&gt;T&lt;/th&gt;&lt;th&gt;U&lt;/th&gt;&lt;th&gt;V&lt;/th&gt;&lt;th&gt;W&lt;/th&gt;&lt;th&gt;X&lt;/th&gt;&lt;th&gt;Y&lt;/th&gt;&lt;th&gt;Z&lt;/th&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;4621&lt;/td&gt;&lt;td&gt;0.06&lt;/td&gt;&lt;td style="border-right: 1px solid"&gt;4.50&lt;/td&gt;&lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#ADD8E6"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;2133&lt;/td&gt;&lt;td&gt;0.08&lt;/td&gt;&lt;td style="border-right: 1px solid"&gt;3.92&lt;/td&gt;&lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#ADD8E6"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#ADD8E6"&gt;&amp;nbsp;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;2598&lt;/td&gt;&lt;td&gt;0.04&lt;/td&gt;&lt;td style="border-right: 1px solid"&gt;3.81&lt;/td&gt;&lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#ADD8E6"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;3035&lt;/td&gt;&lt;td&gt;0.11&lt;/td&gt;&lt;td style="border-right: 1px solid"&gt;3.78&lt;/td&gt;&lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#ADD8E6"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#ADD8E6"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;2404&lt;/td&gt;&lt;td&gt;0.10&lt;/td&gt;&lt;td style="border-right: 1px solid"&gt;3.65&lt;/td&gt;&lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFE3EB"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#ADD8E6"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#ADD8E6"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#ADD8E6"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;1571&lt;/td&gt;&lt;td&gt;0.13&lt;/td&gt;&lt;td style="border-right: 1px solid"&gt;3.33&lt;/td&gt;&lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFE3EB"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#ADD8E6"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#ADD8E6"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;2186&lt;/td&gt;&lt;td&gt;0.07&lt;/td&gt;&lt;td style="border-right: 1px solid"&gt;3.31&lt;/td&gt;&lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#ADD8E6"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#ADD8E6"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;2151&lt;/td&gt;&lt;td&gt;0.15&lt;/td&gt;&lt;td style="border-right: 1px solid"&gt;3.28&lt;/td&gt;&lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#ADD8E6"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#ADD8E6"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#ADD8E6"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#ADD8E6"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;1460&lt;/td&gt;&lt;td&gt;0.07&lt;/td&gt;&lt;td style="border-right: 1px solid"&gt;3.24&lt;/td&gt;&lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFE3EB"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFE3EB"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;1777&lt;/td&gt;&lt;td&gt;0.03&lt;/td&gt;&lt;td style="border-right: 1px solid"&gt;3.09&lt;/td&gt;&lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;1195&lt;/td&gt;&lt;td&gt;0.09&lt;/td&gt;&lt;td style="border-right: 1px solid"&gt;2.98&lt;/td&gt;&lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFE3EB"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#ADD8E6"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#ADD8E6"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;1645&lt;/td&gt;&lt;td&gt;0.19&lt;/td&gt;&lt;td style="border-right: 1px solid"&gt;2.85&lt;/td&gt;&lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFE3EB"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#ADD8E6"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#ADD8E6"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#ADD8E6"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#ADD8E6"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#ADD8E6"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;1202&lt;/td&gt;&lt;td&gt;0.11&lt;/td&gt;&lt;td style="border-right: 1px solid"&gt;2.40&lt;/td&gt;&lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#ADD8E6"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#ADD8E6"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFE3EB"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;1330&lt;/td&gt;&lt;td&gt;0.14&lt;/td&gt;&lt;td style="border-right: 1px solid"&gt;1.84&lt;/td&gt;&lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#ADD8E6"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#ADD8E6"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#ADD8E6"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#ADD8E6"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;154&lt;/td&gt;&lt;td&gt;0.09&lt;/td&gt;&lt;td style="border-right: 1px solid"&gt;1.46&lt;/td&gt;&lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#ADD8E6"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFE3EB"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#ADD8E6"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;1145&lt;/td&gt;&lt;td&gt;0.05&lt;/td&gt;&lt;td style="border-right: 1px solid"&gt;1.06&lt;/td&gt;&lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFE3EB"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#ADD8E6"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;177&lt;/td&gt;&lt;td&gt;0.01&lt;/td&gt;&lt;td style="border-right: 1px solid"&gt;0.00&lt;/td&gt;&lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;392&lt;/td&gt;&lt;td&gt;0.01&lt;/td&gt;&lt;td style="border-right: 1px solid"&gt;0.00&lt;/td&gt;&lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFE3EB"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;445&lt;/td&gt;&lt;td&gt;0.01&lt;/td&gt;&lt;td style="border-right: 1px solid"&gt;0.00&lt;/td&gt;&lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFE3EB"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;315&lt;/td&gt;&lt;td&gt;0.01&lt;/td&gt;&lt;td style="border-right: 1px solid"&gt;-0.00&lt;/td&gt;&lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;

&lt;p&gt;&lt;a name="summary"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Summary&lt;/h3&gt;
&lt;p&gt;Here is a summary of the techniques discussed in this article. In all cases (except chance), LSPC is used to classify the generated/selected features.&lt;/p&gt;
&lt;table&gt;
&lt;tr&gt;&lt;th&gt;Method&lt;/th&gt;&lt;th&gt;Features&lt;/th&gt;&lt;th&gt;Error&lt;/th&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Chance&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;~90%&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Template matching&lt;/td&gt;&lt;td&gt;250000&lt;/td&gt;&lt;td&gt;31.03%&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Hu moments&lt;/td&gt;&lt;td&gt;7&lt;/td&gt;&lt;td&gt;10.34%&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;PCA (continuous activation)&lt;/td&gt;&lt;td&gt;8 principal components (4841 underlying receptors)&lt;/td&gt;&lt;td&gt;0%&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;PCA (binary activation)&lt;/td&gt;&lt;td&gt;4 principal (4841 underlying receptors)&lt;/td&gt;&lt;td&gt;0%&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Receptors (continuous activation)&lt;/td&gt;&lt;td&gt;2500&lt;/td&gt;&lt;td&gt;22%&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Receptors (binary activation)&lt;/td&gt;&lt;td&gt;2500&lt;/td&gt;&lt;td&gt;0%&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Entropy selection (max HXY)&lt;/td&gt;&lt;td&gt;~600 (initially 2500)&lt;/td&gt;&lt;td&gt;0%&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Entropy selection (min HXY)&lt;/td&gt;&lt;td&gt;~1700 (initially 5000)&lt;/td&gt;&lt;td&gt;0%&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Entropy (min HXY) + K-L divergence&lt;/td&gt;&lt;td&gt;~1500 (initially 5000)&lt;/td&gt;&lt;td&gt;0%&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Greedy hill-climbing &amp;amp; pruning&lt;/td&gt;&lt;td&gt;20 (initially 5000)&lt;/td&gt;&lt;td&gt;0%&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;

&lt;p&gt;&lt;a name="refs"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;References/Notes&lt;/h3&gt;
&lt;div class="footnote"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn:lspc"&gt;
&lt;p&gt;&lt;a href="http://www.ms.k.u-tokyo.ac.jp/2010/LSPC.pdf"&gt;Sugiyama, Masashi. "Superfast-trainable multi-class probabilistic classifier by least-squares posterior fitting." &lt;em&gt;IEICE Transactions on Information and Systems&lt;/em&gt; 93.10 (2010): 2690-2701.&lt;/a&gt;&amp;#160;&lt;a class="footnote-backref" href="#fnref:lspc" rev="footnote" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:deskewing"&gt;
&lt;p&gt;Or 'deslanting', discussed in Teow, Loo-Nin, and Kia-Fock Loe. "Robust vision-based features and classification schemes for off-line handwritten digit recognition." &lt;em&gt;Pattern Recognition&lt;/em&gt; 35.11 (2002): 2355-2364.&amp;#160;&lt;a class="footnote-backref" href="#fnref:deskewing" rev="footnote" title="Jump back to footnote 2 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:smalldata"&gt;
&lt;p&gt;This illustrates an inefficiency in the model: the template matching dataset contained more information, extracting the Hu features did not add any information. By rearranging information and throwing away redundant data, I was able to improve performance here. It is theoretically possible that a sufficiently complex neural network could perform optimally (here, perfect classification is possible) on the raw data. In some cases, this is impractical and some preprocessing can go a long way. On the other hand, especially in image recognition tasks, &lt;a href="https://en.wikipedia.org/wiki/Deep_belief_network"&gt;DBNs&lt;/a&gt; and other deep neural models have shown remarkable results and can be used to generate high-level features automatically. It's possible that this kind of model can make manual feature design unnecessary, and enable feature design in spaces we do not understand.&amp;#160;&lt;a class="footnote-backref" href="#fnref:smalldata" rev="footnote" title="Jump back to footnote 3 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:receptors"&gt;
&lt;p&gt;It's worth noting the similarities to template matching here. These features are not invariant to rotation or skew, but are somewhat more flexible than templates because activation may take place anywhere on an arbitrary line segment.&amp;#160;&lt;a class="footnote-backref" href="#fnref:receptors" rev="footnote" title="Jump back to footnote 4 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:log2"&gt;
&lt;p&gt;One feature can split 28 classes into two groups of 14. Further independent features could split those into four groups of 7, then four groups of 3 and four groups of 4, and so on. [28] -&amp;gt; [14 14] -&amp;gt; [7 7 7 7] -&amp;gt; [3 3 3 3 4 4 4 4] -&amp;gt; [2 2 2 2 2 2 2 2 2 2 2 2 1 1 1] -&amp;gt; [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]. So 5 features are needed.&amp;#160;&lt;a class="footnote-backref" href="#fnref:log2" rev="footnote" title="Jump back to footnote 5 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:pcacont"&gt;
&lt;p&gt;With continuous rather than binary receptor activations, PCA+LSPC required 8 principal components.&amp;#160;&lt;a class="footnote-backref" href="#fnref:pcacont" rev="footnote" title="Jump back to footnote 6 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:pca"&gt;
&lt;p&gt;For LSPC, this means PCA is no real advantage. It is cheap enough to classify $d=2500$ vectors. Peprocessing with PCA will be a big speedup for models which depend more heavily on dimension.&amp;#160;&lt;a class="footnote-backref" href="#fnref:pca" rev="footnote" title="Jump back to footnote 7 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:goodquestion"&gt;
&lt;p&gt;Maximizing this value, then, would seem counterintuitive. However, receptors which evenly split the class space also have high entropy. I also tried minimizing H(X|Y), which is more akin to asking "does the subject wear green eyeglasses?" than "does the subject have facial hair?", but small values here at least ensure there is some certainty. Both approach suffer from the redundancy issue I discuss in the next section.&amp;#160;&lt;a class="footnote-backref" href="#fnref:goodquestion" rev="footnote" title="Jump back to footnote 8 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:mrmr"&gt;
&lt;p&gt;This combined entropy/redundancy approach is vaguely reminiscent of more mature techniques like &lt;a href="https://en.wikipedia.org/wiki/Feature_selection#Minimum-redundancy-maximum-relevance_.28mRMR.29_feature_selection"&gt;mRMR&lt;/a&gt;.&amp;#160;&lt;a class="footnote-backref" href="#fnref:mrmr" rev="footnote" title="Jump back to footnote 9 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:hillclimb"&gt;
&lt;p&gt;I guess nobody calls it "valley-descending"&amp;#160;&lt;a class="footnote-backref" href="#fnref:hillclimb" rev="footnote" title="Jump back to footnote 10 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</summary><category term="python"></category><category term="MATLAB"></category><category term="computer math"></category><category term="OCR"></category><category term="feature selection"></category></entry><entry><title>A Localized Path-Finding Genetic Algorithm</title><link href="http://blog.iank.org/a-localized-path-finding-genetic-algorithm.html" rel="alternate"></link><updated>2013-08-17T19:30:00-04:00</updated><author><name>Ian Kilgore</name></author><id>tag:blog.iank.org,2013-08-17:a-localized-path-finding-genetic-algorithm.html</id><summary type="html">&lt;h3&gt;Localized Path-Finding&lt;/h3&gt;
&lt;p&gt;Below I implement a genetic algorithm which attempts the following problem:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Find a model which can, as an autonomous agent, traverse the lowest-cost path across some weighted map using only local information.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;If this agent had prior knowledge of the entire map, determining the best path across it would be an objective (and well-studied) matter. In the following I attempt to train an agent to solve this problem with limited (local) information. These agents make decisions based only on four numbers: the relative heights of the terrain one "move" away in each of four directions (i.e., they can see no further than they can move).&lt;/p&gt;
&lt;p&gt;On a uniformly-weighted space the lowest-cost path is simply the shortest, but here cost may be a proxy for difficult or rough terrain, or an abstraction. Below I will discuss the formulation and implications of the cost function used.&lt;/p&gt;
&lt;h3&gt;Terrain and Sample Problem&lt;/h3&gt;
&lt;p&gt;&lt;a href="/images/erasmus/problem_ex.png"&gt;&lt;img alt="Example Depth Map With Source, Destination, and Two Possible Paths" src="/images/erasmus/problem_ex_t.png" title="Example Depth Map With Source, Destination, and Two Possible Paths" /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The figure above shows one possible problem space. The grey levels in the image can be understood as a height map, with lighter pixels representing higher altitudes. The red circle is a starting position, and an agent must attempt to cross the vertical green line on the right border of the image. Shown in yellow and blue are two possible paths from source to destination.&lt;/p&gt;
&lt;p&gt;A successful agent should strike a balance between the shortest path and one that involves the least amount of steep climbs or descents. It should attempt to follow altitude contours when possible, but occasionally climb (or descend) a hill for a significant shortcut.&lt;/p&gt;
&lt;p&gt;Readers uninterested in the details of implementation may wish to skip to &lt;a href="#results"&gt;results&lt;/a&gt; below.&lt;/p&gt;
&lt;h3&gt;Cost Function&lt;/h3&gt;
&lt;p&gt;It is intuitive that the yellow, longer path is a worse solution than the blue, straightforward one. This notion can be made objective by computing a cost which is equal to the length of the path. I also discretize the problem: an agent only moves in quantum steps of length $\epsilon$, where $\epsilon$ is measured in pixels. This cost function is then proportional (or equal) to $N$, the number of steps required to complete the path:&lt;/p&gt;
&lt;p&gt;\begin{equation}
C = N
\end{equation}&lt;/p&gt;
&lt;p&gt;The shortest path (a straight line) is now always the best path, so this cost function must be augmented to take changes in altitude into account. The cost calculation becomes:&lt;/p&gt;
&lt;p&gt;\begin{equation}
C = \sum\limits_{n=1}^N g_n^2 + \lambda N
\end{equation}&lt;/p&gt;
&lt;p&gt;where&amp;lt;&lt;/p&gt;
&lt;p&gt;\begin{equation}
g_n =
\begin{cases}
\Delta_n, &amp;amp; \text{if }\Delta_n \geq 0\
-\frac{\Delta_n}{2}, &amp;amp; \text{if }\Delta_n &amp;lt; 0
\end{cases}
\end{equation}&lt;/p&gt;
&lt;p&gt;for each step $g_n$ along the path. $\Delta_n$ is the change in height for that step. This cost is a function of both path length and the amount of climbing and descending one must do to complete the path. Note that cost scales with $g_n$ squared, meaning that very steep climbs and descents are penalized more strongly than shallow ones. Also, the cost for a descent is less than for a climb, but still positive (consider driving a vehicle down a steep, unpaved slope).&lt;/p&gt;
&lt;p&gt;The parameter $\lambda$ controls the trade-off in cost between path length and altitude change: when $\lambda$ is very large, the path length component dominates and shorter paths will be selected at the cost of climbing. When $\lambda$ is very small, paths which minimize climbing will be favoured.&lt;/p&gt;
&lt;p&gt;Finally, many agents never find a complete path. A (very large) fixed-cost penalty, $Q$, is added to their total costs.&lt;/p&gt;
&lt;h3&gt;Agent Model&lt;/h3&gt;
&lt;h4&gt;Model Input&lt;/h4&gt;
&lt;p&gt;I model an agent as a function which, at each step, decides which direction to move based on information about the relative height of its immediate surroundings. The input at each step, $\mathbf{x}$, is a vector of length $d$ of (an approximation of) the directional derivatives around the agent's current position:&lt;/p&gt;
&lt;p&gt;\begin{equation}
x_i = \frac{h([x,y] + \epsilon\angle\theta_i)-h([x,y])}{\epsilon} \text{ for } i=1,...,d
\end{equation}&lt;/p&gt;
&lt;p&gt;Here $h(x,y)$ represents the height at position $(x,y)$. The angles $\theta_i$ are spaced evenly along the unit circle. So the vector $\mathbf{x}$ is the difference in height between an agent's current position and $d$ surrounding locations which are $\epsilon$ units away. For a differentiable surface, the gradient of $h(x,y)$ is sufficient to describe it, but for this approximate model I have chosen $d=4$.&lt;/p&gt;
&lt;h4&gt;Model Parameters and Output&lt;/h4&gt;
&lt;p&gt;At each step the agent must decide a new direction in which to move. This should be an angle, $\phi$, between $\pi$ and $-\pi$. The model becomes a function $A$ of $\mathbf{x}$, parameterized by some unknown vector $\alpha$:&lt;/p&gt;
&lt;p&gt;\begin{equation}
\hat{\phi} = A_\mathbf{\alpha}(\mathbf{x})
\end{equation}&lt;/p&gt;
&lt;p&gt;The core of this model, $\mathbf{\alpha}^\top\mathbf{x}$, is a simple linear combination of the parameters, $\mathbf{\alpha}$, and the input vector $\mathbf{x}$. The output is then "squished" with a sigmoid function and normalized between $-\pi$ and $\pi$:&lt;/p&gt;
&lt;p&gt;\begin{equation}
A_\mathbf{\alpha}(\mathbf{x}) = 2\pi\left(\frac{1}{1+exp(\mathbf{\alpha}^\top\mathbf{x})}-0.5\right)
\end{equation}&lt;/p&gt;
&lt;p&gt;I show below that a model with only $d=4$ parameters is sufficient for reasonable performance as a path-finding agent. A genetic algorithm, below, is used to find near-optimal values for these four parameters.&lt;/p&gt;
&lt;h3&gt;Genetic Algorithm&lt;/h3&gt;
&lt;p&gt;A &lt;a href="http://en.wikipedia.org/wiki/Genetic_algorithm"&gt;genetic algorithm&lt;/a&gt; attempts to solve an optimization problem by mimicking evolution. Genetic algorithms are well-studied, so I will describe only my implementation for this problem. I represent each individual as a list of floating-point "genes" (in this case, each individual has four genes corresponding to the model parameters $\mathbf{\alpha}$.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;An initial population of $P=200$ individual agents is randomly generated. I initialize weights using a long-tailed t distribution. This encourages diversity in the gene pool by creating a few more relatively large weights (as opposed to a normal distribution) [&lt;sup id="fnref:montana"&gt;&lt;a class="footnote-ref" href="#fn:montana" rel="footnote"&gt;3&lt;/a&gt;&lt;/sup&gt;].&lt;/li&gt;
&lt;li&gt;Each agent is run and its total cost computed&lt;/li&gt;
&lt;li&gt;The best individual from the previous generation is carried over unchanged. This is referred to as elitism, and prevents the algorithm from throwing away the most fit individual through crossover or mutation [&lt;sup id="fnref:rudolph"&gt;&lt;a class="footnote-ref" href="#fn:rudolph" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt;]. It has also been shown to decrease convergence time [&lt;sup id="fnref:zitzler"&gt;&lt;a class="footnote-ref" href="#fn:zitzler" rel="footnote"&gt;2&lt;/a&gt;&lt;/sup&gt;].&lt;/li&gt;
&lt;li&gt;A new population is bred:&lt;ul&gt;
&lt;li&gt;Two parents are selected with probability proportional to the reciprocal of their associated cost&lt;/li&gt;
&lt;li&gt;The two parents are combined using two-point crossover, creating a child individual&lt;/li&gt;
&lt;li&gt;These children are mutated by adding a small random offset to each gene with a 4% probability.&lt;/li&gt;
&lt;li&gt;This is repeated until 90% of the new generation has been created&lt;/li&gt;
&lt;li&gt;The remaining 10% of the new generation are initialized randomly&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Results&lt;/h3&gt;
&lt;p&gt;&lt;a name="results"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h4&gt;GA vs Control&lt;/h4&gt;
&lt;p&gt;In order to demonstrate that the genetic algorithm is productively solving this problem, I compare it to a control. The control algorithm keeps the best individual from the previous generation, as in the GA. Every other individual, however, is randomly generated. The following figures show that a genetic algorithm (first) outperforms a random search (second) of the parameter space. The cost function here has been tuned to discourage climbing in favour of longer, contour-following paths.&lt;/p&gt;
&lt;p&gt;&lt;a href="/images/erasmus/gavs.png"&gt;&lt;img alt="Path taken by best agent found by genetic algorithm" src="/images/erasmus/gavs_t.png" title="Path taken by best agent found by genetic algorithm" /&gt;&lt;/a&gt;
&lt;a href="/images/erasmus/rndvs.png"&gt;&lt;img alt="Path taken by best agent found by random selection" src="/images/erasmus/rndvs_t.png" title="Path taken by best agent found by random selection" /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h4&gt;Evolution of Best Path&lt;/h4&gt;
&lt;p&gt;In the figures below, the best path for several different generations is evolved. The algorithm finds a global solution fairly quickly, and then optimizes certain local difficulties. The first image, below, shows the initial (random) best path, which does not reach the objective. After a few generations, a reasonable solution has been found but three problem areas (outlined in blue) remain. The next row of images focus on only the lower-right problem area. We see that the path, while initially confused, begins to straighten out after several generations.&lt;/p&gt;
&lt;p&gt;&lt;a href="images/erasmus/evolution.txt"&gt;Text output from this experiment&lt;/a&gt; is available. It is possible here to see how the percentage of the population which sucessfully completes any route grows as successful individuals are selected to reproduce.&lt;/p&gt;
&lt;p&gt;&lt;a href="/images/erasmus/gen01_t.png"&gt;&lt;img alt="Initial (random) solution" src="/images/erasmus/gen01_t.png" title="Initial (random) solution" /&gt;&lt;/a&gt;
&lt;a href="/images/erasmus/gen11_t.png"&gt;&lt;img alt="Global (coarse) solution found after 11 generations. Local problem areas outlined in blue." src="/images/erasmus/gen11_t.png" title="Global (coarse) solution found after 11 generations. Local problem areas outlined in blue." /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="/images/erasmus/gen11_p1_t.png"&gt;&lt;img alt="Local problem area w/in global/coarse solution" src="/images/erasmus/gen11_p1_t.png" title="Local problem area w/in global/coarse solution" /&gt;&lt;/a&gt;
&lt;a href="/images/erasmus/gen15_p2_t.png"&gt;&lt;img alt="Iteration upon problem area" src="/images/erasmus/gen15_p2_t.png" title="Iteration upon problem area" /&gt;&lt;/a&gt;
&lt;a href="/images/erasmus/gen22_p3_t.png"&gt;&lt;img alt="Iteration upon problem area" src="/images/erasmus/gen22_p3_t.png" title="Iteration upon problem area" /&gt;&lt;/a&gt;
&lt;a href="/images/erasmus/gen36_p4_t.png"&gt;&lt;img alt="Iteration upon problem area" src="/images/erasmus/gen36_p4_t.png" title="Iteration upon problem area" /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h4&gt;Step Cost and Differentiability&lt;/h4&gt;
&lt;p&gt;Although the best path in the previous section eventually became somewhat smooth, its jagged nature can be improved upon. The jaggedness of that path can be attributed to two factors:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The images in the previous section were generated using a low step cost $\lambda$. This low step cost does not serve well to discourage too-long paths.&lt;/li&gt;
&lt;li&gt;The image used as a map is discontinuous (i.e. not differentiable) at the transitions between white and black. In this case the agent has no information about the upcoming cliff until it hits it. It cannot choose an intermediate angle and must proceed in a zig/zag fashion.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;By smoothing the image (by a 20x20 boxcar filter) and increasing the step cost, we can find a much better route through the image. From left to right:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;In the first figure below, the problem is demonstrated. The image is discontinuous, and $\lambda=0.001$.&lt;/li&gt;
&lt;li&gt;In the second figure, the image has been smoothed, but the step cost remains $\lambda=0.001$.&lt;/li&gt;
&lt;li&gt;Next, the step cost is increased to $\lambda=50$&lt;/li&gt;
&lt;li&gt;Next, the step cost is increased to $\lambda=1000$, and we see a relatively smooth path.&lt;/li&gt;
&lt;li&gt;Finally, we are shown a global view of the previous image (with $\lambda=1000$), showing the smoother path. Also note that some shortcuts have been taken.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href="/images/erasmus/soln4_t.png"&gt;&lt;img alt="Zig-zag path due to low step cost and discontinuous image" src="/images/erasmus/soln4_t.png" title="Zig-zag path due to low step cost and discontinuous image" /&gt;&lt;/a&gt;
&lt;a href="/images/erasmus/soln1_t.png"&gt;&lt;img alt="Problem is ameliorated by smoothing the image" src="/images/erasmus/soln1_t.png" title="Problem is ameliorated by smoothing the image" /&gt;&lt;/a&gt;
&lt;a href="/images/erasmus/soln2_t.png"&gt;&lt;img alt="Step cost is increased to lambda=50 resulting in a shorter path" src="/images/erasmus/soln2_t.png" title="Step cost is increased to lambda=50 resulting in a shorter path" /&gt;&lt;/a&gt;
&lt;a href="/images/erasmus/soln3_t.png"&gt;&lt;img alt="Further increase in step cost (lambda=1000) results in a shorter, smoother path" src="/images/erasmus/soln3_t.png" title="Further increase in step cost (lambda=1000) results in a shorter, smoother path" /&gt;&lt;/a&gt;
&lt;a href="/images/erasmus/soln3_global_t.png"&gt;&lt;img alt="Global view of previous image" src="/images/erasmus/soln3_global_t.png" title="Global view of previous image" /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h4&gt;Generalization&lt;/h4&gt;
&lt;p&gt;A simple experiment shows that these agents have some limited capacity for generalization. An agent was trained on a perlin noise depth map using an initial position near the centre of the image. It proceeded to its goal while attempting to maintain the same altitude throughout. The same agent was then run starting at the far left of the image (at a different altitude) and then found a reasonable path to its goal, again maintaining a relatively uniform altitude throughout.&lt;/p&gt;
&lt;p&gt;&lt;a href="/images/erasmus/bestroute_trained_t.png"&gt;&lt;img alt="Best route found during training" src="/images/erasmus/bestroute_trained_t.png" title="Best route found during training" /&gt;&lt;/a&gt;
&lt;a href="/images/erasmus/bestroute_generalized_t.png"&gt;&lt;img alt="Same agent released at a different starting position" src="/images/erasmus/bestroute_generalized_t.png" title="Same agent released at a different starting position" /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This capacity for generalization has limits. In the following example, there is a conduit through the image with a fork. One fork is a route through, and the other is not. Because these agents work using only local knowledge, it is impossible to determine a priori which path is best (It is impossible for even a truly intelligent agent to choose the correct path given only the information at hand).&lt;/p&gt;
&lt;p&gt;&lt;a href="/images/erasmus/gen01_t.png"&gt;&lt;img alt="Trained agent on forked path finds a way through" src="/images/erasmus/gen01_t.png" title="Trained agent on forked path finds a way through" /&gt;&lt;/a&gt;
&lt;a href="/images/erasmus/gen01_t.png"&gt;&lt;img alt="Same agent with the forks reversed fails to find the best route" src="/images/erasmus/gen01_t.png" title="Same agent with the forks reversed fails to find the best route" /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Code&lt;/h3&gt;
&lt;p&gt;MATLAB code for this demo may be found on github: &lt;a href="https://github.com/iank/erasmus"&gt;iank/erasmus&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;References&lt;/h3&gt;
&lt;div class="footnote"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn:rudolph"&gt;
&lt;p&gt;G. Rudolph. Evolutionary search for minimal elements in partially ordered Ô¨Ånite sets. In V. W. Porto, N. Saravanan, D. Waagen, and A. E. Eiben, editors, &lt;em&gt;Evolutionary Programming VII, Proceedings of the 7th Annual Conference on Evolutionary Programming&lt;/em&gt;, pages 345‚Äì353. Springer, Berlin, 1998.&amp;#160;&lt;a class="footnote-backref" href="#fnref:rudolph" rev="footnote" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:zitzler"&gt;
&lt;p&gt;E. Zitzler, K. Deb, and L. Thiele. Comparison of Multiobjective Evolutionary Algorithms: Empirical Results. &lt;em&gt;Evolutionary Computation&lt;/em&gt; 8.2 (2000): 173-195.&amp;#160;&lt;a class="footnote-backref" href="#fnref:zitzler" rev="footnote" title="Jump back to footnote 2 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:montana"&gt;
&lt;p&gt;D. Montana and L. Davis. Training Feedforward Neural Networks Using Genetic Algorithms. &lt;em&gt;IJCAI&lt;/em&gt;, vol. 89 (1989): 762-767&amp;#160;&lt;a class="footnote-backref" href="#fnref:montana" rev="footnote" title="Jump back to footnote 3 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</summary><category term="computer math"></category><category term="genetic algorithm"></category><category term="models"></category><category term="machine learning"></category></entry><entry><title>PCA on X-Plane Images</title><link href="http://blog.iank.org/pca-on-x-plane-images.html" rel="alternate"></link><updated>2013-07-21T20:09:00-04:00</updated><author><name>Ian Kilgore</name></author><id>tag:blog.iank.org,2013-07-21:pca-on-x-plane-images.html</id><summary type="html">&lt;h3&gt;Problem&lt;/h3&gt;
&lt;p&gt;As a demonstration of a multivariate analysis technique I have formulated a classification task:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Given screenshots of a cockpit in the flight simulator &lt;a href="http://www.x-plane.com/"&gt;X-Plane&lt;/a&gt;, discriminate between left and right banking.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;a href="/images/pca/screenshot_49.png"&gt;&lt;img alt="Example Screenshot Indicating Right Bank" src="/images/pca/screenshot_49_thumb.png" title="Example Screenshot Indicating Right Bank" /&gt;&lt;/a&gt;
&lt;a href="/images/pca/screenshot_119.png"&gt;&lt;img alt="Example Screenshot Indicating Left Bank" src="/images/pca/screenshot_119_thumb.png" title="Example Screenshot Indicating Left Bank" /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Method&lt;/h3&gt;
&lt;h4&gt;Data and Preprocessing&lt;/h4&gt;
&lt;p&gt;$$n=101 \text{ screenshots}$$ were taken at various points during simulated left and right turns, then hand-labelled as either 'left' or 'right'. These screenshots are 1180x800 8-bit RGB images, which can be represented using $$1180 \cdot 800 \cdot 3 = 2,832,000 \text{ values}$$&lt;/p&gt;
&lt;p&gt;If we are to use these images as feature vector inputs to a supervised learner, we find that 2.8 million-dimensional vectors are too large for practical applications.&lt;/p&gt;
&lt;p&gt;As an initial step, we may remove some redundancy in these images by converting them to 118x80 grayscale:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;09:44 &amp;lt; ik&amp;gt; ik's principled guide to multivariate analysis: if the data is too big, just throw away a lot of it&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This leaves us with screenshots resembling the following low-resolution grayscale images. These images can be represented as 9440-dimensional feature vectors, which are still rather large.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Example Screenshot Indicating Right Bank" src="/images/pca/right_49.png" title="Example Screenshot Indicating Right Bank" /&gt;
&lt;img alt="Example Screenshot Indicating Left Bank" src="/images/pca/left_119.png" title="Example Screenshot Indicating Left Bank" /&gt;&lt;/p&gt;
&lt;p&gt;It is clear that these images still exhibit much redundancy. The cockpit interior, for instance, is mostly either constant across all images (the cowling and blank space between instruments), or noise (most of the instruments vary between screenshots but are not useful for determining bank direction). The sky is mostly featureless and the ground is noise (we do not care if we are looking at a runway or a pasture). The only element of these images we are interested in is the horizon (and possibly the artificial horizon instrument and the turn coordinator).&lt;/p&gt;
&lt;p&gt;I made this problem easy by selecting only screenshots where the horizon was visible (ie, some sky and some ground was visible in each picture). So the slope of the horizon is a sufficient statistic for our task. (Had this not been the case, we would want to focus on the artificial horizon instrument).&lt;/p&gt;
&lt;p&gt;We can, of course, write some heuristic to extract the important information from these images, but there is a general method.&lt;/p&gt;
&lt;h4&gt;Principal Component Analysis&lt;/h4&gt;
&lt;p&gt;Much has been written about &lt;a href="https://en.wikipedia.org/wiki/Principal_component_analysis"&gt;PCA&lt;/a&gt;, so this section will only summarize the technique as I have implemented it in the solving of this problem. Here, we use PCA for dimensionality reduction: By selecting only the first s principal components, we can transform our d-dimensional data X to a s-dimensional subspace while retaining most of the variance of the data (thereby discarding some correlated variables (ie, redundancy) and noise). Of course, d &amp;gt;&amp;gt; s.&lt;/p&gt;
&lt;p&gt;Given n observations of d-dimensional data X (the values of X are, in this case, pixel intensities represented as integers ranging from 0 to 255):&lt;/p&gt;
&lt;p&gt;$$\mathbf{X}_{n \times d}$$&lt;/p&gt;
&lt;p&gt;We take the mean of each column and subtract from the data:&lt;/p&gt;
&lt;p&gt;\begin{equation}
\mathbf{\Psi} = \frac{1}{n}\sum\limits_{i=1}^n \vec{x}_i
\end{equation}
\begin{equation}
\mathbf{\Phi} = \mathbf{X} - \mathbf{\Psi}
\end{equation}&lt;/p&gt;
&lt;p&gt;A covariance matrix is computed:
\begin{equation}
\mathbf{C} = \mathbf{\Phi}^\top\mathbf{\Phi}
\end{equation}&lt;/p&gt;
&lt;p&gt;Note that this covariance matrix can be very large (d-by-d or, in our case, 9440 by 9440). In practise, &lt;a href="https://en.wikipedia.org/wiki/Principal_component_analysis#The_NIPALS_method"&gt;other methods&lt;/a&gt; are used to find the first few principal components without computing the entire covariance matrix.&lt;/p&gt;
&lt;p&gt;We find the eigenvalues and eigenvectors of the covariance matrix such that:&lt;/p&gt;
&lt;p&gt;\begin{equation}
\mathbf{V}^{-1}\mathbf{C}\mathbf{V} = \mathbf{\Lambda}
\end{equation}&lt;/p&gt;
&lt;p&gt;where V is a matrix of d column vectors corresponding to the d eigenvectors of C, and Œõ is a diagonal matrix with the d corresponding eigenvalues on its diagonal.&lt;/p&gt;
&lt;p&gt;We can think of the high-eigenvalued eigenvectors as modelling the signal subspace in our data, and the low-eigenvalued eigenvectors as modelling the noise subspace. Alternatively we can think of the high-eigenvalued eigenvectors as &lt;em&gt;axes&lt;/em&gt; along which our data has much variance. If we sort the eigenvalues and plot them, we have:&lt;/p&gt;
&lt;p&gt;&lt;img alt="Eigenvalues of Covariance Matrix" src="/images/pca/values.png" title="Eigenvalues of Covariance Matrix" /&gt;&lt;/p&gt;
&lt;p&gt;Note that I have zoomed in on the first fifty or so eigenvalues so as to show some detail. In reality there are 9440 of them. In most applications, the contrast between high values and low values is not nearly so sharp. So we have a good cutoff point, and we see that there are relatively few high eigenvalues, suggesting that the data is mostly correlated.&lt;/p&gt;
&lt;p&gt;While it may be advisable to select a few more, I let s = 2 to allow for visualization. So we take the two highest-eigenvalued eigenvectors and create a matrix which we can use to transform our data:&lt;/p&gt;
&lt;p&gt;\begin{equation}
\mathbf{U}_{d \times 2} = [\begin{array}{cc} \vec{\lambda}_1 &amp;amp; \vec{\lambda}_2 \end{array}]
\end{equation}&lt;/p&gt;
&lt;p&gt;\begin{equation}
\mathbf{U}_{d \times 2} = [\begin{array}{cc} \vec{\lambda}_1 &amp;amp; \vec{\lambda}_2 \end{array}]
\end{equation}&lt;/p&gt;
&lt;p&gt;We may now project our data into this two-dimensional space and plot it:&lt;/p&gt;
&lt;p&gt;\begin{equation}
\mathbf{X}_f = (\mathbf{X} - \mathbf{\Psi})\times\mathbf{U}^\top
\end{equation}&lt;/p&gt;
&lt;p&gt;&lt;img alt="X-Plane screenshots mapped onto two-dimensional space" src="/images/pca/2value.png" title="X-Plane screenshots mapped onto two-dimensional space" /&gt;&lt;/p&gt;
&lt;p&gt;I have plotted data points corresponding to each class ('left', 'right') with different colours. So we see that even with only two principal components we can achieve fairly good separation (even a linear classifier would do well here).&lt;/p&gt;
&lt;h3&gt;Results&lt;/h3&gt;
&lt;p&gt;Returning to our original problem. Given n observations of d-dimensional data X (screenshots) we should like to predict the class labels Y corresponding to 'right' and 'left' bank:&lt;/p&gt;
&lt;p&gt;$$\mathbf{X}_{n \times d}, \; \vec{Y}_n$$&lt;/p&gt;
&lt;p&gt;Using &lt;a href="http://sugiyama-www.cs.titech.ac.jp/~sugi/2010/LSPC.pdf"&gt;LSPC&lt;/a&gt;, a fast non-linear supervised classifier, we may attempt to separate this data. I used 75 screenshots to train, and withheld 26 for testing.&lt;/p&gt;
&lt;p&gt;By training LSPC on these 75 screenshots (projected into two dimensions), we find functions which estimate the posterior probability that a screenshot is a member of class Y = 1 or 2.&lt;/p&gt;
&lt;p&gt;$$\text{find } \hat{P}(Y=1|x_i); \hat{P}(Y=2|x_i)$$&lt;/p&gt;
&lt;p&gt;The estimated posterior probabilities are plotted as a heatmap over the two-dimensional data (this plot actually shows the training data, not the withheld test data). We make our decision at P(Y|x) = 0.5&lt;/p&gt;
&lt;p&gt;&lt;img alt="Estimated posterior probability (decision boundary = 0.5)" src="/images/pca/boundary.png" title="&amp;quot;Estimated posterior probability (decisioun boundary = 0.5" /&gt;&lt;/p&gt;
&lt;p&gt;Using this model we estimate the class label for our 26 withheld examples and find that it correctly classified 25 of the 26 screenshots (corresponding to an error rate of about 3.85%).&lt;/p&gt;</summary><category term="computer math"></category><category term="PCA"></category><category term="machine learning"></category><category term="LSPC"></category></entry></feed>