<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Ian Kilgore's blog</title><link href="http://blog.iank.org/" rel="alternate"></link><link href="http://blog.iank.org/feeds/computer-vision.atom.xml" rel="self"></link><id>http://blog.iank.org/</id><updated>2015-06-04T17:05:00-04:00</updated><entry><title>Playing Capitals with OpenCV and Python</title><link href="http://blog.iank.org/playing-capitals-with-opencv-and-python.html" rel="alternate"></link><updated>2015-06-04T17:05:00-04:00</updated><author><name>Ian Kilgore</name></author><id>tag:blog.iank.org,2015-06-04:playing-capitals-with-opencv-and-python.html</id><summary type="html">&lt;p&gt;On Monday evening I had dinner with my friend Alysia Promislow, who showed me the game &lt;a href="https://itunes.apple.com/us/app/capitals-free-word-battle/id968456900"&gt;Capitals&lt;/a&gt; and suggested it might be interesting to play it programmatically.&lt;/p&gt;
&lt;p&gt;I spent the last 18-20 working hours doing that. &lt;a href="https://github.com/iank/capitals-solver"&gt;(Github link with code and example images)&lt;/a&gt;. Hopefully it's redundant to mention that I've done this because it let me geek out on a goofy computational problem, not because I'm interested in cheating at a phone game&lt;sup id="fnref:game"&gt;&lt;a class="footnote-ref" href="#fn:game" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;p&gt;90% of getting anything done is knowing things exist, and the first two things I thought about after seeing the game is:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The low-complexity shapes and clear separation make it amenable to some simple computer vision techniques &lt;a href="http://iank.org/rmbc.html"&gt;that I have employed before&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Hexagonal coordinate systems are a thing&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Decoding game state from a screenshot&lt;/h3&gt;
&lt;p&gt;I spent Tuesday afternoon writing a Python script to decode the game state from a screenshot, using &lt;a href="http://opencv.org"&gt;OpenCV&lt;/a&gt; and &lt;a href="https://code.google.com/p/tesseract-ocr/"&gt;Tesseract&lt;/a&gt; OCR engine.&lt;/p&gt;
&lt;p&gt;It takes an RGB image, such as:&lt;/p&gt;
&lt;p&gt;&lt;img alt="RGB screenshot" src="/images/capitals_ex.png" /&gt;&lt;/p&gt;
&lt;p&gt;Next, it greyscales and runs the &lt;a href="http://docs.opencv.org/modules/imgproc/doc/feature_detection.html?highlight=canny#canny"&gt;Canny edge detector&lt;/a&gt; to produce:&lt;/p&gt;
&lt;p&gt;&lt;img alt="Edge-detected" src="/images/capital_ex_canny.png" /&gt;&lt;/p&gt;
&lt;p&gt;To detect and isolate hexagons, I follow a &lt;a href="https://github.com/Itseez/opencv/blob/master/samples/cpp/squares.cpp"&gt;similar approach&lt;/a&gt; as the OpenCV example &lt;a href="https://github.com/Itseez/opencv/blob/master/samples/cpp/squares.cpp"&gt;squares.cpp&lt;/a&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://docs.opencv.org/modules/imgproc/doc/structural_analysis_and_shape_descriptors.html#findcontours"&gt;Find contours&lt;/a&gt; in the edge-detected image&lt;/li&gt;
&lt;li&gt;Using the &lt;a href="http://docs.opencv.org/modules/imgproc/doc/structural_analysis_and_shape_descriptors.html#approxpolydp"&gt;Ramer-Douglas-Peucker algorithm&lt;/a&gt;, attempt to approximate polygonal curves as lower-degree polygons&lt;/li&gt;
&lt;li&gt;Take all detected six-sided convex polygons having a certain minimum area&lt;/li&gt;
&lt;li&gt;It is also useful to check for approximately 120 degree angles, but it's not necessary for this application.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Taking only the contours which meet the criteria, we have:&lt;/p&gt;
&lt;p&gt;&lt;img alt="Isolated contours" src="/images/capital_ex_contour_mask.png" /&gt;&lt;/p&gt;
&lt;p&gt;Iterating through these I use a series of increasingly-dubious heuristics to classify the hexagons:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Take the average RGB value of each hexagon:&lt;ul&gt;
&lt;li&gt;Hexagons that are much more red than blue belong to red player&lt;/li&gt;
&lt;li&gt;Hexagons that are much more blue than red belong to blue player&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Hexagons that are mostly white belong to neither, and I determine the letter by passing the masked image to &lt;a href="https://code.google.com/p/tesseract-ocr/"&gt;Tesseract&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Rather than searching for the icon that denotes the capital, I count white pixels in each red and blue hexagon. e.g., a hexagon that is mostly red but has a significant white space is the red capital.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Now I can find possible words, but only some of them are useful. Also, there are typically thousands of candidates. In order to consider word connectedness, I find the centroids of each hexagon and estimate their position on a hexagonal grid. I've encountered hexagonal coordinate systems in &lt;a href="http://en.wikipedia.org/wiki/File:CellTowersAtCorners.gif"&gt;wireless communications&lt;/a&gt;, but I didn't know about the &lt;a href="http://keekerdc.com/2011/03/hexagon-grids-coordinate-systems-and-distance-calculations/"&gt;Q*bert equivalence&lt;/a&gt;. (There's also a great &lt;a href="http://www.redblobgames.com/grids/hexagons/"&gt;animation here&lt;/a&gt;, search for "convert to cube coordinates").&lt;/p&gt;
&lt;p&gt;Here is &lt;a href="/images/hex_derivation.jpg"&gt;my derivation&lt;/a&gt; for the mapping from rectangular to hexagonal coordinates, given the hexagonal side length (estimated from detected contours) and an origin (arbitrarily chosen, it only needs to be relatively consistent). Also there is a spacing between hexagons in this game, which I have denoted 'b'.&lt;/p&gt;
&lt;h3&gt;Finding useful moves from game state&lt;/h3&gt;
&lt;p&gt;On Wednesday afternoon I wrote code to score candidate words. It is trivial to find all possible words, given a list of letters and a dictionary. However as mentioned above, a word's length is not the most useful indicator of its fitness as a move in the game. For a played word, letters that are connected to the player's territory will become a part of it. Isolated letters can be used to construct a word, but will not become part of player territory. Also, if connected tiles in a word are adjacent to enemy territory, the opposing player will lose that territory. Finally, it is frequently possible to create the same word using differently-located tiles, and this has a strategic impact (so words are not unique, combinations of tiles are).&lt;/p&gt;
&lt;p&gt;I score candidate word choices by counting the length of the word, number of tiles it will add to player territory, number of tiles it will remove from enemy territory, and whether one of those tiles is the enemy capital (thus granting the player an extra turn, usually allowing a win).&lt;sup id="fnref:vars"&gt;&lt;a class="footnote-ref" href="#fn:vars" rel="footnote"&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;I determine connectedness of a candidate word by considering the list of all currently-owned tiles. For each of these, I check each of the six adjacent tiles. If it is part of the candidate word, add to the list of owned tiles, and note that I've visited it. Iterate until I am done with the list of owned tiles. The result is a list of all connected tiles in the candidate word, which I then use to check enemy player adjacency. For each candidate word a vector of these score variables is generated, and I do some rudimentary sorting to produce a suggestion, such as this suggestion for the red player:&lt;sup id="fnref:word"&gt;&lt;a class="footnote-ref" href="#fn:word" rel="footnote"&gt;3&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;word&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;    &lt;span class="n"&gt;retrenching&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;territory&lt;/span&gt; &lt;span class="n"&gt;gain&lt;/span&gt;   &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;enemy&lt;/span&gt; &lt;span class="n"&gt;territory&lt;/span&gt; &lt;span class="n"&gt;loss&lt;/span&gt;    &lt;span class="mi"&gt;6&lt;/span&gt;
&lt;span class="n"&gt;word&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;    &lt;span class="n"&gt;incremented&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;territory&lt;/span&gt; &lt;span class="n"&gt;gain&lt;/span&gt;   &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;enemy&lt;/span&gt; &lt;span class="n"&gt;territory&lt;/span&gt; &lt;span class="n"&gt;loss&lt;/span&gt;    &lt;span class="mi"&gt;5&lt;/span&gt;
&lt;span class="n"&gt;word&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;     &lt;span class="n"&gt;converting&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;territory&lt;/span&gt; &lt;span class="n"&gt;gain&lt;/span&gt;   &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;enemy&lt;/span&gt; &lt;span class="n"&gt;territory&lt;/span&gt; &lt;span class="n"&gt;loss&lt;/span&gt;    &lt;span class="mi"&gt;5&lt;/span&gt;
&lt;span class="n"&gt;word&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;     &lt;span class="n"&gt;converting&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;territory&lt;/span&gt; &lt;span class="n"&gt;gain&lt;/span&gt;   &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;enemy&lt;/span&gt; &lt;span class="n"&gt;territory&lt;/span&gt; &lt;span class="n"&gt;loss&lt;/span&gt;    &lt;span class="mi"&gt;5&lt;/span&gt;
&lt;span class="n"&gt;word&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;     &lt;span class="n"&gt;monteverdi&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;territory&lt;/span&gt; &lt;span class="n"&gt;gain&lt;/span&gt;   &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;enemy&lt;/span&gt; &lt;span class="n"&gt;territory&lt;/span&gt; &lt;span class="n"&gt;loss&lt;/span&gt;    &lt;span class="mi"&gt;5&lt;/span&gt;
&lt;span class="n"&gt;word&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;     &lt;span class="n"&gt;reentering&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;territory&lt;/span&gt; &lt;span class="n"&gt;gain&lt;/span&gt;    &lt;span class="mi"&gt;9&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;enemy&lt;/span&gt; &lt;span class="n"&gt;territory&lt;/span&gt; &lt;span class="n"&gt;loss&lt;/span&gt;    &lt;span class="mi"&gt;6&lt;/span&gt;
&lt;span class="n"&gt;word&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;    &lt;span class="n"&gt;retrenching&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;territory&lt;/span&gt; &lt;span class="n"&gt;gain&lt;/span&gt;    &lt;span class="mi"&gt;9&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;enemy&lt;/span&gt; &lt;span class="n"&gt;territory&lt;/span&gt; &lt;span class="n"&gt;loss&lt;/span&gt;    &lt;span class="mi"&gt;6&lt;/span&gt;
&lt;span class="n"&gt;word&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;    &lt;span class="n"&gt;retrenching&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;territory&lt;/span&gt; &lt;span class="n"&gt;gain&lt;/span&gt;    &lt;span class="mi"&gt;9&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;enemy&lt;/span&gt; &lt;span class="n"&gt;territory&lt;/span&gt; &lt;span class="n"&gt;loss&lt;/span&gt;    &lt;span class="mi"&gt;6&lt;/span&gt;
&lt;span class="n"&gt;word&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;      &lt;span class="n"&gt;comintern&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;territory&lt;/span&gt; &lt;span class="n"&gt;gain&lt;/span&gt;    &lt;span class="mi"&gt;9&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;enemy&lt;/span&gt; &lt;span class="n"&gt;territory&lt;/span&gt; &lt;span class="n"&gt;loss&lt;/span&gt;    &lt;span class="mi"&gt;5&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="Suggestion" src="/images/capitals_ex_suggestion.png" /&gt;&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn:game"&gt;
&lt;p&gt;I'm terrible at this game, though. Scrabble too.&amp;#160;&lt;a class="footnote-backref" href="#fnref:game" rev="footnote" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:vars"&gt;
&lt;p&gt;There are other variables to consider such as protecting one's own capital, avoiding being the player to bridge the gap, and positioning (ie gaining tiles in the center is more important than gaining isolated tiles which have no path to the enemy player). My thought is to construct a feature vector with these variables, weight them by some vector $\alpha$, and use a genetic algorithm to pit several of these automated players against each other in order to learn $\alpha$. I may never get around to it.&amp;#160;&lt;a class="footnote-backref" href="#fnref:vars" rev="footnote" title="Jump back to footnote 2 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:word"&gt;
&lt;p&gt;Although here I'd rather play "incremented" in order to gain the 'm' tile, protecting the red capital.&amp;#160;&lt;a class="footnote-backref" href="#fnref:word" rev="footnote" title="Jump back to footnote 3 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</summary><category term="computer math"></category><category term="hexagons"></category><category term="capitals"></category></entry><entry><title>Breaking reddit.com's CAPTCHA</title><link href="http://blog.iank.org/breaking-redditcoms-captcha.html" rel="alternate"></link><updated>2013-07-26T18:56:00-04:00</updated><author><name>Ian Kilgore</name></author><id>tag:blog.iank.org,2013-07-26:breaking-redditcoms-captcha.html</id><summary type="html">&lt;h3&gt;Problem&lt;/h3&gt;
&lt;p&gt;&lt;a href="http://en.wikipedia.org/wiki/CAPTCHA"&gt;CAPTCHAs&lt;/a&gt; are "a type of challenge-response test used in computing to determine whether or not the user is human." They are designed to be relatively easy for humans to solve, and difficult to automate. Some of them are very good, but the CAPTCHA system employed by &lt;a href="http://reddit.com/"&gt;reddit.com&lt;/a&gt; is, as of 2013-07-26, not state-of-the-art. Below, I attempt to solve this CAPTCHA automatically.&lt;/p&gt;
&lt;p&gt;A common approach to solving this kind of problem is to divide the problem into two parts: segmentation and recognition. First we attempt to divide the CAPTCHA into its single-character parts. Second, we use a classifier to match segments with labels. It has been shown [&lt;sup id="fnref:chellapilla"&gt;&lt;a class="footnote-ref" href="#fn:chellapilla" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt;] that automatic classifiers perform well on single-letter images, and that segmentation is the more difficult problem.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Example CAPTCHA (1)" src="/images/rmbc/ex1.png" title="Example CAPTCHA (1)" /&gt;
&lt;img alt="Example CAPTCHA (2)" src="/images/rmbc/ex2.png" title="Example CAPTCHA (2)" /&gt;&lt;/p&gt;
&lt;h3&gt;Method&lt;/h3&gt;
&lt;h4&gt;Data&lt;/h4&gt;
&lt;p&gt;One thousand CAPTCHA images were collected. Each image is 8-bit 120x50 grayscale. All images have a six-character uppercase alphabetic solution, e.g. JVYKVC and TEMIWX, above. Half of the data was held out as a validation set, and hand-labelled with the correct solution by a human volunteer, Adrian C. Only 489 of these images were human-readable. We use the remaining five hundred images for segmentation.&lt;/p&gt;
&lt;h4&gt;Segmentation&lt;/h4&gt;
&lt;p&gt;&lt;a href="/images/rmbc/segment4.png"&gt;&lt;img alt="Segmented CAPTCHA" src="/images/rmbc/segment4_t.png" title="Segmented CAPTCHA" /&gt;&lt;/a&gt;
&lt;a href="/images/rmbc/segment5.png"&gt;&lt;img alt="Segmented CAPTCHA" src="/images/rmbc/segment5_t.png" title="Segmented CAPTCHA" /&gt;&lt;/a&gt;
&lt;a href="/images/rmbc/segment6.png"&gt;&lt;img alt="Segmented CAPTCHA" src="/images/rmbc/segment6_t.png" title="Segmented CAPTCHA" /&gt;&lt;/a&gt;
&lt;a href="/images/rmbc/segment7.png"&gt;&lt;img alt="Segmented CAPTCHA" src="/images/rmbc/segment7_t.png" title="Segmented CAPTCHA" /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Reddit's CAPTCHA algorithm employs a distorted grid which intercepts and joins each character in an attempt to prevent easy segmentation. However, these images are 8-bit rather than binary, and the anti-segmentation feature is rendered at a lower intensity than the letters themselves. This is the key weakness in this CAPTCHA algorithm.&lt;/p&gt;
&lt;p&gt;By thresholding these images at a pixel value of 150 (chosen empirically), we remove much of this anti-segmentation grid, leaving noise. This also degrades the letters themselves at the edges, however, which leads to difficulty later on in the recognition phase. &lt;a href="http://en.wikipedia.org/wiki/Connected-component_labeling"&gt;Connected components&lt;/a&gt; are then labelled, and components with fewer than twenty pixels (again chosen empirically) are discarded.&lt;/p&gt;
&lt;p&gt;This process is shown visually in the four images above. Note that not every segmentation attempt is successful. See above a case above in which three letters remained joined by a particularly large remnant of a grid line. In some cases not pictured, letters are over-segmented, e.g. a 'W' is split into two 'V's, or an 'N' is incorrectly segmented at one of its vertices. Also, some noise components, especially at the borders, are still quite large and remain in the image. We deal with these in the next step.&lt;/p&gt;
&lt;h4&gt;Recognition&lt;/h4&gt;
&lt;p&gt;At this point we have done a reasonable, though not optimal job of segmenting these images. From the original five hundred training images, we now have 3,244 individual components, which I labelled by hand.&lt;/p&gt;
&lt;p&gt;Some of these components are letters, but some are incorrectly-segmented multiple-letter sequences, half-letters, or pure noise. I trained a classifier, LSPC [&lt;sup id="fnref:sugiyama"&gt;&lt;a class="footnote-ref" href="#fn:sugiyama" rel="footnote"&gt;2&lt;/a&gt;&lt;/sup&gt;] to distinguish four classes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Correctly-segmented letters&lt;/li&gt;
&lt;li&gt;Two characters incorrectly combined into one&lt;/li&gt;
&lt;li&gt;Three characters incorrectly combined into one&lt;/li&gt;
&lt;li&gt;Noise (non-letters, partial letters)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This classifier performs well, with a 3.58% misclassification rate (compared to a 16.77% misclassification rate if we simply always guess 'letter', the most probable case). In theory this classifier would allow us to attempt to fix the two- and three-character cases. In this example, I discard all non-letter components and proceed to the second classifier.&lt;/p&gt;
&lt;p&gt;The second classifier attempts to categorize an input into one of twenty six classes (corresponding to the letters of the alphabet). After trying several versions of this classifier, I achieved the best misclassification error (10.14%), with a stacked autoencoder generating features for each image which were then fed to LSPC. In practice I actually used simple LSPC on raw pixel features (template matching), which achieved a misclassification error of 12.76%. I found that when analyzed in context of the entire system (segmentation+recognition), this classifier slightly outperforms the deep autoencoder.&lt;/p&gt;
&lt;p&gt;This classifier assigns probability values to its guesses, so in the event that an image appears to have more than six segments, we take the most likely six. In the event that our segmentation process only finds five or fewer unique components, we abstain from guessing a solution (in practice, most interfaces have some feature to allow a user to request a new CAPTCHA, as they are occasionally unreadable for humans).&lt;/p&gt;
&lt;h3&gt;Results&lt;/h3&gt;
&lt;p&gt;On the held-out validation set of 489 images, this system guessed only 5.73% (28) correctly. However, we knew a priori (because segmentation had failed), that we could not guess a number of images. If we abstain in those cases and request a new CAPTCHA, the success rate rises to an even 10%.&lt;/p&gt;
&lt;p&gt;In a scenario where we have a limited number of incorrect attempts, but may request new CAPTCHAs without guessing, it is possible to achieve a success rate of 29% by only guessing on the 3% of the images we are most confident about.&lt;/p&gt;
&lt;p&gt;Raw output of this test run is &lt;a href="/images/rmbc/log.txt"&gt;available&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;References&lt;/h3&gt;
&lt;div class="footnote"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn:chellapilla"&gt;
&lt;p&gt;K. Chellapilla, K. Larson, P. Simard, and M. Czerwinski, "Computers Beat Humans at Single Character Recognition in Reading Based Human Interaction Proofs (HIPs)," in &lt;em&gt;Proceedings of the Third Conference on E-Mail and AntiSpam&lt;/em&gt;, 2005.&amp;#160;&lt;a class="footnote-backref" href="#fnref:chellapilla" rev="footnote" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:sugiyama"&gt;
&lt;p&gt;M. Sugiyama. "Superfast-Trainable Multi-Class Probabilistic Classifier by Least-Squares Posterior Fitting". &lt;em&gt;IEICE Transactions on Information and Systems&lt;/em&gt;, E93-D(10), pp. 2690â€“2701, 2010.&amp;#160;&lt;a class="footnote-backref" href="#fnref:sugiyama" rev="footnote" title="Jump back to footnote 2 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</summary><category term="computer math"></category><category term="OpenCV"></category><category term="CAPTCHA"></category><category term="LSPC"></category></entry></feed>