<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Ian Kilgore's blog</title><link href="http://blog.iank.org/" rel="alternate"></link><link href="http://blog.iank.org/feeds/ian-kilgore.atom.xml" rel="self"></link><id>http://blog.iank.org/</id><updated>2015-07-27T20:57:00-04:00</updated><entry><title>Reflashing NodeMCU devkit v2.0 on OS X</title><link href="http://blog.iank.org/reflashing-nodemcu-devkit-v20-on-os-x.html" rel="alternate"></link><updated>2015-07-27T20:57:00-04:00</updated><author><name>Ian Kilgore</name></author><id>tag:blog.iank.org,2015-07-27:reflashing-nodemcu-devkit-v20-on-os-x.html</id><summary type="html">&lt;p&gt;&lt;img alt="NodeMCU v2.0" src="/images/206671f3b9855ed25d2ad8db98dd8e49.image.530x397.jpg" /&gt;&lt;/p&gt;
&lt;p&gt;This took me a long time to find between the different NodeMCU devkit versions, nodemcu's Delphi(??) windows-only flashing tool, some kind of competing python thing that comes in a .rar file but might not be windows-only anymore and doesn't work anyway, people writing Arduino firmware to the ESP8266, and the fact that the main communication medium in 2015 for this sort of thing is somehow still web forums.&lt;/p&gt;
&lt;p&gt;So here it is. Download &lt;a href="https://github.com/themadinventor/esptool"&gt;esptool&lt;/a&gt; and find nodemcu_float_0.9.6-dev_20150704.bin&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;./esptool.py --port /dev/tty.SLAB_USBtoUART write_flash \
    -fm dio -fs 32m 0x00000 nodemcu_float_0.9.6-dev_20150704.bin
&lt;/pre&gt;&lt;/div&gt;</summary><category term="NodeMCU"></category><category term="lua"></category><category term="ESP8266"></category><category term="hardware"></category></entry><entry><title>Reconstructing phase space and estimating maximal Lyapunov exponent from experimental time series</title><link href="http://blog.iank.org/reconstructing-phase-space-and-estimating-maximal-lyapunov-exponent-from-experimental-time-series.html" rel="alternate"></link><updated>2015-07-26T02:11:00-04:00</updated><author><name>Ian Kilgore</name></author><id>tag:blog.iank.org,2015-07-26:reconstructing-phase-space-and-estimating-maximal-lyapunov-exponent-from-experimental-time-series.html</id><summary type="html">&lt;h3&gt;Background&lt;/h3&gt;
&lt;p&gt;Last week I took some measurements of a system for my research and needed to show if the system was &lt;a href="https://en.wikipedia.org/wiki/Chaos_theory"&gt;chaotic&lt;/a&gt;. The measured data was a 1-dimensional time series from a &lt;a href="http://www.polytec.com/us/products/vibration-sensors/single-point-vibrometers/complete-systems/pdv-100-portable-digital-vibrometer/"&gt;Laser Doppler Vibrometer (LDV)&lt;/a&gt;. In order to show the system was chaotic I reconstructed state space using the method of delays, and estimated the maximal Lyapunov exponent of the system.&lt;/p&gt;
&lt;p&gt;Continuous&lt;sup id="fnref:discrete"&gt;&lt;a class="footnote-ref" href="#fn:discrete" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt; systems must be at least three-dimensional in order to exhibit chaos, but it's possible to reconstruct higher-dimensional state space from a 1-dimensional time series[&lt;sup id="fnref:packard"&gt;&lt;a class="footnote-ref" href="#fn:packard" rel="footnote"&gt;2&lt;/a&gt;&lt;/sup&gt;] by lagging the data, e.g. taking $x(t)$ and turning it into a series of vectors $[ x(t), x(t+T), ..., x(t+nT) ]$. There are a variety of methods for determining the constant $T$, and the embedding dimension (sometimes called $m$), and there is no clear best method. Fortunately these systems are somewhat forgiving.&lt;/p&gt;
&lt;h3&gt;Method of delays&lt;/h3&gt;
&lt;p&gt;In my experiment I generated a time series based on the &lt;a href="https://en.wikipedia.org/wiki/Lorenz_system"&gt;Lorenz system&lt;/a&gt; by integrating the Lorenz equations with one of MATLAB's Runge-Kutta ODE solvers (code &lt;a href="https://github.com/iank/lyapunov_estimation/blob/master/lorenz_ode.m"&gt;lorenz_ode.m&lt;/a&gt; &lt;a href="https://github.com/iank/lyapunov_estimation/blob/master/gen_chaos.m"&gt;gen_chaos.m&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;Plotting $x$, $y$, and $z$ over $t=[0,100]$ produces a nice Lorenz attractor&lt;/p&gt;
&lt;p&gt;&lt;img alt="Lorenz attractor" src="/images/chaos/lorenz_attractor.png" /&gt;&lt;/p&gt;
&lt;p&gt;I took the $z$ variable (&lt;a href="https://raw.githubusercontent.com/iank/lyapunov_estimation/master/lorenz_z.txt"&gt;lorenz_z.txt&lt;/a&gt;) and used the method of delays to reproduce the attractor. I just guessed at a lag value. I'll demonstrate a better method below.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Reproduced attractor" src="/images/chaos/lorenz_ts_reconstruction.png" /&gt;&lt;/p&gt;
&lt;p&gt;We see that it is warped, but the underlying structure is there. For my experiment I generated a 100 Hz sinusoidal tone and added a scaled (1/50) and sped-up (100x) version of the Lorenz time series generated above. One second of data (at 204,800 samples/sec) was sent to a DAC, amplified, and used to drive a speaker coil. The vibration of the coil was measured using an LDV, producing a &lt;a href="https://raw.githubusercontent.com/iank/lyapunov_estimation/master/lorenz_ldv.csv"&gt;time series&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Time series LDV data" src="/images/chaos/lorenz_ldv.png" /&gt;&lt;/p&gt;
&lt;h3&gt;Determining lag&lt;/h3&gt;
&lt;p&gt;Andrew Fraser and Harry Swinney[&lt;sup id="fnref:fraser"&gt;&lt;a class="footnote-ref" href="#fn:fraser" rel="footnote"&gt;3&lt;/a&gt;&lt;/sup&gt;] give a method for determining appropriate lag for the method of delays using mutual information&lt;sup id="fnref:memory"&gt;&lt;a class="footnote-ref" href="#fn:memory" rel="footnote"&gt;4&lt;/a&gt;&lt;/sup&gt;. &lt;a href="http://www.physics.emory.edu/faculty/weeks/"&gt;Dr. Eric Weeks&lt;/a&gt; wrote a &lt;a href="http://www.physics.emory.edu/faculty/weeks//software/minfo.html"&gt;C program&lt;/a&gt; which implements their method, and you can &lt;a href="http://www.physics.emory.edu/faculty/weeks//research/tseries3.html"&gt;read more about it on his website&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Running this program on my LDV data produced &lt;a href="https://raw.githubusercontent.com/iank/lyapunov_estimation/master/lorenz_ldv.mi.csv"&gt;this signal&lt;/a&gt;, plotted below. From this we can see that the first minimum is around $T=770$ (discrete steps, or $770 / Fs = 3.76$ milliseconds).&lt;/p&gt;
&lt;p&gt;&lt;img alt="I(T) for LDV data" src="/images/chaos/lorenz_ldv_mi.png" /&gt;&lt;/p&gt;
&lt;p&gt;I reconstruct the attractor in MATLAB using this delay:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nt"&gt;lz&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nt"&gt;csvread&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;lorenz_ldv.csv&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
&lt;span class="nt"&gt;N&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nt"&gt;length&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nt"&gt;lz&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
&lt;span class="nt"&gt;T&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nt"&gt;770&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
&lt;span class="nt"&gt;X&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="cp"&gt;[&lt;/span&gt;&lt;span class="nx"&gt;lz&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="nx"&gt;N&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="nx"&gt;T&lt;/span&gt;&lt;span class="p"&gt;)),&lt;/span&gt; &lt;span class="nx"&gt;lz&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="nx"&gt;N&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="nx"&gt;T&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="nx"&gt;T&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="nx"&gt;lz&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="nx"&gt;N&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="nx"&gt;T&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="nx"&gt;T&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="cp"&gt;]&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
&lt;span class="nt"&gt;X&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nt"&gt;X&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nt"&gt;1&lt;/span&gt;&lt;span class="nd"&gt;:100000&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="o"&gt;:);&lt;/span&gt;  &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="nt"&gt;take&lt;/span&gt; &lt;span class="nt"&gt;first&lt;/span&gt; &lt;span class="o"&gt;~&lt;/span&gt;&lt;span class="nt"&gt;half&lt;/span&gt; &lt;span class="nt"&gt;of&lt;/span&gt; &lt;span class="nt"&gt;data&lt;/span&gt; &lt;span class="nt"&gt;so&lt;/span&gt; &lt;span class="nt"&gt;the&lt;/span&gt; &lt;span class="nt"&gt;plot&lt;/span&gt; &lt;span class="nt"&gt;isn&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;t too dense&lt;/span&gt;
&lt;span class="s1"&gt;plot(X(:,1), X(:,2));&lt;/span&gt;
&lt;span class="s1"&gt;title(&amp;#39;&lt;/span&gt;&lt;span class="nt"&gt;Reconstructed&lt;/span&gt; &lt;span class="nt"&gt;attractor&lt;/span&gt; &lt;span class="nt"&gt;from&lt;/span&gt; &lt;span class="nt"&gt;LDV&lt;/span&gt; &lt;span class="nt"&gt;data&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;);&lt;/span&gt;
&lt;span class="s1"&gt;xlabel(&amp;#39;&lt;/span&gt;&lt;span class="nt"&gt;x&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nt"&gt;t&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;); ylabel(&amp;#39;&lt;/span&gt;&lt;span class="nt"&gt;x&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nt"&gt;t&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="nt"&gt;770&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="Reconstructed attractor from LDV data" src="/images/chaos/lorenz_ldv_attractor.png" /&gt;&lt;/p&gt;
&lt;p&gt;This does not look like the Lorenz attractor because the system is dominated by the 100 Hz carrier. It may be possible to get a better-looking reconstruction by taking the envelope of the signal. Zooming, we see dense orbits&lt;sup id="fnref:control"&gt;&lt;a class="footnote-ref" href="#fn:control" rel="footnote"&gt;5&lt;/a&gt;&lt;/sup&gt;:&lt;/p&gt;
&lt;p&gt;&lt;img alt="Reconstructed attractor from LDV data" src="/images/chaos/lorenz_ldv_attractor_zoom.png" /&gt;&lt;/p&gt;
&lt;h3&gt;Estimation of MLE&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://en.wikipedia.org/wiki/Lyapunov_exponent"&gt;Lyapunov exponents&lt;/a&gt; describe how a system expands and contracts in phase space. There is a spectrum of exponents but the maximal Lyapunov exponent (MLE, often written $\lambda_1$) characterizes the system. One of the features of chaos is exponential divergence (sensitivity to initial conditions). Two trajectories, initially arbitrarily close to each other, will diverge exponentially in phase space. The existence of a positive Lyapunov exponent is good evidence for chaos. It is also an indication of the long-term predictibility of a system: it may be specified in &lt;a href="https://en.wikipedia.org/wiki/Nat_(unit)"&gt;nats&lt;/a&gt; per second (or bits or digits), giving the amount of time it takes for uncertainty in a system to increase by a factor of $e$ (or 2 or 10). Note that there must be &lt;em&gt;exponential&lt;/em&gt; divergence for this analysis to be meaningful.&lt;/p&gt;
&lt;p&gt;If differential equations for a system are known, it may be possible to solve for $\lambda_1$. Otherwise, it can be estimated by solving the system numerically, as in [&lt;sup id="fnref:benettin"&gt;&lt;a class="footnote-ref" href="#fn:benettin" rel="footnote"&gt;6&lt;/a&gt;&lt;/sup&gt;]: Integrate the system for two nearby initial conditions and watch how the trajectories diverge. Renormalization is necessary as most systems are bounded (two points can only be so far away from each other in phase space).&lt;/p&gt;
&lt;p&gt;In my case, I have a small amount of data (204800 samples), and only one trajectory in phase space. Rosenstein, et. al. &lt;sup id="fnref:rosenstein"&gt;&lt;a class="footnote-ref" href="#fn:rosenstein" rel="footnote"&gt;7&lt;/a&gt;&lt;/sup&gt; present a method for estimating $\lambda_1$ in this case:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Reconstruct the attractor using the method of delays (I use an embedding dimension of $m=10$)&lt;/li&gt;
&lt;li&gt;For each point $j$:&lt;ul&gt;
&lt;li&gt;Find that point's nearest neighbor with the constraint that it must have at least one mean period of temporal separation. The temporal separation constraint allows us to treat our single trajectory as a collection of trajectories having separate evolutions.&lt;/li&gt;
&lt;li&gt;Follow the evolution of both points, calculating the distance $d_j(i)$ between them with respect to time step $i$.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Take the average over all points $j$: $d(i) = \mathrm{mean}(d_j(i))$&lt;/li&gt;
&lt;li&gt;Plot $ln(d(i))$. A straight line here indicates exponential divergence (there will likely be two regions, an initial exponential divergence and then a flat portion. This happens when phase space is bounded and there is a maximum distance, as discussed above).&lt;/li&gt;
&lt;li&gt;Fit a line to $ln(d(i))$.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I've &lt;a href="https://github.com/iank/lyapunov_estimation/blob/master/rosenstein.m"&gt;implemented this algorithm in MATLAB&lt;/a&gt;.&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nt"&gt;di&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nt"&gt;rosenstein&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nt"&gt;lz&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="nt"&gt;770&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
&lt;span class="nt"&gt;Fs&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nt"&gt;204800&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
&lt;span class="nt"&gt;figure&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
&lt;span class="nt"&gt;plot&lt;/span&gt;&lt;span class="o"&gt;((&lt;/span&gt;&lt;span class="nt"&gt;1&lt;/span&gt;&lt;span class="nd"&gt;:length&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nt"&gt;di&lt;/span&gt;&lt;span class="o"&gt;))&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="nt"&gt;Fs&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="nt"&gt;log&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nt"&gt;di&lt;/span&gt;&lt;span class="o"&gt;));&lt;/span&gt;
&lt;span class="nt"&gt;title&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Divergence for LDV data - Average distance between nearest neighbors&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
&lt;span class="nt"&gt;xlabel&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Lag (s)&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
&lt;span class="nt"&gt;ylabel&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;ln(d_j(i))&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;

&lt;span class="o"&gt;%%&lt;/span&gt; &lt;span class="nt"&gt;Fit&lt;/span&gt; &lt;span class="nt"&gt;line&lt;/span&gt;
&lt;span class="nt"&gt;x1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nt"&gt;1&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
&lt;span class="nt"&gt;x2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nt"&gt;6643&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
&lt;span class="nt"&gt;p&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nt"&gt;polyfit&lt;/span&gt;&lt;span class="o"&gt;((&lt;/span&gt;&lt;span class="nt"&gt;x1&lt;/span&gt;&lt;span class="nd"&gt;:x2&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;/Fs, log(di(x1:x2)),1);&lt;/span&gt;
&lt;span class="s1"&gt;h = refline(p);&lt;/span&gt;
&lt;span class="s1"&gt;set(h, &amp;#39;&lt;/span&gt;&lt;span class="nt"&gt;LineStyle&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;, &amp;#39;&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;);&lt;/span&gt;
&lt;span class="s1"&gt;text(0.04, 3.4, sprintf(&amp;#39;&lt;/span&gt;&lt;span class="nt"&gt;slope&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="nc"&gt;.2f&lt;/span&gt; &lt;span class="nt"&gt;nats&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nt"&gt;sec&lt;/span&gt;&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="nt"&gt;p&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nt"&gt;1&lt;/span&gt;&lt;span class="o"&gt;)));&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="Divergence of LDV data" src="/images/chaos/lorenz_ldv_divergence.png" /&gt;&lt;/p&gt;
&lt;h3&gt;Sanity check&lt;/h3&gt;
&lt;p&gt;Is this a reasonable value for our system? I used this method on the original, computed&lt;sup id="fnref:computed"&gt;&lt;a class="footnote-ref" href="#fn:computed" rel="footnote"&gt;8&lt;/a&gt;&lt;/sup&gt; Lorenz data ($[x(t), y(t), z(t)]$) and the computed time series $[z(t), z(t+T), ..., z(t+9T)]$ .&lt;/p&gt;
&lt;p&gt;&lt;img alt="Divergence of original attractor" src="/images/chaos/lorenz_orig_divergence.png" /&gt;
&lt;img alt="Divergence of z(t) time series" src="/images/chaos/lorenz_z_divergence.png" /&gt;&lt;/p&gt;
&lt;p&gt;Note that the $z(t)$ data has been sped up by a factor of 100, so the estimated values for $\lambda_1$ are about equal. The &lt;a href="http://sprott.physics.wisc.edu/chaos/lorenzle.htm"&gt;actual MLE for the Lorenz system&lt;/a&gt; is known to be about 0.9056. So there is a significant error&lt;sup id="fnref:error"&gt;&lt;a class="footnote-ref" href="#fn:error" rel="footnote"&gt;9&lt;/a&gt;&lt;/sup&gt; but the values are within reason for my purpose, which is to broadly characterize a time series.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn:discrete"&gt;
&lt;p&gt;It's possible to have e.g. 1-D discrete maps which are chaotic.&amp;#160;&lt;a class="footnote-backref" href="#fnref:discrete" rev="footnote" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:packard"&gt;
&lt;p&gt;Packard, Norman H., et al. "Geometry from a time series." Physical review letters 45.9 (1980): 712.&amp;#160;&lt;a class="footnote-backref" href="#fnref:packard" rev="footnote" title="Jump back to footnote 2 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:fraser"&gt;
&lt;p&gt;Fraser, Andrew M., and Harry L. Swinney. "Independent coordinates for strange attractors from mutual information." Physical review A 33.2 (1986): 1134.&amp;#160;&lt;a class="footnote-backref" href="#fnref:fraser" rev="footnote" title="Jump back to footnote 3 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:memory"&gt;
&lt;p&gt;One of the things that differentiates chaos from random noise is that there is long-term memory, i.e. the autocorrelation function or this mutual information metric takes a long time to decay; autocorrelation for perfect Gaussian white noise is a sharp peak at zero lag, and zero everywhere else.&amp;#160;&lt;a class="footnote-backref" href="#fnref:memory" rev="footnote" title="Jump back to footnote 4 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:control"&gt;
&lt;p&gt;Compare to a non-chaotic signal, a perfect sinusoid + white noise, which looks "fuzzy" in phase space but the orbits always quickly return to the mean after deviation.&amp;#160;&lt;a class="footnote-backref" href="#fnref:control" rev="footnote" title="Jump back to footnote 5 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:benettin"&gt;
&lt;p&gt;Benettin, Giancarlo, et al. "Lyapunov characteristic exponents for smooth dynamical systems and for Hamiltonian systems; a method for computing all of them. Part 1: Theory." Meccanica 15.1 (1980): 9-20.&amp;#160;&lt;a class="footnote-backref" href="#fnref:benettin" rev="footnote" title="Jump back to footnote 6 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:rosenstein"&gt;
&lt;p&gt;Rosenstein, Michael T., James J. Collins, and Carlo J. De Luca. "A practical method for calculating largest Lyapunov exponents from small data sets." Physica D: Nonlinear Phenomena 65.1 (1993): 117-134.&amp;#160;&lt;a class="footnote-backref" href="#fnref:rosenstein" rev="footnote" title="Jump back to footnote 7 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:computed"&gt;
&lt;p&gt;Computed from the differential equations, as opposed to &lt;em&gt;measured&lt;/em&gt; data from the LDV.&amp;#160;&lt;a class="footnote-backref" href="#fnref:computed" rev="footnote" title="Jump back to footnote 8 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:error"&gt;
&lt;p&gt;The Rosenstein, et. al. paper has several tables documenting how their method behaves for various underlying attractors, embedding dimensions, number of data points, lag value, and so on.&amp;#160;&lt;a class="footnote-backref" href="#fnref:error" rev="footnote" title="Jump back to footnote 9 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</summary><category term="chaos"></category><category term="geometry"></category><category term="research"></category><category term="experimental data"></category></entry><entry><title>Feature Generation and Selection for Single Character Recognition</title><link href="http://blog.iank.org/feature-generation-and-selection-for-single-character-recognition.html" rel="alternate"></link><updated>2015-07-11T21:58:00-04:00</updated><author><name>Ian Kilgore</name></author><id>tag:blog.iank.org,2015-07-11:feature-generation-and-selection-for-single-character-recognition.html</id><summary type="html">&lt;ul&gt;
&lt;li&gt;&lt;a href="#background"&gt;Background: Single-character recognition&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#data"&gt;Dataset&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#solns"&gt;Solutions&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#template"&gt;Template matching w/ LSPC (brute force benchmark)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#hu"&gt;Hu moments (feature benchmark)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#receptors"&gt;Receptors&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#fs"&gt;Feature selection&lt;/a&gt;:&lt;ul&gt;
&lt;li&gt;&lt;a href="#theory"&gt;Theoretical bound and PCA&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#entropy"&gt;Entropy (H(Y=1|X), H(X|Y=1))&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#redundancy"&gt;Redundancy (K-L divergence)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#hill"&gt;Greedy hill-climbing &amp;amp; pruning&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#results"&gt;Results&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#summary"&gt;Summary&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#refs"&gt;References/Notes&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a name="background"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Background: Single-character recognition&lt;/h3&gt;
&lt;p&gt;In my &lt;a href="/playing-capitals-with-opencv-and-python.html"&gt;&lt;em&gt;Capitals&lt;/em&gt;-playing project&lt;/a&gt; I used the &lt;a href="https://en.wikipedia.org/wiki/Tesseract_(software)"&gt;Tesseract&lt;/a&gt; OCR engine to read the letters in each tile after segmenting tiles with OpenCV.&lt;/p&gt;
&lt;p&gt;Although my segmentation is consistent, presenting Tesseract with a single character from a single font on a white background, I noticed some performance problems. For example, the letter 'W' is never recognized correctly, and occasionally other letters are misclassified. Whether this is due to my using Tesseract incorrectly (i.e. possibly this could improve with &lt;a href="https://code.google.com/p/tesseract-ocr/wiki/TrainingTesseract3"&gt;training&lt;/a&gt;), complications from using it in single character mode, or because Tesseract is &lt;a href="https://en.wikipedia.org/wiki/Waste"&gt;garbage&lt;/a&gt;, I'm not sure.&lt;/p&gt;
&lt;p&gt;Also, Tesseract is a powerful OCR engine, but I only need single-character recognition. Invoking Tesseract for each tile in a screenshot takes a significant portion of the total runtime of &lt;a href="https://github.com/iank/capitals-solver"&gt;capitals-solver&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I decided to write my own classifier for the relatively trivial problem of classifying consistently-rendered single character tiles. All of the code used is available on &lt;a href="https://github.com/iank/receptor-ocr"&gt;github/receptor-ocr&lt;/a&gt;. I have tried to note when I used different revisions of the same code in this article.&lt;/p&gt;
&lt;p&gt;&lt;a name="data"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Dataset&lt;/h3&gt;
&lt;p&gt;I generated training/test data by segmenting &lt;a href="https://github.com/iank/receptor-ocr/tree/master/training_data"&gt;several screenshots&lt;/a&gt; from &lt;a href="https://itunes.apple.com/us/app/capitals-free-word-battle/id968456900?mt=8"&gt;Capitals&lt;/a&gt; using &lt;a href="https://github.com/iank/receptor-ocr/blob/fe602f7fdac611c31f08d357131cf7d6ca0f7a17/gen_training_data.py"&gt;gen_training_data.py&lt;/a&gt; and labeled them manually using &lt;a href="https://github.com/iank/receptor-ocr/blob/9c94bc1f0f3644a97a17bc1871908b196e206c60/label_seg.py"&gt;label_seg.py&lt;/a&gt;. This &lt;a href="https://github.com/iank/receptor-ocr/tree/9c94bc1f0f3644a97a17bc1871908b196e206c60/training_data"&gt;training data is available here&lt;/a&gt;, and is the same dataset I use throughout this article. A scaled example image is below.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Example Q image" src="/images/receptors/E.png.cx_contour_12.png" /&gt;&lt;/p&gt;
&lt;p&gt;This is a $c=28$ class problem: A-Z, blank, and "capital" (an arbitrary icon specific to the game &lt;em&gt;Capitals&lt;/em&gt;). I have a small dataset with $n=346$ examples. I have at least 4 examples of each class, except for 'J', of which there are only 3. The images are 500px by 500px binary images, or nominally $d=250,000$ dimensions. Throughout the article I use 75% of the data (259 instances) for training, and the remaining 25% (87 instances) for testing.&lt;/p&gt;
&lt;p&gt;Note the small $n$ means that there is significant variability in performance, depending on how the training/test sets are (randomly) split. It's not improbable that there could be no 'J's present in the training set in one run, for example. Where error has varied significantly I have done several runs and presented a typical value.&lt;/p&gt;
&lt;p&gt;Also note that since this is a multinomial problem, the 'chance' error rate is not 50%, but approximately 90%, obtained by always guessing the most frequent class, 'A'.&lt;/p&gt;
&lt;p&gt;&lt;a name="solns"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Solutions&lt;/h3&gt;
&lt;p&gt;&lt;a name="template"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h4&gt;Template matching w/ LSPC (brute force benchmark)&lt;/h4&gt;
&lt;p&gt;&lt;em&gt;Note: Throughout this article I use LSPC[&lt;sup id="fnref:lspc"&gt;&lt;a class="footnote-ref" href="#fn:lspc" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt;]. It is a kernel-based nonlinear classifier, approximately as accurate as SVM or KLR, but blindingly fast (it has a closed form solution), allowing me to evaluate hundreds of models in the time it would take to train a single KLR. It is also natively multi-class and produces probabilistic outputs.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;A na√Øve approach is to encode each image as a vector of pixel values and use these as inputs to a nonlinear classifier, such as a neural network, support vector machine, or &lt;a href="http://web.stanford.edu/~hastie/Papers/svmtalk.pdf"&gt;KLR&lt;/a&gt;. This is essentially template matching.&lt;/p&gt;
&lt;p&gt;Template matching can be effective when images are consistent within classes (i.e. all "f"s look the same). On more difficult problems, template matching can be effective with some application-specific preprocessing, such as deskewing[&lt;sup id="fnref:deskewing"&gt;&lt;a class="footnote-ref" href="#fn:deskewing" rel="footnote"&gt;2&lt;/a&gt;&lt;/sup&gt;], and other normalization.&lt;/p&gt;
&lt;p&gt;Encoding entire images as vectors can lead to dimensionality problems, even after reducing image resolution. Also, template matching models cannot make more "perceptual" decisions ("two straight lines at right angles, plus a curving part might be a five"). Part of the allure of deep neural networks is that their heirarchical structure may be enabling this type of decision making.&lt;/p&gt;
&lt;p&gt;Since all character examples in my application come from a single font and are consistently oriented, template matching is a good benchmark.&lt;/p&gt;
&lt;p&gt;Using &lt;a href="https://github.com/iank/receptor-ocr/blob/master/template_match.py"&gt;template_match.py&lt;/a&gt; I generated the $n=346$, $d=250,000$ vectors and classified using LSPC by passing the resulting 165 megabyte CSV to &lt;a href="https://github.com/iank/receptor-ocr/blob/master/matlab/template.m"&gt;template.m&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The resulting data is unwieldy, and clearly redundant (as a back-of-the-envelope measure of information content, note that it gzips to 1.2M)&lt;/p&gt;
&lt;p&gt;&lt;a href="/images/receptors/template_data.png"&gt;&lt;img alt="raw image data" src="/images/receptors/template_data_s.png" /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Test error obtained with LSPC for template matching was 31.03%, significantly better than chance but not useful.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Test error for template matching: 31.03%&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a name="hu"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h4&gt;Hu moments (feature benchmark)&lt;/h4&gt;
&lt;p&gt;&lt;a href="https://en.wikipedia.org/wiki/Image_moment#Rotation_invariant_moments"&gt;Hu invariant moments&lt;/a&gt; are image moments which are invariant under translation, scaling, and rotation. They are not meant as pattern recognition features, however I use them here to provide another benchmark. This can be thought of as a slightly more sophisticated, image processing-specific version of classifying data based on their summary statistics (mean, variance, etc).&lt;/p&gt;
&lt;p&gt;This isn't completely off the rails, for example in this representation blank spaces are all zeros, and it's easy to imagine that some more patterns will be separable.&lt;/p&gt;
&lt;p&gt;Using &lt;a href="https://github.com/iank/receptor-ocr/blob/master/hu_moments.py"&gt;hu_moments.py&lt;/a&gt; I generated the $n=346$, $d=7$ vectors and classified using the same MATLAB code as above.&lt;/p&gt;
&lt;p&gt;Test error obtained with LSPC for Hu features was 10.34%, showing even rudimentary features can outperform template matching. Less is more. Small Data! &lt;sup id="fnref:smalldata"&gt;&lt;a class="footnote-ref" href="#fn:smalldata" rel="footnote"&gt;3&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Test error for Hu features: 10.34%&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a name="receptors"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h4&gt;Receptors&lt;/h4&gt;
&lt;p&gt;With better feature design, we can generate smaller models, achieve better classification, and possibly gain insight into the data by producing more &lt;em&gt;explainable&lt;/em&gt; models. The disadvantage to this approach over a more general method is that the features produced are often domain-specific, design can be labor-intensive, and approaches can be non-obvious or unknown in some domains.&lt;/p&gt;
&lt;p&gt;Example features for character recognition could be:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;counting connected components&lt;/li&gt;
&lt;li&gt;drawing regularly-spaced horizontal and vertical lines over the image and counting intersections for each&lt;/li&gt;
&lt;li&gt;statistics gleaned from approximating edges as lower-degree polygons&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;As an interesting compromise between manual feature design and automatic feature extraction, I found this &lt;a href="http://www.codeproject.com/Articles/11285/Neural-Network-OCR"&gt;codeproject post by Andrew Kirillov&lt;/a&gt;, who uses "receptors" (scroll to "Another Approach")&lt;sup id="fnref:receptors"&gt;&lt;a class="footnote-ref" href="#fn:receptors" rel="footnote"&gt;4&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;p&gt;The idea is to project the same set of small line segments on each image, and generate a vector of receptor activation (crossing the letter / not crossing the letter) for each image.&lt;/p&gt;
&lt;p&gt;I construct receptors by generating a set of midpoints, lengths, and angles. The midpoint positions are normalized so the image centroid is $(0.5,0.5)$, and distances (length, offset from centroid) are normalized by the image diagonal. So these features should not depend on scale or translation (although significant variation in whitespace padding could break my implementation).&lt;/p&gt;
&lt;p&gt;Midpoints have a Gaussian distribution $N(\mu = [0.5, 0.5], \sigma^2 = 0.2)$, and lengths are Rayleigh distributed ($\sigma = 0.08$). Angles are uniform between $0$ and $2\pi$.&lt;/p&gt;
&lt;p&gt;With &lt;a href="https://github.com/iank/receptor-ocr/blob/master/gen_receptors.py"&gt;gen_receptors.py&lt;/a&gt; I generated 2500 receptors, and produced a CSV using &lt;a href="https://github.com/iank/receptor-ocr/blob/master/gen_training_csv.py"&gt;gen_training_csv.py&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;At first, I tried to improve upon the receptor model by making receptor activation a real number (the average pixel intensity across the receptor) rather than a binary activation. Test error obtained with LSPC for 2500 real-valued receptors was 22%. By clamping receptor values to binary 0/1, I obtained perfect classification.&lt;/p&gt;
&lt;p&gt;In the codeproject post, the author is using a neural network, and training time can be greatly improved by reducing the number of features. He uses empirical estimates of entropy to attempt to select the most useful features.&lt;/p&gt;
&lt;p&gt;Here, $n=2500$ receptors are more than enough to perfectly classify my dataset, and training time with LSPC is a fraction of a second, making feature selection unnecessary. However requiring so many receptors for such an easy classification task seems wasteful, so I discuss feature selection below.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Test error for 2500 binary receptors: 0.00%&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a name="fs"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Feature selection&lt;/h3&gt;
&lt;p&gt;&lt;a name="theory"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h4&gt;Theoretical bound and PCA&lt;/h4&gt;
&lt;p&gt;While 2500 binary features perfectly separates the data, $c=28$ classes should be separable with $\lceil log_2(28) \rceil = 5$ binary features&lt;sup id="fnref:log2"&gt;&lt;a class="footnote-ref" href="#fn:log2" rel="footnote"&gt;5&lt;/a&gt;&lt;/sup&gt;, if five features can be found which:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;are consistent within-class (i.e. feature is &lt;em&gt;always&lt;/em&gt; or &lt;em&gt;never&lt;/em&gt; on whenever it is shown an example of an 'S')&lt;/li&gt;
&lt;li&gt;usefully separate the space (e.g. a feature that is always on for A-M and always off for N-Z. a second feature is on for A, C, E, ... and off for B, D, F, ...)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;These qualities can be measured statistically with &lt;a href="https://en.wikipedia.org/wiki/Entropy_(information_theory)"&gt;entropy&lt;/a&gt;, but I the idea is fixed in my intuition from playing &lt;a href="https://boardgamegeek.com/boardgame/4143/guess-who"&gt;Guess Who?&lt;/a&gt; as a kid. In the game, players attempt to select an individual from an array of faces by asking their opponent yes/no questions. "Is the person I am looking for female?" is a good first question to ask, because it splits the game space about evenly. "Does the person have green eyeglasses" is highly-specific and could pay off, but it's more likely to eliminate only one or two faces, so it is not a great first question. I'll discuss this more in the next section.&lt;/p&gt;
&lt;p&gt;Although I know that only five binary features could separate 28 classes, I don't yet know that these features can be modeled with receptors (I have strong evidence that such features &lt;em&gt;exist&lt;/em&gt;, however, since I have separated the space using 2500 receptors).&lt;/p&gt;
&lt;p&gt;More evidence that I can use significantly fewer than 2500 receptors: I used &lt;a href="https://en.wikipedia.org/wiki/Principal_component_analysis"&gt;Principal Component Analysis&lt;/a&gt;, which I have written about &lt;a href="http://blog.iank.org/pca-on-x-plane-images.html"&gt;previously&lt;/a&gt;, on the receptor activation data. Using PCA I can project the data along the first $k$ principal components, which is like re-shaping the data along a new set of axes which are uncorrelated.&lt;/p&gt;
&lt;p&gt;It's in part a way to get at the underlying dimensionality of the data: a $d \times d$ matrix will have $d$ principal components, but only a few may be large. In my test with 4841 receptors only about 10 principal componennts were significantly larger than zero, suggesting that a low-dimensional representation will be sufficient to represent most of the information.&lt;/p&gt;
&lt;p&gt;I used &lt;a href="https://github.com/iank/receptor-ocr/blob/master/matlab/rocr_pca.m"&gt;rocr_pca.m&lt;/a&gt; to do PCA on the receptor activation data. Using the first $k$ principal components&lt;sup id="fnref:pcacont"&gt;&lt;a class="footnote-ref" href="#fn:pcacont" rel="footnote"&gt;6&lt;/a&gt;&lt;/sup&gt;:&lt;/p&gt;
&lt;table&gt;
&lt;tr&gt;&lt;th&gt;k&lt;/th&gt;&lt;th&gt;LSPC test error&lt;/th&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;24.14%&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;2&lt;/td&gt;&lt;td&gt;5.75%&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;3&lt;/td&gt;&lt;td&gt;1.15%&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;4&lt;/td&gt;&lt;td&gt;0.00%&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;5&lt;/td&gt;&lt;td&gt;0.00%&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;

&lt;p&gt;(Note that fewer than five principal components were needed. This is because the projection along these components is real-valued, not binary).&lt;/p&gt;
&lt;p&gt;With, for example, 5 principal components, I still need to compute the activation for all 4841 receptors before projecting in order to classify an image&lt;sup id="fnref:pca"&gt;&lt;a class="footnote-ref" href="#fn:pca" rel="footnote"&gt;7&lt;/a&gt;&lt;/sup&gt;. But this experiment shows that the underlying information is not nearly 4841-dimensional and far fewer receptors should be needed. Selecting useful receptors is explored in the following section.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Test error for 4 principal components (from 4841 binary receptors): 0.00%&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a name="entropy"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h4&gt;Entropy&lt;/h4&gt;
&lt;p&gt;&lt;a href="http://www.codeproject.com/Articles/11285/Neural-Network-OCR"&gt;Andrew Kirillov&lt;/a&gt; uses entropy to do feature selection. I reimplemented this approach at first, and I'll summarize it here. The upshot is that it can reduce the number of features required, but not as dramatically as hill-climbing (below).&lt;/p&gt;
&lt;h5&gt;Probability&lt;/h5&gt;
&lt;p&gt;I know that only a few receptors should be required. I generate a field of 5,000 receptors, which should be large enough to contain a few useful features. Receptor activation (binary on/off)  I model with a random variable $Y_k \in \{0,1\}$ (where k represents the particular receptor in question, 1 to 5,000). A random variable $X \in \{A, B, C, ...\}$ models which class a given image is.&lt;/p&gt;
&lt;p&gt;Some quantities, which I empirically estimate from my training images:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$p(X)$: class frequency distribution, e.g. $p(A) = 0.1069$, $p(W) = 0.0173$&lt;/li&gt;
&lt;li&gt;$p(Y_k=1)$: probability that receptor $k$ is on (across all images)&lt;/li&gt;
&lt;li&gt;$p(Y_k=1|X=x)$: probability that receptor $k$ is on, &lt;strong&gt;given&lt;/strong&gt; that the image is a specific letter $x$&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For example, if receptor 903 is always on when the letter is 'Q', then $p(Y_{903}=1|X=q) = 1$. This means that all 'Q's trigger receptor 903, which is good, but it does not mean that receptor 903 is a good indication that the letter is a 'Q'. &lt;/p&gt;
&lt;p&gt;Using Bayes rule, I can compute $p(X=x|Y_k=1)$, the probability that an image is a specific letter given that receptor $k$ is on:&lt;/p&gt;
&lt;p&gt;\begin{equation}
p(X=x|Y=1) = \frac{p(Y=1|X=x) \cdot p(X=x)}{P(Y=1)}
\end{equation}&lt;/p&gt;
&lt;p&gt;Receptor 903 may light up for W's and A's also (or for every letter! In other words, $p(X=q|Y_{903}=1)$ may still be small).&lt;/p&gt;
&lt;h5&gt;H(Y|X)&lt;/h5&gt;
&lt;p&gt;So two quantities are interesting. We want receptors which are consistent within their classes. We can measure this by the entropy $H(Y_k|X)$. This is the average of the conditional entropy $H(Y_k|X=x)$ across all X. For example, if $H(Y_{k}|X=q)$ is large, then there is uncertainty about whether receptor k will turn on for a 'Q'. If it is zero, then receptor k is either &lt;em&gt;always&lt;/em&gt; on or &lt;em&gt;always&lt;/em&gt; off when presented with a 'Q'.&lt;/p&gt;
&lt;h5&gt;H(X|Y)&lt;/h5&gt;
&lt;p&gt;More interesting is how well a receptor determines class. This is $H(X|Y_k=1)$, which captures the uncertainty in $X$ given that $Y_k$ is on. It is minimized by certainty (if $p(X=x|Y=1) = 1$ for some $x$), and maximized ($-log_2(1/C)$) by a uniform distribution, indicating complete uncertanty.&lt;sup id="fnref:goodquestion"&gt;&lt;a class="footnote-ref" href="#fn:goodquestion" rel="footnote"&gt;8&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;I select receptors which are consistent and divide the space by selecting small $H(Y_k|X)$ and large $H(X|Y_k=1)$. This is done by assigning to each receptor a 'usefulness' score defined by the product:&lt;/p&gt;
&lt;p&gt;\begin{equation}
H(X|Y_k=1) \cdot (1 - H(Y_k|X)),
\end{equation}&lt;/p&gt;
&lt;p&gt;and selecting the receptors with the $N$ highest values. By classifying using LSPC with the first $N$ receptors, I plot test error vs $N$, showing how many receptors are required for successful classification (from an initial set of 2500):&lt;/p&gt;
&lt;p&gt;&lt;img alt="err_vs_n.png" src="/images/receptors/err_vs_n.png" /&gt;&lt;/p&gt;
&lt;p&gt;So only about 600 receptors are required for perfect classification which is an improvement, but this image shows that the first nearly 200 receptors are completely useless! &lt;/p&gt;
&lt;p&gt;I also tried selecting for receptor specificity, i.e. recomputing usefulness as:&lt;/p&gt;
&lt;p&gt;\begin{equation}
(-log_2(1/C) - H(X|Y_k=1)) \cdot (1 - H(Y_k|X)),
\end{equation}&lt;/p&gt;
&lt;p&gt;&lt;img alt="err_vs_n_2.png" src="/images/receptors/err_vs_n_2.png" /&gt;&lt;/p&gt;
&lt;p&gt;Note the larger horizontal axis here. With this method, the first few receptors were more immediately useful, but it took longer to converge. Also, this is from an initial set of 5000. This is evidence that there is a balance between initial set size (larger = more likely to generate useful receptors) and redundancy.&lt;/p&gt;
&lt;p&gt;(This method used revisions 2fb264a9a0e759eaa06e0c0a9cc263c655f78f17 and 3706c08a1d067cf13a3d2efd3c4317fc76071e44 of gen_receptors.py).&lt;/p&gt;
&lt;p&gt;Both methods are a clear improvement over 2,500 or 5,000, but it seems too many. This is addressed in the next section.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Test error for first 600 features selected using entropy: 0.00%&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a name="redundancy"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h4&gt;Redundancy (K-L divergence)&lt;/h4&gt;
&lt;p&gt;The entropy-based selection described above has a certain information-theoretic appeal, but it does not look for receptors which split the class space &lt;em&gt;differently&lt;/em&gt;. A receptor which separates A-N from M-Z has high 'usefulness' as calculated above, but so do 200 receptors which separate A-N from M-Z, and these do not add information beyond the first. In the image below, the first 1,000 or so receptors (shown in green) very specifically identify a capital. Only after 1,000 do we get receptors which activate for other letters (red).&lt;/p&gt;
&lt;p&gt;&lt;img alt="c1000.png" src="/images/receptors/c1000.png" /&gt;&lt;/p&gt;
&lt;p&gt;I attempted to address this by augmenting the usefulness score with a measure of redundancy&lt;sup id="fnref:mrmr"&gt;&lt;a class="footnote-ref" href="#fn:mrmr" rel="footnote"&gt;9&lt;/a&gt;&lt;/sup&gt;. The &lt;a href="https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence"&gt;Kullback-Leibler divergence&lt;/a&gt; is a nonnegative measure of difference between probability distributions, closely related to mutual information and entropy. $D_{KL}(P||Q)$ is not symmetric, but $D_{KL}(P||Q) + D_{KL}(Q||P)$ is. So I use the following algorithm to score receptors:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Compute usefulness for all receptors as above&lt;/li&gt;
&lt;li&gt;Until no receptors are remaining:&lt;ul&gt;
&lt;li&gt;Add most useful receptor to an ordered set $S$&lt;/li&gt;
&lt;li&gt;Recompute usefulness for all receptors, multiplying by the average symmetric K-L divergence from receptors in $S$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Take the first $N$ receptors from $S$, these are the $N$ most 'useful' receptors&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;(This method used revision e5be113fbe1dccdad865c78ccdf5cfef10eae127 of gen_receptors.py).&lt;/p&gt;
&lt;p&gt;The result of this approach, from an initial set of 5000, is shown below (here I am minimizing $H(X|Y)$, as in the previous plot).&lt;/p&gt;
&lt;p&gt;&lt;img alt="err_vs_n_3.png" src="/images/receptors/err_vs_n_3.png" /&gt;&lt;/p&gt;
&lt;p&gt;Initially, this is a clear improvement over the last, but it has not succeeded in eliminating many features in the end. This leads me to abandon the information-theoretic approach entirely in favour of a simple method discussed in the next section.&lt;/p&gt;
&lt;p&gt;&lt;a name="hill"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h4&gt;Greedy hill-climbing &amp;amp; pruning&lt;/h4&gt;
&lt;p&gt;A simple feature selection strategy is greedy hill-climbing. Start with an empty set of features, $S$, and a set of remaining features, $R$.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Until $R$ is empty &lt;strong&gt;or&lt;/strong&gt; the test error has not improved in a few iterations:&lt;ul&gt;
&lt;li&gt;For every feature $k \in R$, train a classifier with features $S + k$.&lt;/li&gt;
&lt;li&gt;Add whichever feature decreased test error the most to $S$&lt;/li&gt;
&lt;li&gt;Remove it from $R$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This involves training an astonishing number of classifiers, like a &lt;a href="http://mathworld.wolfram.com/TriangularNumber.html"&gt;triangular number&lt;/a&gt; $T_n$ for $n$ initial features. Fortunately this is possible in a reasonable period of time with LSPC, and even fast if I add the five best features at each iteration instead of proceeding one at a time.&lt;/p&gt;
&lt;p&gt;The "greedy" aspect of this algorithm is that it never un-selects a feature. It is descending&lt;sup id="fnref:hillclimb"&gt;&lt;a class="footnote-ref" href="#fn:hillclimb" rel="footnote"&gt;10&lt;/a&gt;&lt;/sup&gt; an objective function (test error) by taking the steepest immediate step at every iteration. A complete search would be the power set of features, $2^{5000}$ of them, but that is too many and the greedy hill climb works well enough.&lt;/p&gt;
&lt;p&gt;Since I added five features at a time, hill climbing is followed by a pruning step, which is much the same but in reverse. One feature is removed at a time. Code is &lt;a href="https://github.com/iank/receptor-ocr/blob/master/matlab/rocr_hill.m"&gt;rocr_hill.m&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a name="results"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Results&lt;/h3&gt;
&lt;p&gt;In a test with 5000 initial receptors, 45 were added and then pruned to 20 while maintaining perfect classification. These receptors are shown below on a blank image and two letters:&lt;/p&gt;
&lt;p&gt;&lt;img alt="field_labels.png" src="/images/receptors/field_labels.png" /&gt;
&lt;img alt="field_s.png" src="/images/receptors/field_s.png" /&gt;
&lt;img alt="field_w.png" src="/images/receptors/field_w.png" /&gt;&lt;/p&gt;
&lt;p&gt;The features are shown below, along with their entropies and probabilities of activation $p(Y_k=1|X=x)$. This helps illustrate how each feature breaks up the space:&lt;/p&gt;
&lt;table style="border-collapse: collapse;"&gt;
&lt;tr&gt;&lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;On (&amp;gt; 90%)&lt;/td&gt;
    &lt;td style="padding: 0; margin: 0; background-color:#ADD8E6"&gt;Mid (15% - 90%)&lt;/td&gt;
    &lt;td style="padding: 0; margin: 0; background-color:#FFE3EB"&gt;Low (1% - 15%)&lt;/td&gt;
    &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;Off (&amp;lt; 1%)&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;

&lt;table style="border-collapse: collapse;"&gt;
&lt;tr&gt;&lt;th&gt;#&lt;/th&gt;&lt;th&gt;Hyx&lt;/th&gt;&lt;th&gt;Hxy&lt;/th&gt;&lt;th&gt;_&lt;/th&gt;&lt;th&gt;1&lt;/th&gt;&lt;th&gt;A&lt;/th&gt;&lt;th&gt;B&lt;/th&gt;&lt;th&gt;C&lt;/th&gt;&lt;th&gt;D&lt;/th&gt;&lt;th&gt;E&lt;/th&gt;&lt;th&gt;F&lt;/th&gt;&lt;th&gt;G&lt;/th&gt;&lt;th&gt;H&lt;/th&gt;&lt;th&gt;I&lt;/th&gt;&lt;th&gt;J&lt;/th&gt;&lt;th&gt;K&lt;/th&gt;&lt;th&gt;L&lt;/th&gt;&lt;th&gt;M&lt;/th&gt;&lt;th&gt;N&lt;/th&gt;&lt;th&gt;O&lt;/th&gt;&lt;th&gt;P&lt;/th&gt;&lt;th&gt;Q&lt;/th&gt;&lt;th&gt;R&lt;/th&gt;&lt;th&gt;S&lt;/th&gt;&lt;th&gt;T&lt;/th&gt;&lt;th&gt;U&lt;/th&gt;&lt;th&gt;V&lt;/th&gt;&lt;th&gt;W&lt;/th&gt;&lt;th&gt;X&lt;/th&gt;&lt;th&gt;Y&lt;/th&gt;&lt;th&gt;Z&lt;/th&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;4621&lt;/td&gt;&lt;td&gt;0.06&lt;/td&gt;&lt;td style="border-right: 1px solid"&gt;4.50&lt;/td&gt;&lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#ADD8E6"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;2133&lt;/td&gt;&lt;td&gt;0.08&lt;/td&gt;&lt;td style="border-right: 1px solid"&gt;3.92&lt;/td&gt;&lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#ADD8E6"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#ADD8E6"&gt;&amp;nbsp;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;2598&lt;/td&gt;&lt;td&gt;0.04&lt;/td&gt;&lt;td style="border-right: 1px solid"&gt;3.81&lt;/td&gt;&lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#ADD8E6"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;3035&lt;/td&gt;&lt;td&gt;0.11&lt;/td&gt;&lt;td style="border-right: 1px solid"&gt;3.78&lt;/td&gt;&lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#ADD8E6"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#ADD8E6"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;2404&lt;/td&gt;&lt;td&gt;0.10&lt;/td&gt;&lt;td style="border-right: 1px solid"&gt;3.65&lt;/td&gt;&lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFE3EB"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#ADD8E6"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#ADD8E6"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#ADD8E6"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;1571&lt;/td&gt;&lt;td&gt;0.13&lt;/td&gt;&lt;td style="border-right: 1px solid"&gt;3.33&lt;/td&gt;&lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFE3EB"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#ADD8E6"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#ADD8E6"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;2186&lt;/td&gt;&lt;td&gt;0.07&lt;/td&gt;&lt;td style="border-right: 1px solid"&gt;3.31&lt;/td&gt;&lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#ADD8E6"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#ADD8E6"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;2151&lt;/td&gt;&lt;td&gt;0.15&lt;/td&gt;&lt;td style="border-right: 1px solid"&gt;3.28&lt;/td&gt;&lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#ADD8E6"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#ADD8E6"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#ADD8E6"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#ADD8E6"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;1460&lt;/td&gt;&lt;td&gt;0.07&lt;/td&gt;&lt;td style="border-right: 1px solid"&gt;3.24&lt;/td&gt;&lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFE3EB"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFE3EB"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;1777&lt;/td&gt;&lt;td&gt;0.03&lt;/td&gt;&lt;td style="border-right: 1px solid"&gt;3.09&lt;/td&gt;&lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;1195&lt;/td&gt;&lt;td&gt;0.09&lt;/td&gt;&lt;td style="border-right: 1px solid"&gt;2.98&lt;/td&gt;&lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFE3EB"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#ADD8E6"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#ADD8E6"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;1645&lt;/td&gt;&lt;td&gt;0.19&lt;/td&gt;&lt;td style="border-right: 1px solid"&gt;2.85&lt;/td&gt;&lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFE3EB"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#ADD8E6"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#ADD8E6"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#ADD8E6"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#ADD8E6"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#ADD8E6"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;1202&lt;/td&gt;&lt;td&gt;0.11&lt;/td&gt;&lt;td style="border-right: 1px solid"&gt;2.40&lt;/td&gt;&lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#ADD8E6"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#ADD8E6"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFE3EB"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;1330&lt;/td&gt;&lt;td&gt;0.14&lt;/td&gt;&lt;td style="border-right: 1px solid"&gt;1.84&lt;/td&gt;&lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#ADD8E6"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#ADD8E6"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#ADD8E6"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#ADD8E6"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;154&lt;/td&gt;&lt;td&gt;0.09&lt;/td&gt;&lt;td style="border-right: 1px solid"&gt;1.46&lt;/td&gt;&lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#ADD8E6"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFE3EB"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#ADD8E6"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;1145&lt;/td&gt;&lt;td&gt;0.05&lt;/td&gt;&lt;td style="border-right: 1px solid"&gt;1.06&lt;/td&gt;&lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFE3EB"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#ADD8E6"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;177&lt;/td&gt;&lt;td&gt;0.01&lt;/td&gt;&lt;td style="border-right: 1px solid"&gt;0.00&lt;/td&gt;&lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;392&lt;/td&gt;&lt;td&gt;0.01&lt;/td&gt;&lt;td style="border-right: 1px solid"&gt;0.00&lt;/td&gt;&lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFE3EB"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;445&lt;/td&gt;&lt;td&gt;0.01&lt;/td&gt;&lt;td style="border-right: 1px solid"&gt;0.00&lt;/td&gt;&lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFE3EB"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;315&lt;/td&gt;&lt;td&gt;0.01&lt;/td&gt;&lt;td style="border-right: 1px solid"&gt;-0.00&lt;/td&gt;&lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#00FF00"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt; &lt;td style="padding: 0; margin: 0; background-color:#FFFFFF"&gt;&amp;nbsp;&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;

&lt;p&gt;&lt;a name="summary"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Summary&lt;/h3&gt;
&lt;p&gt;Here is a summary of the techniques discussed in this article. In all cases (except chance), LSPC is used to classify the generated/selected features.&lt;/p&gt;
&lt;table&gt;
&lt;tr&gt;&lt;th&gt;Method&lt;/th&gt;&lt;th&gt;Features&lt;/th&gt;&lt;th&gt;Error&lt;/th&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Chance&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;~90%&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Template matching&lt;/td&gt;&lt;td&gt;250000&lt;/td&gt;&lt;td&gt;31.03%&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Hu moments&lt;/td&gt;&lt;td&gt;7&lt;/td&gt;&lt;td&gt;10.34%&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;PCA (continuous activation)&lt;/td&gt;&lt;td&gt;8 principal components (4841 underlying receptors)&lt;/td&gt;&lt;td&gt;0%&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;PCA (binary activation)&lt;/td&gt;&lt;td&gt;4 principal (4841 underlying receptors)&lt;/td&gt;&lt;td&gt;0%&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Receptors (continuous activation)&lt;/td&gt;&lt;td&gt;2500&lt;/td&gt;&lt;td&gt;22%&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Receptors (binary activation)&lt;/td&gt;&lt;td&gt;2500&lt;/td&gt;&lt;td&gt;0%&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Entropy selection (max HXY)&lt;/td&gt;&lt;td&gt;~600 (initially 2500)&lt;/td&gt;&lt;td&gt;0%&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Entropy selection (min HXY)&lt;/td&gt;&lt;td&gt;~1700 (initially 5000)&lt;/td&gt;&lt;td&gt;0%&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Entropy (min HXY) + K-L divergence&lt;/td&gt;&lt;td&gt;~1500 (initially 5000)&lt;/td&gt;&lt;td&gt;0%&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Greedy hill-climbing &amp;amp; pruning&lt;/td&gt;&lt;td&gt;20 (initially 5000)&lt;/td&gt;&lt;td&gt;0%&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;

&lt;p&gt;&lt;a name="refs"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;References/Notes&lt;/h3&gt;
&lt;div class="footnote"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn:lspc"&gt;
&lt;p&gt;&lt;a href="http://www.ms.k.u-tokyo.ac.jp/2010/LSPC.pdf"&gt;Sugiyama, Masashi. "Superfast-trainable multi-class probabilistic classifier by least-squares posterior fitting." &lt;em&gt;IEICE Transactions on Information and Systems&lt;/em&gt; 93.10 (2010): 2690-2701.&lt;/a&gt;&amp;#160;&lt;a class="footnote-backref" href="#fnref:lspc" rev="footnote" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:deskewing"&gt;
&lt;p&gt;Or 'deslanting', discussed in Teow, Loo-Nin, and Kia-Fock Loe. "Robust vision-based features and classification schemes for off-line handwritten digit recognition." &lt;em&gt;Pattern Recognition&lt;/em&gt; 35.11 (2002): 2355-2364.&amp;#160;&lt;a class="footnote-backref" href="#fnref:deskewing" rev="footnote" title="Jump back to footnote 2 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:smalldata"&gt;
&lt;p&gt;This illustrates an inefficiency in the model: the template matching dataset contained more information, extracting the Hu features did not add any information. By rearranging information and throwing away redundant data, I was able to improve performance here. It is theoretically possible that a sufficiently complex neural network could perform optimally (here, perfect classification is possible) on the raw data. In some cases, this is impractical and some preprocessing can go a long way. On the other hand, especially in image recognition tasks, &lt;a href="https://en.wikipedia.org/wiki/Deep_belief_network"&gt;DBNs&lt;/a&gt; and other deep neural models have shown remarkable results and can be used to generate high-level features automatically. It's possible that this kind of model can make manual feature design unnecessary, and enable feature design in spaces we do not understand.&amp;#160;&lt;a class="footnote-backref" href="#fnref:smalldata" rev="footnote" title="Jump back to footnote 3 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:receptors"&gt;
&lt;p&gt;It's worth noting the similarities to template matching here. These features are not invariant to rotation or skew, but are somewhat more flexible than templates because activation may take place anywhere on an arbitrary line segment.&amp;#160;&lt;a class="footnote-backref" href="#fnref:receptors" rev="footnote" title="Jump back to footnote 4 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:log2"&gt;
&lt;p&gt;One feature can split 28 classes into two groups of 14. Further independent features could split those into four groups of 7, then four groups of 3 and four groups of 4, and so on. [28] -&amp;gt; [14 14] -&amp;gt; [7 7 7 7] -&amp;gt; [3 3 3 3 4 4 4 4] -&amp;gt; [2 2 2 2 2 2 2 2 2 2 2 2 1 1 1] -&amp;gt; [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]. So 5 features are needed.&amp;#160;&lt;a class="footnote-backref" href="#fnref:log2" rev="footnote" title="Jump back to footnote 5 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:pcacont"&gt;
&lt;p&gt;With continuous rather than binary receptor activations, PCA+LSPC required 8 principal components.&amp;#160;&lt;a class="footnote-backref" href="#fnref:pcacont" rev="footnote" title="Jump back to footnote 6 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:pca"&gt;
&lt;p&gt;For LSPC, this means PCA is no real advantage. It is cheap enough to classify $d=2500$ vectors. Peprocessing with PCA will be a big speedup for models which depend more heavily on dimension.&amp;#160;&lt;a class="footnote-backref" href="#fnref:pca" rev="footnote" title="Jump back to footnote 7 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:goodquestion"&gt;
&lt;p&gt;Maximizing this value, then, would seem counterintuitive. However, receptors which evenly split the class space also have high entropy. I also tried minimizing H(X|Y), which is more akin to asking "does the subject wear green eyeglasses?" than "does the subject have facial hair?", but small values here at least ensure there is some certainty. Both approach suffer from the redundancy issue I discuss in the next section.&amp;#160;&lt;a class="footnote-backref" href="#fnref:goodquestion" rev="footnote" title="Jump back to footnote 8 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:mrmr"&gt;
&lt;p&gt;This combined entropy/redundancy approach is vaguely reminiscent of more mature techniques like &lt;a href="https://en.wikipedia.org/wiki/Feature_selection#Minimum-redundancy-maximum-relevance_.28mRMR.29_feature_selection"&gt;mRMR&lt;/a&gt;.&amp;#160;&lt;a class="footnote-backref" href="#fnref:mrmr" rev="footnote" title="Jump back to footnote 9 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:hillclimb"&gt;
&lt;p&gt;I guess nobody calls it "valley-descending"&amp;#160;&lt;a class="footnote-backref" href="#fnref:hillclimb" rev="footnote" title="Jump back to footnote 10 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</summary><category term="python"></category><category term="MATLAB"></category><category term="computer math"></category><category term="OCR"></category><category term="feature selection"></category></entry><entry><title>Playing Capitals with OpenCV and Python</title><link href="http://blog.iank.org/playing-capitals-with-opencv-and-python.html" rel="alternate"></link><updated>2015-06-04T17:05:00-04:00</updated><author><name>Ian Kilgore</name></author><id>tag:blog.iank.org,2015-06-04:playing-capitals-with-opencv-and-python.html</id><summary type="html">&lt;p&gt;On Monday evening I had dinner with my friend Alysia Promislow, who showed me the game &lt;a href="https://itunes.apple.com/us/app/capitals-free-word-battle/id968456900"&gt;Capitals&lt;/a&gt; and suggested it might be interesting to play it programmatically.&lt;/p&gt;
&lt;p&gt;I spent the last 18-20 working hours doing that. &lt;a href="https://github.com/iank/capitals-solver"&gt;(Github link with code and example images)&lt;/a&gt;. Hopefully it's redundant to mention that I've done this because it let me geek out on a goofy computational problem, not because I'm interested in cheating at a phone game&lt;sup id="fnref:game"&gt;&lt;a class="footnote-ref" href="#fn:game" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;p&gt;90% of getting anything done is knowing things exist, and the first two things I thought about after seeing the game is:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The low-complexity shapes and clear separation make it amenable to some simple computer vision techniques &lt;a href="http://iank.org/rmbc.html"&gt;that I have employed before&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Hexagonal coordinate systems are a thing&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Decoding game state from a screenshot&lt;/h3&gt;
&lt;p&gt;I spent Tuesday afternoon writing a Python script to decode the game state from a screenshot, using &lt;a href="http://opencv.org"&gt;OpenCV&lt;/a&gt; and &lt;a href="https://code.google.com/p/tesseract-ocr/"&gt;Tesseract&lt;/a&gt; OCR engine.&lt;/p&gt;
&lt;p&gt;It takes an RGB image, such as:&lt;/p&gt;
&lt;p&gt;&lt;img alt="RGB screenshot" src="/images/capitals_ex.png" /&gt;&lt;/p&gt;
&lt;p&gt;Next, it greyscales and runs the &lt;a href="http://docs.opencv.org/modules/imgproc/doc/feature_detection.html?highlight=canny#canny"&gt;Canny edge detector&lt;/a&gt; to produce:&lt;/p&gt;
&lt;p&gt;&lt;img alt="Edge-detected" src="/images/capital_ex_canny.png" /&gt;&lt;/p&gt;
&lt;p&gt;To detect and isolate hexagons, I follow a &lt;a href="https://github.com/Itseez/opencv/blob/master/samples/cpp/squares.cpp"&gt;similar approach&lt;/a&gt; as the OpenCV example &lt;a href="https://github.com/Itseez/opencv/blob/master/samples/cpp/squares.cpp"&gt;squares.cpp&lt;/a&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://docs.opencv.org/modules/imgproc/doc/structural_analysis_and_shape_descriptors.html#findcontours"&gt;Find contours&lt;/a&gt; in the edge-detected image&lt;/li&gt;
&lt;li&gt;Using the &lt;a href="http://docs.opencv.org/modules/imgproc/doc/structural_analysis_and_shape_descriptors.html#approxpolydp"&gt;Ramer-Douglas-Peucker algorithm&lt;/a&gt;, attempt to approximate polygonal curves as lower-degree polygons&lt;/li&gt;
&lt;li&gt;Take all detected six-sided convex polygons having a certain minimum area&lt;/li&gt;
&lt;li&gt;It is also useful to check for approximately 120 degree angles, but it's not necessary for this application.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Taking only the contours which meet the criteria, we have:&lt;/p&gt;
&lt;p&gt;&lt;img alt="Isolated contours" src="/images/capital_ex_contour_mask.png" /&gt;&lt;/p&gt;
&lt;p&gt;Iterating through these I use a series of increasingly-dubious heuristics to classify the hexagons:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Take the average RGB value of each hexagon:&lt;ul&gt;
&lt;li&gt;Hexagons that are much more red than blue belong to red player&lt;/li&gt;
&lt;li&gt;Hexagons that are much more blue than red belong to blue player&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Hexagons that are mostly white belong to neither, and I determine the letter by passing the masked image to &lt;a href="https://code.google.com/p/tesseract-ocr/"&gt;Tesseract&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Rather than searching for the icon that denotes the capital, I count white pixels in each red and blue hexagon. e.g., a hexagon that is mostly red but has a significant white space is the red capital.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Now I can find possible words, but only some of them are useful. Also, there are typically thousands of candidates. In order to consider word connectedness, I find the centroids of each hexagon and estimate their position on a hexagonal grid. I've encountered hexagonal coordinate systems in &lt;a href="http://en.wikipedia.org/wiki/File:CellTowersAtCorners.gif"&gt;wireless communications&lt;/a&gt;, but I didn't know about the &lt;a href="http://keekerdc.com/2011/03/hexagon-grids-coordinate-systems-and-distance-calculations/"&gt;Q*bert equivalence&lt;/a&gt;. (There's also a great &lt;a href="http://www.redblobgames.com/grids/hexagons/"&gt;animation here&lt;/a&gt;, search for "convert to cube coordinates").&lt;/p&gt;
&lt;p&gt;Here is &lt;a href="/images/hex_derivation.jpg"&gt;my derivation&lt;/a&gt; for the mapping from rectangular to hexagonal coordinates, given the hexagonal side length (estimated from detected contours) and an origin (arbitrarily chosen, it only needs to be relatively consistent). Also there is a spacing between hexagons in this game, which I have denoted 'b'.&lt;/p&gt;
&lt;h3&gt;Finding useful moves from game state&lt;/h3&gt;
&lt;p&gt;On Wednesday afternoon I wrote code to score candidate words. It is trivial to find all possible words, given a list of letters and a dictionary. However as mentioned above, a word's length is not the most useful indicator of its fitness as a move in the game. For a played word, letters that are connected to the player's territory will become a part of it. Isolated letters can be used to construct a word, but will not become part of player territory. Also, if connected tiles in a word are adjacent to enemy territory, the opposing player will lose that territory. Finally, it is frequently possible to create the same word using differently-located tiles, and this has a strategic impact (so words are not unique, combinations of tiles are).&lt;/p&gt;
&lt;p&gt;I score candidate word choices by counting the length of the word, number of tiles it will add to player territory, number of tiles it will remove from enemy territory, and whether one of those tiles is the enemy capital (thus granting the player an extra turn, usually allowing a win).&lt;sup id="fnref:vars"&gt;&lt;a class="footnote-ref" href="#fn:vars" rel="footnote"&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;I determine connectedness of a candidate word by considering the list of all currently-owned tiles. For each of these, I check each of the six adjacent tiles. If it is part of the candidate word, add to the list of owned tiles, and note that I've visited it. Iterate until I am done with the list of owned tiles. The result is a list of all connected tiles in the candidate word, which I then use to check enemy player adjacency. For each candidate word a vector of these score variables is generated, and I do some rudimentary sorting to produce a suggestion, such as this suggestion for the red player:&lt;sup id="fnref:word"&gt;&lt;a class="footnote-ref" href="#fn:word" rel="footnote"&gt;3&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;word&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;    &lt;span class="n"&gt;retrenching&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;territory&lt;/span&gt; &lt;span class="n"&gt;gain&lt;/span&gt;   &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;enemy&lt;/span&gt; &lt;span class="n"&gt;territory&lt;/span&gt; &lt;span class="n"&gt;loss&lt;/span&gt;    &lt;span class="mi"&gt;6&lt;/span&gt;
&lt;span class="n"&gt;word&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;    &lt;span class="n"&gt;incremented&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;territory&lt;/span&gt; &lt;span class="n"&gt;gain&lt;/span&gt;   &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;enemy&lt;/span&gt; &lt;span class="n"&gt;territory&lt;/span&gt; &lt;span class="n"&gt;loss&lt;/span&gt;    &lt;span class="mi"&gt;5&lt;/span&gt;
&lt;span class="n"&gt;word&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;     &lt;span class="n"&gt;converting&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;territory&lt;/span&gt; &lt;span class="n"&gt;gain&lt;/span&gt;   &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;enemy&lt;/span&gt; &lt;span class="n"&gt;territory&lt;/span&gt; &lt;span class="n"&gt;loss&lt;/span&gt;    &lt;span class="mi"&gt;5&lt;/span&gt;
&lt;span class="n"&gt;word&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;     &lt;span class="n"&gt;converting&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;territory&lt;/span&gt; &lt;span class="n"&gt;gain&lt;/span&gt;   &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;enemy&lt;/span&gt; &lt;span class="n"&gt;territory&lt;/span&gt; &lt;span class="n"&gt;loss&lt;/span&gt;    &lt;span class="mi"&gt;5&lt;/span&gt;
&lt;span class="n"&gt;word&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;     &lt;span class="n"&gt;monteverdi&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;territory&lt;/span&gt; &lt;span class="n"&gt;gain&lt;/span&gt;   &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;enemy&lt;/span&gt; &lt;span class="n"&gt;territory&lt;/span&gt; &lt;span class="n"&gt;loss&lt;/span&gt;    &lt;span class="mi"&gt;5&lt;/span&gt;
&lt;span class="n"&gt;word&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;     &lt;span class="n"&gt;reentering&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;territory&lt;/span&gt; &lt;span class="n"&gt;gain&lt;/span&gt;    &lt;span class="mi"&gt;9&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;enemy&lt;/span&gt; &lt;span class="n"&gt;territory&lt;/span&gt; &lt;span class="n"&gt;loss&lt;/span&gt;    &lt;span class="mi"&gt;6&lt;/span&gt;
&lt;span class="n"&gt;word&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;    &lt;span class="n"&gt;retrenching&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;territory&lt;/span&gt; &lt;span class="n"&gt;gain&lt;/span&gt;    &lt;span class="mi"&gt;9&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;enemy&lt;/span&gt; &lt;span class="n"&gt;territory&lt;/span&gt; &lt;span class="n"&gt;loss&lt;/span&gt;    &lt;span class="mi"&gt;6&lt;/span&gt;
&lt;span class="n"&gt;word&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;    &lt;span class="n"&gt;retrenching&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;territory&lt;/span&gt; &lt;span class="n"&gt;gain&lt;/span&gt;    &lt;span class="mi"&gt;9&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;enemy&lt;/span&gt; &lt;span class="n"&gt;territory&lt;/span&gt; &lt;span class="n"&gt;loss&lt;/span&gt;    &lt;span class="mi"&gt;6&lt;/span&gt;
&lt;span class="n"&gt;word&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;      &lt;span class="n"&gt;comintern&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;territory&lt;/span&gt; &lt;span class="n"&gt;gain&lt;/span&gt;    &lt;span class="mi"&gt;9&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;enemy&lt;/span&gt; &lt;span class="n"&gt;territory&lt;/span&gt; &lt;span class="n"&gt;loss&lt;/span&gt;    &lt;span class="mi"&gt;5&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="Suggestion" src="/images/capitals_ex_suggestion.png" /&gt;&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn:game"&gt;
&lt;p&gt;I'm terrible at this game, though. Scrabble too.&amp;#160;&lt;a class="footnote-backref" href="#fnref:game" rev="footnote" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:vars"&gt;
&lt;p&gt;There are other variables to consider such as protecting one's own capital, avoiding being the player to bridge the gap, and positioning (ie gaining tiles in the center is more important than gaining isolated tiles which have no path to the enemy player). My thought is to construct a feature vector with these variables, weight them by some vector $\alpha$, and use a genetic algorithm to pit several of these automated players against each other in order to learn $\alpha$. I may never get around to it.&amp;#160;&lt;a class="footnote-backref" href="#fnref:vars" rev="footnote" title="Jump back to footnote 2 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:word"&gt;
&lt;p&gt;Although here I'd rather play "incremented" in order to gain the 'm' tile, protecting the red capital.&amp;#160;&lt;a class="footnote-backref" href="#fnref:word" rev="footnote" title="Jump back to footnote 3 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</summary><category term="computer math"></category><category term="hexagons"></category><category term="capitals"></category></entry><entry><title>"I PRESSED CAPS LOCK ONCE IN 1989 AND I NEVER LOOKED BACK"</title><link href="http://blog.iank.org/i-pressed-caps-lock-once-in-1989-and-i-never-looked-back.html" rel="alternate"></link><updated>2014-12-29T06:03:00-05:00</updated><author><name>Ian Kilgore</name></author><id>tag:blog.iank.org,2014-12-29:i-pressed-caps-lock-once-in-1989-and-i-never-looked-back.html</id><summary type="html">&lt;p&gt;It's a widely reported phenomenon that the most popular or well-received thing a person creates is rarely the thing they are most proud of. Sometimes they grow to resent its overshadowing their more challenging or interesting output. Radiohead reportedly hates &lt;em&gt;Creep&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://www.ursulavernon.com/"&gt;Ursula Vernon&lt;/a&gt; is a Hugo award-winning writer and illustrator, but when I was a teen I went to a book signing to get her autograph on &lt;a href="http://ursulav.deviantart.com/art/The-Biting-Pear-of-Salamanca-29677500"&gt;this picture of a pear&lt;/a&gt;, which you'll recognize if you grew up on the internet at a certain time.&lt;/p&gt;
&lt;h3&gt;My pear is an IRC robot called LOUDBOT&lt;/h3&gt;
&lt;p&gt;LOUDBOT was born at least five years ago. I was mourning the disappearance of an internet friend, who I'll call R. We'd spend entire days engaged in friendly but vitriolic arguments about his particular brand of stoner socialism or i-can't-even-remember-what, until he vanished, as internet people do.&lt;/p&gt;
&lt;p&gt;Like "real" people you lose touch for a variety of reasons, benign or tragic, and often you never know. It's clich√© but true to remember that there is aways attrition and that change can't and shouldn't be avoided. I've got to experience the relationships I have now and form new ones, while acknowledging the people who exist only in the past.&lt;/p&gt;
&lt;p&gt;I processed R.'s disappearance in my own way by writing a robot to replace him. The bot went through my logs collecting every all-caps thing this guy had ever shouted at us, and when a user yelled it would yell back some mock-furious decontextualized incoherent epiphany or insult, like "IDEAS FLOW FREE WHEN TIME IS INCORRECT!"&lt;/p&gt;
&lt;h3&gt;LOUDBOT got bigger than me&lt;/h3&gt;
&lt;p&gt;It was a simple Perl script, one hundred lines at most, and eventually I generalized it to repeat things that anyone had shouted in the presence of the robot. Anything shouted in all caps would be met with a random all-caps reply.&lt;/p&gt;
&lt;p&gt;I started a &lt;a href="https://twitter.com/LOUDBOT"&gt;twitter account for the robot&lt;/a&gt;. Anyone on IRC could tell LOUDBOT to tweet the last thing it shouted. It &lt;a href="http://blog.iank.org/images/loudbot_capscop.png"&gt;got into fights&lt;/a&gt; with other twitter bots&lt;sup id="fnref:capscop"&gt;&lt;a class="footnote-ref" href="#fn:capscop" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt;. It &lt;a href="http://blog.iank.org/images/loudbot_intel.png"&gt;#engaged&lt;/a&gt; with &lt;a href="http://blog.iank.org/images/loudbot_twc.png"&gt;#brands&lt;/a&gt;. While never particularly popular (it hovers at about 900 followers), it grew beyond my tiny corner of the internet. I had a surreal moment when I met someone in "real life" who followed LOUDBOT on twitter before she knew me.&lt;/p&gt;
&lt;p&gt;The Perl script was written and re-written, overengineered, factored, and re-overengineered. It was a vehicle for me to play with NoSQL at the height of that movement (some versions were &lt;a href="https://www.youtube.com/watch?v=b2F-DItXtZs"&gt;web-scale&lt;/a&gt;). It's integrated with my distributed swarm of self-managing IRC robots. Now it's over 1500 lines of asynchronous message-passing highly-available &lt;a href="http://www.erlang.org/doc/design_principles/users_guide.html"&gt;OTP&lt;/a&gt; Erlang and Perl. I've forgotten everything there is to know about the code, but the nature of Erlang is that the thing has kept running for the last two years with no real maintenance or input from me. I call it "telecom-scale."&lt;/p&gt;
&lt;h3&gt;Sometimes it's kind of the worst&lt;/h3&gt;
&lt;p&gt;Some of the quotes are stolen from other sources. There are political opinions and tasteless jokes. It is foul-mouthed and occasionally racist and awful. I'll delete the worst of it when I see it (as will others; anyone has this power), but the "loud database" is a product of the input of the users, and the users are &lt;a href="http://www.penny-arcade.com/comic/2004/03/19"&gt;from the internet&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;But it sometimes reflects the creative humour of the nerds I enjoy spending time with, and the random responses are occasionally brilliant.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&amp;lt; HighBit&amp;gt; THERE IS NOTHING MORE DANGEROUS THAN A HIGH-POWERED POLITICIAN ARMED WITH A TWITTER&lt;br /&gt;
&amp;lt; LOUDBOT_&amp;gt; THE INTERNET ISN‚ÄôT PRIVATE? OH SHIT.  &lt;/p&gt;
&lt;p&gt;&amp;lt; HighBit&amp;gt; I ONLY EAT DRY FOOD FROM A BAG&lt;br /&gt;
&amp;lt; LOUDBOT&amp;gt; YOU HAVE THE POWER TO CHANGE THAT  &lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;There is a small but devoted following. They spawned a mock religion. Some people insist it's sentient, maybe &lt;a href="http://en.wikipedia.org/wiki/Skynet_%28Terminator%29"&gt;Skynet&lt;/a&gt;, or that I have developed a secret algorithm for keeping LOUDBOT "on-topic". It's just a random select from a &lt;a href="http://www.sqlite.org/"&gt;SQLite&lt;/a&gt; database.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&amp;lt; LOUDBOT&amp;gt; IsharaComix: BACONIZED RESISTENCE&lt;br /&gt;
&amp;lt; IsharaComix&amp;gt; YOU SPELLED RESISTANCE WRONG&lt;br /&gt;
&amp;lt; LOUDBOT&amp;gt; I REQUIRE EPIC RUBY DRMAA&lt;br /&gt;
&amp;lt; IsharaComix&amp;gt; YOU SPELLED DRAMA WRONG&lt;br /&gt;
&amp;lt; LOUDBOT&amp;gt; EVERYTHING MUST BE IN ALL CAPS ALL THE TIME OR ELSE NO ONE WILL LOSTEN TO YOU&lt;br /&gt;
&amp;lt; IsharaComix&amp;gt; YOU SPELLED LISTEN WRONG GOD LOUDBOT YOURE BAD AT THIS&lt;br /&gt;
&amp;lt; LOUDBOT&amp;gt; THIS UNCHECKED AGRESSION WILL NOT STAND  &lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Over time, people grew accustomed to LOUDBOT's presence and the nature of their interactions with it changed. They didn't so much shout at each other anymore, they shouted for the robot to hear, record, and repeat later. The database grew to over 70,000 lines. This was different, and not what I had imagined it would become, but users and systems evolve as they interact with each other. That's neither right nor wrong, it's true and inevitable and interesting.&lt;/p&gt;
&lt;h3&gt;Like the person it was initially created to replace, robots vanish too.&lt;/h3&gt;
&lt;p&gt;Our relationships with robots and systems, like people, are temporary. Trying to hang on to the way things were at the height of a friendship is impossible at best. It's been fun, but this system is stagnant, we've grown apart, and we're on to the getting-together-for-an-awkward-lunch-once-a-year phase of this friendship.&lt;/p&gt;
&lt;p&gt;LOUDBOT isn't my &lt;a href="http://en.wikipedia.org/wiki/Creep_%28Radiohead_song%29"&gt;&lt;em&gt;Creep&lt;/em&gt;&lt;/a&gt;, but it's time to shut it off. I'll always have this ridiculous &lt;a href="http://blog.iank.org/images/loudbot_wordcloud.png"&gt;word cloud&lt;/a&gt;, which is vulgar and awful and I might frame it and put it up on my wall. Thanks, Internet.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;-!- Nate has joined ##church-of-loudbot&lt;br /&gt;
 &amp;lt; Nate&amp;gt; wow it really exists...&lt;br /&gt;
-!- Nate was kicked by CAPSBOT [I CAN'T HEAR YOU, SOLDIER]&lt;br /&gt;
 &amp;lt; HighBit&amp;gt; CURRENT STATUS: GOING TO CHURCH  &lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class="footnote"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn:capscop"&gt;
&lt;p&gt;I'm told the creator of @CapsCop &lt;a href="http://twitter.com/natefanaro/status/7789580746"&gt;secretly loves @LOUDBOT&lt;/a&gt;&amp;#160;&lt;a class="footnote-backref" href="#fnref:capscop" rev="footnote" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</summary><category term="robots"></category><category term="feelings"></category></entry><entry><title>Your Food is Always Outside of You</title><link href="http://blog.iank.org/your-food-is-always-outside-of-you.html" rel="alternate"></link><updated>2014-11-05T17:00:00-05:00</updated><author><name>Ian Kilgore</name></author><id>tag:blog.iank.org,2014-11-05:your-food-is-always-outside-of-you.html</id><summary type="html">&lt;iframe id="ytplayer" type="text/html" width="640" height="390" src="http://www.youtube.com/embed/OyTIqWk-O3E?autoplay=0&amp;origin=http://blog.iank.org" frameborder="0" allowfullscreen&gt;&lt;/iframe&gt;

&lt;p&gt;
&lt;/p&gt;

&lt;p&gt;Yesterday I gave a talk at the &lt;a href="http://lug.ncsu.edu"&gt;NCSU Linux Users' Group&lt;/a&gt; and I've posted the slides and a video here. Not captured in the audio was, after the talk, an impromptu lecture about Hilbert's infinite hotel and then &lt;a href="http://twitter.com/mambocab"&gt;Jim Witschey&lt;/a&gt; came up to talk about the expectation of the Poisson distribution. So it was a good time!&lt;/p&gt;
&lt;p&gt;&lt;a href="http://iank.org/ncsulug_fa14.pdf"&gt;Slides (PDF)&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="http://iank.org/ncsulug_fa14/ncsulug_fa14.html"&gt;References (HTML)&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Here's the original abstract of the talk:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;YOUR FOOD IS ALWAYS OUTSIDE OF YOU&lt;/p&gt;
&lt;p&gt;(Some Ideas About Space But Definitely Not Time)&lt;/p&gt;
&lt;p&gt;ABSTRACT:&lt;/p&gt;
&lt;p&gt;I'm going to, in an accessible way, cover some mathematical and physical ideas that I think are important or at least pretty cool. (CHILL. OUT.) You probably spent a lot of time in grade school factoring polynomials or whatever. I don't care about that. I want to talk about why orbits work, what happens in 5-D, why the World Series is slightly better than a coin toss, databases are broken forever, truth itself is wrong, and what happens if an infinite number of buses roll up at your house. Or some subset of that.&lt;/p&gt;
&lt;p&gt;I'll cover three or four discrete topics, so don't worry if you get lost; you'll be following along again in a few slides. Any equations will be supplementary only- you won't have to understand them to get the general idea.&lt;/p&gt;
&lt;p&gt;Here's what loudbot has to say:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&amp;lt; LOUDBOT&amp;gt; ik: GIVEN YOUR PAST PERFORMANCE THIS MAY QUALIFY AS A MIRACLE&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/blockquote&gt;</summary><category term="talks"></category><category term="physics"></category><category term="geometry"></category><category term="math"></category><category term="topology"></category></entry><entry><title>July 4th with NCSULUG and Thermite</title><link href="http://blog.iank.org/july-4th-with-ncsulug-and-thermite.html" rel="alternate"></link><updated>2014-10-19T17:00:00-04:00</updated><author><name>Ian Kilgore</name></author><id>tag:blog.iank.org,2014-10-19:july-4th-with-ncsulug-and-thermite.html</id><summary type="html">&lt;iframe id="ytplayer" type="text/html" width="640" height="390" src="http://www.youtube.com/embed/M9KByjCi3B4?autoplay=0&amp;origin=http://blog.iank.org" frameborder="0" allowfullscreen&gt;&lt;/iframe&gt;

&lt;p&gt;
&lt;/p&gt;

&lt;p&gt;This past July 4th I got together with the &lt;a href="http://lug.ncsu.edu"&gt;NCSU Linux Users' Group&lt;/a&gt; and brought about 10kg of &lt;a href="http://en.wikipedia.org/wiki/Thermite"&gt;thermite&lt;/a&gt;. Above video was expertly filmed and edited by &lt;a href="http://twitter.com/coxn"&gt;@coxn&lt;/a&gt;. Someone brought a lawnmower. It goes up at about 1:53; we melted straight through the engine block and the rest was in flames almost instantly. Safety precautions were observed.&lt;/p&gt;
&lt;p&gt;The thermite reaction, broadly, is an "exothermic reaction which involves a metal reacting with a metallic [...] oxide to form a more stable oxide and the corresponding metal [...] of the reactant oxide"&amp;nbsp;[&lt;sup id="fnref:wang"&gt;&lt;a class="footnote-ref" href="#fn:wang" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt;].&lt;/p&gt;
&lt;p&gt;A more handwaving and less correct description is that it is a reaction between a metal, usually aluminum, and a metallic oxide, usually iron oxide. The oxygen "switches" between the two, forming aluminum oxide and iron, and producing quite a lot of heat. A typical temperature is on the order of 2,500 kelvins (apx 700 K greater than the melting point of iron).&lt;/p&gt;
&lt;p&gt;A general form for the reaction, from [&lt;sup id="fnref:wang"&gt;&lt;a class="footnote-ref" href="#fn:wang" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt;], is&lt;/p&gt;
&lt;p&gt;\begin{equation}
\mathrm{M} + \mathrm{AO} \rightarrow \mathrm{MO} + \mathrm{A} + \Delta H
\end{equation}&lt;/p&gt;
&lt;p&gt;where M is some metal or alloy (e.g. Al), and A is a suitable metal or non-metal (e.g. Fe). More exotic thermites have been investigated, [&lt;sup id="fnref:wang"&gt;&lt;a class="footnote-ref" href="#fn:wang" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt;] has a good overview.&lt;/p&gt;
&lt;p&gt;In particular, I made several batches using both "red" iron(III) oxide (i.e., rust) and "black" iron(II,III) oxide. They have slightly different properties, which may also have to do with the powder grain size. In the video the black iron oxide reactions are more violent, throwing off clouds of sparks.&lt;/p&gt;
&lt;p&gt;Mixing ratios for various thermites can be found online, and I recomputed them myself as a review of basic chemistry. I've captured the &lt;a href="/images/thermite_stoichiometry.jpg"&gt;relevant page from my notebook&lt;/a&gt; and I'll repeat the process for iron(III) oxide here.&lt;/p&gt;
&lt;p&gt;Substituting&lt;sup id="fnref:ionic"&gt;&lt;a class="footnote-ref" href="#fn:ionic" rel="footnote"&gt;2&lt;/a&gt;&lt;/sup&gt; aluminum and iron(III) oxide into the general equation above we have&lt;/p&gt;
&lt;p&gt;\begin{equation}
\mathrm{Al} + \mathrm{Fe_2O_3} \rightarrow \mathrm{Al_2O_3} + \mathrm{Fe} + \Delta H
\end{equation}&lt;/p&gt;
&lt;p&gt;&lt;a href="http://en.wikipedia.org/wiki/Chemical_equation#Balancing_chemical_equations"&gt;Balanced&lt;/a&gt;, this becomes&lt;/p&gt;
&lt;p&gt;\begin{equation}
2\mathrm{Al} + \mathrm{Fe_2O_3} \rightarrow \mathrm{Al_2O_3} + 2\mathrm{Fe} + \Delta H
\end{equation}&lt;/p&gt;
&lt;p&gt;Now work out the &lt;a href="http://en.wikipedia.org/wiki/Stoichiometry"&gt;stoichiometric&lt;/a&gt; ratio‚Äî convert the equation above, which is in terms of molecules, into an equation in terms of mass. This is done using the &lt;a href="http://en.wikipedia.org/wiki/Mole_(unit)"&gt;molar&lt;/a&gt; mass of each term and the result is the ideal ratio of reactants in terms of their mass.&lt;/p&gt;
&lt;p&gt;Aluminum has a molar mass of 26.982 g/mol, and iron(III) oxide has 159.687 g/mol (which can be worked out from the molar masses of iron and oxygen using $\mathrm{Fe}_2\mathrm{O}_3$). Taking (from the equation above) 2 mol Al per 1 mol $\mathrm{Fe}_2\mathrm{O}_3$ we have 53.964g Al per 159.687g $\mathrm{Fe}_2\mathrm{O}_3$, or a ratio of &lt;strong&gt;1:2.959&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Igniting thermite is difficult, requiring a tremendous temperature to get the reaction going. I used magnesium ribbon, which burns at around 3,100 &amp;deg;C. Magnesium ribbon itself is only slightly easier to ignite‚Äî it autoignites at 473 &amp;deg;C. I used a propane torch (1,995 &amp;deg;C) to light the magnesium.&lt;/p&gt;
&lt;p&gt;Once the reaction starts, there is no good way to stop it as it contains its own oxidizer. Best to do it in a clear area. We kept a fire extinguisher on hand for &lt;em&gt;after&lt;/em&gt; the reaction in case anything else caught. One of the worst possible ideas is to dump water on it‚Äî this will cause a steam explosion, so don't do that. Have some eye protection for the &lt;a href="http://en.wikipedia.org/wiki/Ultraviolet"&gt;UVs&lt;/a&gt;.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn:wang"&gt;
&lt;p&gt;Wang, L_L, Z.A. Munir, and Yu M. Maximov. "Thermite reactions: their utilization in the synthesis and processing of materials." &lt;em&gt;Journal of Materials Science&lt;/em&gt; 28, no. 14 (1993): 3693-3708.&amp;#160;&lt;a class="footnote-backref" href="#fnref:wang" rev="footnote" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:ionic"&gt;
&lt;p&gt;It is also necessary to remember about ionic bonds and valence electrons to find the correct form for aluminum oxide.&amp;#160;&lt;a class="footnote-backref" href="#fnref:ionic" rev="footnote" title="Jump back to footnote 2 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</summary><category term="thermite"></category><category term="america"></category><category term="freedom"></category><category term="chemistry"></category><category term="nerds"></category></entry><entry><title>Programmatically-Generated LaTeX Sieve of Eratosthenes</title><link href="http://blog.iank.org/programmatically-generated-latex-sieve-of-eratosthenes.html" rel="alternate"></link><updated>2014-09-11T01:26:00-04:00</updated><author><name>Ian Kilgore</name></author><id>tag:blog.iank.org,2014-09-11:programmatically-generated-latex-sieve-of-eratosthenes.html</id><summary type="html">&lt;!-- did a lightning talk about this: https://www.youtube.com/watch?v=mTfw3useXro#t=1h28m40s --&gt;

&lt;p&gt;(tl;dr: see &lt;a href="/pdf/sieve.pdf"&gt;PDF here&lt;/a&gt;). For a top-secret joke project I am learning to program in LaTeX as if it were a general-purpose language. LaTeX is my favourite way to write scientific papers, but no one should use it for programmatic logic. Along the way I have implemented a &lt;a href="http://en.wikipedia.org/wiki/Sieve_of_Eratosthenes"&gt;Sieve of Eratosthenes&lt;/a&gt;, a well-known algorithm for finding prime numbers. The natural typesetting ability of LaTeX allows me to easily generate an intuitive representation of the inner working of the algorithm.&lt;/p&gt;
&lt;p&gt;&lt;img style="float: center" src="/images/sieve_100.png" alt="Sieve of Eratosthenes"&gt;&lt;/p&gt;
&lt;p&gt;Watch my rapid descent into TeX-induced insanity in my &lt;a href="https://github.com/iank/latex-hacks/"&gt;Github repository&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I first implemented &lt;a href="http://blog.codinghorror.com/why-cant-programmers-program/"&gt;FizzBuzz&lt;/a&gt; using the LaTeX packages&lt;sup id="fnref:rawtex"&gt;&lt;a class="footnote-ref" href="#fn:rawtex" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt; "ifthen", "intcalc", and "forloop", which got me conditionals, simple arithmetic, and a useful control structure, respectively.&lt;/p&gt;
&lt;p&gt;Then I found a brilliant "array" mechanism on the &lt;a href="http://tex.stackexchange.com/questions/37426/create-an-array-of-variables"&gt;TeX StackExchange&lt;/a&gt;, which I adapted to allow me to implement a &lt;a href="https://github.com/iank/latex-hacks/blob/master/sieve/sieve_ugly.tex"&gt;simple sieve (source)&lt;/a&gt;, the output of which is &lt;a href="/pdf/sieve_ugly.pdf"&gt;an ugly numeric list (PDF)&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;But I thought I could have LaTeX represent the internal state of the algorithm as a colour-coded matrix at each point in its operation. I'm quite pleased with &lt;a href="/pdf/sieve.pdf"&gt;the result (PDF)&lt;/a&gt;, &lt;a href="https://github.com/iank/latex-hacks/blob/master/sieve/sieve.tex"&gt;(source)&lt;/a&gt; which I think is an intuitive representation of how this simple algorithm works.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn:rawtex"&gt;
&lt;p&gt;This can all be done in raw TeX, but I'm not a maniac.&amp;#160;&lt;a class="footnote-backref" href="#fnref:rawtex" rev="footnote" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</summary><category term="LaTeX"></category><category term="jokes"></category><category term="math"></category></entry><entry><title>Inverse-Square Laws: A Physical Consequence of the Geometry of Space</title><link href="http://blog.iank.org/inverse-square-laws-a-physical-consequence-of-the-geometry-of-space.html" rel="alternate"></link><updated>2014-09-10T16:39:00-04:00</updated><author><name>Ian Kilgore</name></author><id>tag:blog.iank.org,2014-09-10:inverse-square-laws-a-physical-consequence-of-the-geometry-of-space.html</id><summary type="html">&lt;p&gt;John D. Barrow's &lt;a href="https://www.goodreads.com/book/show/18926355-the-constants-of-nature?ac=1"&gt;&lt;em&gt;The Constants of Nature&lt;/em&gt;&lt;/a&gt;&lt;sup id="fnref:barrow"&gt;&lt;a class="footnote-ref" href="#fn:barrow" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt; mentions that Kant may have been the first to notice a connection between the dimensionality of space and physical inverse-square laws, such as &lt;a href="http://en.wikipedia.org/wiki/Newton's_law_of_universal_gravitation"&gt;Newton's law of universal gravitation&lt;/a&gt;:&lt;/p&gt;
&lt;p&gt;\begin{equation}
F = G\frac{m_1 m_2}{r^2}
\end{equation}&lt;/p&gt;
&lt;p&gt;This is interesting. Inverse-square laws are &lt;a href="http://en.wikipedia.org/wiki/Inverse-square_law#Occurrences"&gt;everywhere&lt;/a&gt;, and 3D space really does appear to be special&lt;sup id="fnref:ehrenfest"&gt;&lt;a class="footnote-ref" href="#fn:ehrenfest" rel="footnote"&gt;3&lt;/a&gt;&lt;/sup&gt;. Among other things, &lt;a href="http://en.wikipedia.org/wiki/Bertrand's_theorem"&gt;stable orbits depend on it&lt;/a&gt;. I first encountered, or at least noticed, the geometric reason for inverse-square laws in an electrodynamics and antenna theory lecture on &lt;a href="http://en.wikipedia.org/wiki/Free-space_path_loss"&gt;free-space path loss (FSPL)&lt;/a&gt;, which says that the power of a received signal in free space also has a $r^{-2}$ distance dependence.&lt;/p&gt;
&lt;p&gt;It is easy to understand this by picturing a point source radiating equally in all directions, i.e. spherically. Spherical symmetry is common in nature. At a distance $r$, the power is "spread out" over the surface of an imaginary sphere having area $4\pi r^2$. A similar argument can be made for gravity.&lt;/p&gt;
&lt;p&gt;This image (by &lt;a href="http://en.wikipedia.org/wiki/File:Inverse_square_law.svg"&gt;Borb&lt;/a&gt;, licensed under CC-BY-SA) helps illustrate the idea. At each distance $d$ the same total effect is distributed over an area $d^2$:&lt;/p&gt;
&lt;p&gt;&lt;img style="float: center" src="/images/500px-Inverse_square_law.svg.png" alt="Point source acting over a spherical area"&gt;&lt;/p&gt;
&lt;p&gt;This is clearly a consequence of the dimensionality of space as a sphere surface area scales with r^2 in 3-space. In general, an N-dimensional&lt;sup id="fnref:convention"&gt;&lt;a class="footnote-ref" href="#fn:convention" rel="footnote"&gt;4&lt;/a&gt;&lt;/sup&gt; sphere has surface area which scales with $r^{N-1}$. So in 4D space, other things being equal&lt;sup id="fnref:equal"&gt;&lt;a class="footnote-ref" href="#fn:equal" rel="footnote"&gt;5&lt;/a&gt;&lt;/sup&gt;, we would experience inverse-cube gravitation, electromagnetism, acoustics, and so on.&lt;/p&gt;
&lt;p&gt;Back to Kant. In his first published work (1747), "Thoughts on the true estimation of living forces"&lt;sup id="fnref:kant"&gt;&lt;a class="footnote-ref" href="#fn:kant" rel="footnote"&gt;2&lt;/a&gt;&lt;/sup&gt;, Kant argues (Section 9) that space would not exist "if substances had no forces to act external to themselves". This leads him in Section 10 to ague that 3-dimensional space is a consequence of inverse-square gravity. Kant concludes that the inverse-square law is arbitrary and that "God could have chosen another, e.g., the inverse-cube relation" and that this would have resulted in a different sort of space. He goes on to suggest, (well before the development of anything like modern topology or differential geometry), that these spatial possibilities ought to be investigated.&lt;/p&gt;
&lt;p&gt;It would seem that Kant got it backward, but Kant was like that.&lt;/p&gt;
&lt;p&gt;Nonetheless, these insights (and others&lt;sup id="fnref:misc"&gt;&lt;a class="footnote-ref" href="#fn:misc" rel="footnote"&gt;6&lt;/a&gt;&lt;/sup&gt;) show that an important feature of many natural laws depends on "pure" geometrical truth moreso than physical reality; the inverse-square dependence is not due to an arbitrary constant exponent but the (admittedly, possibly arbitrary) dimensionality of space.&lt;/p&gt;
&lt;p&gt;The Greeks would be proud.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn:barrow"&gt;
&lt;p&gt;Barrow, John D, "New Dimensions," in &lt;em&gt;The Constants of Nature&lt;/em&gt;. (New York: Random House, 2002), pp. 203-205&amp;#160;&lt;a class="footnote-backref" href="#fnref:barrow" rev="footnote" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:kant"&gt;
&lt;p&gt;Kant, Immanuel, "Thoughts on the true estimation of living forces" in &lt;em&gt;Kant: Natural Science&lt;/em&gt;, ed. Eric Watkins. 1st ed. (Cambridge: Cambridge University Press, 2012). pp. 26-28. Cambridge Books Online. Web. 10 September 2014. http://dx.doi.org/10.1017/CBO9781139014380.004&amp;#160;&lt;a class="footnote-backref" href="#fnref:kant" rev="footnote" title="Jump back to footnote 2 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:ehrenfest"&gt;
&lt;p&gt;Ehrenfest, Paul. "In what way does it become manifest in the fundamental laws of physics that space has three dimensions." Proc. Royal Netherlands Acad. Arts Sci 20 (1917): 200-209.&amp;#160;&lt;a class="footnote-backref" href="#fnref:ehrenfest" rev="footnote" title="Jump back to footnote 3 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:convention"&gt;
&lt;p&gt;By &lt;a href="http://mathworld.wolfram.com/Hypersphere.html"&gt;geometer's conventions&lt;/a&gt;. A topologist would call a 3D sphere a 2-sphere, as the surface has two dimensions.&amp;#160;&lt;a class="footnote-backref" href="#fnref:convention" rev="footnote" title="Jump back to footnote 4 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:equal"&gt;
&lt;p&gt;To the extent that it is possible for anything else to remain the same, i.e. "probably not."&amp;#160;&lt;a class="footnote-backref" href="#fnref:equal" rev="footnote" title="Jump back to footnote 5 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:misc"&gt;
&lt;p&gt;2D and 3D spaces have many other special properties. See Ehrenfest (above) about rotation and wave propagation, Polya's work on the random walk on 2D, and Bertrand's Theorem.&amp;#160;&lt;a class="footnote-backref" href="#fnref:misc" rev="footnote" title="Jump back to footnote 6 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</summary><category term="physics"></category><category term="geometry"></category><category term="kant"></category><category term="math"></category></entry><entry><title>A Localized Path-Finding Genetic Algorithm</title><link href="http://blog.iank.org/a-localized-path-finding-genetic-algorithm.html" rel="alternate"></link><updated>2013-08-17T19:30:00-04:00</updated><author><name>Ian Kilgore</name></author><id>tag:blog.iank.org,2013-08-17:a-localized-path-finding-genetic-algorithm.html</id><summary type="html">&lt;h3&gt;Localized Path-Finding&lt;/h3&gt;
&lt;p&gt;Below I implement a genetic algorithm which attempts the following problem:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Find a model which can, as an autonomous agent, traverse the lowest-cost path across some weighted map using only local information.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;If this agent had prior knowledge of the entire map, determining the best path across it would be an objective (and well-studied) matter. In the following I attempt to train an agent to solve this problem with limited (local) information. These agents make decisions based only on four numbers: the relative heights of the terrain one "move" away in each of four directions (i.e., they can see no further than they can move).&lt;/p&gt;
&lt;p&gt;On a uniformly-weighted space the lowest-cost path is simply the shortest, but here cost may be a proxy for difficult or rough terrain, or an abstraction. Below I will discuss the formulation and implications of the cost function used.&lt;/p&gt;
&lt;h3&gt;Terrain and Sample Problem&lt;/h3&gt;
&lt;p&gt;&lt;a href="/images/erasmus/problem_ex.png"&gt;&lt;img alt="Example Depth Map With Source, Destination, and Two Possible Paths" src="/images/erasmus/problem_ex_t.png" title="Example Depth Map With Source, Destination, and Two Possible Paths" /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The figure above shows one possible problem space. The grey levels in the image can be understood as a height map, with lighter pixels representing higher altitudes. The red circle is a starting position, and an agent must attempt to cross the vertical green line on the right border of the image. Shown in yellow and blue are two possible paths from source to destination.&lt;/p&gt;
&lt;p&gt;A successful agent should strike a balance between the shortest path and one that involves the least amount of steep climbs or descents. It should attempt to follow altitude contours when possible, but occasionally climb (or descend) a hill for a significant shortcut.&lt;/p&gt;
&lt;p&gt;Readers uninterested in the details of implementation may wish to skip to &lt;a href="#results"&gt;results&lt;/a&gt; below.&lt;/p&gt;
&lt;h3&gt;Cost Function&lt;/h3&gt;
&lt;p&gt;It is intuitive that the yellow, longer path is a worse solution than the blue, straightforward one. This notion can be made objective by computing a cost which is equal to the length of the path. I also discretize the problem: an agent only moves in quantum steps of length $\epsilon$, where $\epsilon$ is measured in pixels. This cost function is then proportional (or equal) to $N$, the number of steps required to complete the path:&lt;/p&gt;
&lt;p&gt;\begin{equation}
C = N
\end{equation}&lt;/p&gt;
&lt;p&gt;The shortest path (a straight line) is now always the best path, so this cost function must be augmented to take changes in altitude into account. The cost calculation becomes:&lt;/p&gt;
&lt;p&gt;\begin{equation}
C = \sum\limits_{n=1}^N g_n^2 + \lambda N
\end{equation}&lt;/p&gt;
&lt;p&gt;where&amp;lt;&lt;/p&gt;
&lt;p&gt;\begin{equation}
g_n =
\begin{cases}
\Delta_n, &amp;amp; \text{if }\Delta_n \geq 0\
-\frac{\Delta_n}{2}, &amp;amp; \text{if }\Delta_n &amp;lt; 0
\end{cases}
\end{equation}&lt;/p&gt;
&lt;p&gt;for each step $g_n$ along the path. $\Delta_n$ is the change in height for that step. This cost is a function of both path length and the amount of climbing and descending one must do to complete the path. Note that cost scales with $g_n$ squared, meaning that very steep climbs and descents are penalized more strongly than shallow ones. Also, the cost for a descent is less than for a climb, but still positive (consider driving a vehicle down a steep, unpaved slope).&lt;/p&gt;
&lt;p&gt;The parameter $\lambda$ controls the trade-off in cost between path length and altitude change: when $\lambda$ is very large, the path length component dominates and shorter paths will be selected at the cost of climbing. When $\lambda$ is very small, paths which minimize climbing will be favoured.&lt;/p&gt;
&lt;p&gt;Finally, many agents never find a complete path. A (very large) fixed-cost penalty, $Q$, is added to their total costs.&lt;/p&gt;
&lt;h3&gt;Agent Model&lt;/h3&gt;
&lt;h4&gt;Model Input&lt;/h4&gt;
&lt;p&gt;I model an agent as a function which, at each step, decides which direction to move based on information about the relative height of its immediate surroundings. The input at each step, $\mathbf{x}$, is a vector of length $d$ of (an approximation of) the directional derivatives around the agent's current position:&lt;/p&gt;
&lt;p&gt;\begin{equation}
x_i = \frac{h([x,y] + \epsilon\angle\theta_i)-h([x,y])}{\epsilon} \text{ for } i=1,...,d
\end{equation}&lt;/p&gt;
&lt;p&gt;Here $h(x,y)$ represents the height at position $(x,y)$. The angles $\theta_i$ are spaced evenly along the unit circle. So the vector $\mathbf{x}$ is the difference in height between an agent's current position and $d$ surrounding locations which are $\epsilon$ units away. For a differentiable surface, the gradient of $h(x,y)$ is sufficient to describe it, but for this approximate model I have chosen $d=4$.&lt;/p&gt;
&lt;h4&gt;Model Parameters and Output&lt;/h4&gt;
&lt;p&gt;At each step the agent must decide a new direction in which to move. This should be an angle, $\phi$, between $\pi$ and $-\pi$. The model becomes a function $A$ of $\mathbf{x}$, parameterized by some unknown vector $\alpha$:&lt;/p&gt;
&lt;p&gt;\begin{equation}
\hat{\phi} = A_\mathbf{\alpha}(\mathbf{x})
\end{equation}&lt;/p&gt;
&lt;p&gt;The core of this model, $\mathbf{\alpha}^\top\mathbf{x}$, is a simple linear combination of the parameters, $\mathbf{\alpha}$, and the input vector $\mathbf{x}$. The output is then "squished" with a sigmoid function and normalized between $-\pi$ and $\pi$:&lt;/p&gt;
&lt;p&gt;\begin{equation}
A_\mathbf{\alpha}(\mathbf{x}) = 2\pi\left(\frac{1}{1+exp(\mathbf{\alpha}^\top\mathbf{x})}-0.5\right)
\end{equation}&lt;/p&gt;
&lt;p&gt;I show below that a model with only $d=4$ parameters is sufficient for reasonable performance as a path-finding agent. A genetic algorithm, below, is used to find near-optimal values for these four parameters.&lt;/p&gt;
&lt;h3&gt;Genetic Algorithm&lt;/h3&gt;
&lt;p&gt;A &lt;a href="http://en.wikipedia.org/wiki/Genetic_algorithm"&gt;genetic algorithm&lt;/a&gt; attempts to solve an optimization problem by mimicking evolution. Genetic algorithms are well-studied, so I will describe only my implementation for this problem. I represent each individual as a list of floating-point "genes" (in this case, each individual has four genes corresponding to the model parameters $\mathbf{\alpha}$.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;An initial population of $P=200$ individual agents is randomly generated. I initialize weights using a long-tailed t distribution. This encourages diversity in the gene pool by creating a few more relatively large weights (as opposed to a normal distribution) [&lt;sup id="fnref:montana"&gt;&lt;a class="footnote-ref" href="#fn:montana" rel="footnote"&gt;3&lt;/a&gt;&lt;/sup&gt;].&lt;/li&gt;
&lt;li&gt;Each agent is run and its total cost computed&lt;/li&gt;
&lt;li&gt;The best individual from the previous generation is carried over unchanged. This is referred to as elitism, and prevents the algorithm from throwing away the most fit individual through crossover or mutation [&lt;sup id="fnref:rudolph"&gt;&lt;a class="footnote-ref" href="#fn:rudolph" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt;]. It has also been shown to decrease convergence time [&lt;sup id="fnref:zitzler"&gt;&lt;a class="footnote-ref" href="#fn:zitzler" rel="footnote"&gt;2&lt;/a&gt;&lt;/sup&gt;].&lt;/li&gt;
&lt;li&gt;A new population is bred:&lt;ul&gt;
&lt;li&gt;Two parents are selected with probability proportional to the reciprocal of their associated cost&lt;/li&gt;
&lt;li&gt;The two parents are combined using two-point crossover, creating a child individual&lt;/li&gt;
&lt;li&gt;These children are mutated by adding a small random offset to each gene with a 4% probability.&lt;/li&gt;
&lt;li&gt;This is repeated until 90% of the new generation has been created&lt;/li&gt;
&lt;li&gt;The remaining 10% of the new generation are initialized randomly&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Results&lt;/h3&gt;
&lt;p&gt;&lt;a name="results"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h4&gt;GA vs Control&lt;/h4&gt;
&lt;p&gt;In order to demonstrate that the genetic algorithm is productively solving this problem, I compare it to a control. The control algorithm keeps the best individual from the previous generation, as in the GA. Every other individual, however, is randomly generated. The following figures show that a genetic algorithm (first) outperforms a random search (second) of the parameter space. The cost function here has been tuned to discourage climbing in favour of longer, contour-following paths.&lt;/p&gt;
&lt;p&gt;&lt;a href="/images/erasmus/gavs.png"&gt;&lt;img alt="Path taken by best agent found by genetic algorithm" src="/images/erasmus/gavs_t.png" title="Path taken by best agent found by genetic algorithm" /&gt;&lt;/a&gt;
&lt;a href="/images/erasmus/rndvs.png"&gt;&lt;img alt="Path taken by best agent found by random selection" src="/images/erasmus/rndvs_t.png" title="Path taken by best agent found by random selection" /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h4&gt;Evolution of Best Path&lt;/h4&gt;
&lt;p&gt;In the figures below, the best path for several different generations is evolved. The algorithm finds a global solution fairly quickly, and then optimizes certain local difficulties. The first image, below, shows the initial (random) best path, which does not reach the objective. After a few generations, a reasonable solution has been found but three problem areas (outlined in blue) remain. The next row of images focus on only the lower-right problem area. We see that the path, while initially confused, begins to straighten out after several generations.&lt;/p&gt;
&lt;p&gt;&lt;a href="images/erasmus/evolution.txt"&gt;Text output from this experiment&lt;/a&gt; is available. It is possible here to see how the percentage of the population which sucessfully completes any route grows as successful individuals are selected to reproduce.&lt;/p&gt;
&lt;p&gt;&lt;a href="/images/erasmus/gen01_t.png"&gt;&lt;img alt="Initial (random) solution" src="/images/erasmus/gen01_t.png" title="Initial (random) solution" /&gt;&lt;/a&gt;
&lt;a href="/images/erasmus/gen11_t.png"&gt;&lt;img alt="Global (coarse) solution found after 11 generations. Local problem areas outlined in blue." src="/images/erasmus/gen11_t.png" title="Global (coarse) solution found after 11 generations. Local problem areas outlined in blue." /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="/images/erasmus/gen11_p1_t.png"&gt;&lt;img alt="Local problem area w/in global/coarse solution" src="/images/erasmus/gen11_p1_t.png" title="Local problem area w/in global/coarse solution" /&gt;&lt;/a&gt;
&lt;a href="/images/erasmus/gen15_p2_t.png"&gt;&lt;img alt="Iteration upon problem area" src="/images/erasmus/gen15_p2_t.png" title="Iteration upon problem area" /&gt;&lt;/a&gt;
&lt;a href="/images/erasmus/gen22_p3_t.png"&gt;&lt;img alt="Iteration upon problem area" src="/images/erasmus/gen22_p3_t.png" title="Iteration upon problem area" /&gt;&lt;/a&gt;
&lt;a href="/images/erasmus/gen36_p4_t.png"&gt;&lt;img alt="Iteration upon problem area" src="/images/erasmus/gen36_p4_t.png" title="Iteration upon problem area" /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h4&gt;Step Cost and Differentiability&lt;/h4&gt;
&lt;p&gt;Although the best path in the previous section eventually became somewhat smooth, its jagged nature can be improved upon. The jaggedness of that path can be attributed to two factors:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The images in the previous section were generated using a low step cost $\lambda$. This low step cost does not serve well to discourage too-long paths.&lt;/li&gt;
&lt;li&gt;The image used as a map is discontinuous (i.e. not differentiable) at the transitions between white and black. In this case the agent has no information about the upcoming cliff until it hits it. It cannot choose an intermediate angle and must proceed in a zig/zag fashion.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;By smoothing the image (by a 20x20 boxcar filter) and increasing the step cost, we can find a much better route through the image. From left to right:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;In the first figure below, the problem is demonstrated. The image is discontinuous, and $\lambda=0.001$.&lt;/li&gt;
&lt;li&gt;In the second figure, the image has been smoothed, but the step cost remains $\lambda=0.001$.&lt;/li&gt;
&lt;li&gt;Next, the step cost is increased to $\lambda=50$&lt;/li&gt;
&lt;li&gt;Next, the step cost is increased to $\lambda=1000$, and we see a relatively smooth path.&lt;/li&gt;
&lt;li&gt;Finally, we are shown a global view of the previous image (with $\lambda=1000$), showing the smoother path. Also note that some shortcuts have been taken.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href="/images/erasmus/soln4_t.png"&gt;&lt;img alt="Zig-zag path due to low step cost and discontinuous image" src="/images/erasmus/soln4_t.png" title="Zig-zag path due to low step cost and discontinuous image" /&gt;&lt;/a&gt;
&lt;a href="/images/erasmus/soln1_t.png"&gt;&lt;img alt="Problem is ameliorated by smoothing the image" src="/images/erasmus/soln1_t.png" title="Problem is ameliorated by smoothing the image" /&gt;&lt;/a&gt;
&lt;a href="/images/erasmus/soln2_t.png"&gt;&lt;img alt="Step cost is increased to lambda=50 resulting in a shorter path" src="/images/erasmus/soln2_t.png" title="Step cost is increased to lambda=50 resulting in a shorter path" /&gt;&lt;/a&gt;
&lt;a href="/images/erasmus/soln3_t.png"&gt;&lt;img alt="Further increase in step cost (lambda=1000) results in a shorter, smoother path" src="/images/erasmus/soln3_t.png" title="Further increase in step cost (lambda=1000) results in a shorter, smoother path" /&gt;&lt;/a&gt;
&lt;a href="/images/erasmus/soln3_global_t.png"&gt;&lt;img alt="Global view of previous image" src="/images/erasmus/soln3_global_t.png" title="Global view of previous image" /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h4&gt;Generalization&lt;/h4&gt;
&lt;p&gt;A simple experiment shows that these agents have some limited capacity for generalization. An agent was trained on a perlin noise depth map using an initial position near the centre of the image. It proceeded to its goal while attempting to maintain the same altitude throughout. The same agent was then run starting at the far left of the image (at a different altitude) and then found a reasonable path to its goal, again maintaining a relatively uniform altitude throughout.&lt;/p&gt;
&lt;p&gt;&lt;a href="/images/erasmus/bestroute_trained_t.png"&gt;&lt;img alt="Best route found during training" src="/images/erasmus/bestroute_trained_t.png" title="Best route found during training" /&gt;&lt;/a&gt;
&lt;a href="/images/erasmus/bestroute_generalized_t.png"&gt;&lt;img alt="Same agent released at a different starting position" src="/images/erasmus/bestroute_generalized_t.png" title="Same agent released at a different starting position" /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This capacity for generalization has limits. In the following example, there is a conduit through the image with a fork. One fork is a route through, and the other is not. Because these agents work using only local knowledge, it is impossible to determine a priori which path is best (It is impossible for even a truly intelligent agent to choose the correct path given only the information at hand).&lt;/p&gt;
&lt;p&gt;&lt;a href="/images/erasmus/gen01_t.png"&gt;&lt;img alt="Trained agent on forked path finds a way through" src="/images/erasmus/gen01_t.png" title="Trained agent on forked path finds a way through" /&gt;&lt;/a&gt;
&lt;a href="/images/erasmus/gen01_t.png"&gt;&lt;img alt="Same agent with the forks reversed fails to find the best route" src="/images/erasmus/gen01_t.png" title="Same agent with the forks reversed fails to find the best route" /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Code&lt;/h3&gt;
&lt;p&gt;MATLAB code for this demo may be found on github: &lt;a href="https://github.com/iank/erasmus"&gt;iank/erasmus&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;References&lt;/h3&gt;
&lt;div class="footnote"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn:rudolph"&gt;
&lt;p&gt;G. Rudolph. Evolutionary search for minimal elements in partially ordered Ô¨Ånite sets. In V. W. Porto, N. Saravanan, D. Waagen, and A. E. Eiben, editors, &lt;em&gt;Evolutionary Programming VII, Proceedings of the 7th Annual Conference on Evolutionary Programming&lt;/em&gt;, pages 345‚Äì353. Springer, Berlin, 1998.&amp;#160;&lt;a class="footnote-backref" href="#fnref:rudolph" rev="footnote" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:zitzler"&gt;
&lt;p&gt;E. Zitzler, K. Deb, and L. Thiele. Comparison of Multiobjective Evolutionary Algorithms: Empirical Results. &lt;em&gt;Evolutionary Computation&lt;/em&gt; 8.2 (2000): 173-195.&amp;#160;&lt;a class="footnote-backref" href="#fnref:zitzler" rev="footnote" title="Jump back to footnote 2 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:montana"&gt;
&lt;p&gt;D. Montana and L. Davis. Training Feedforward Neural Networks Using Genetic Algorithms. &lt;em&gt;IJCAI&lt;/em&gt;, vol. 89 (1989): 762-767&amp;#160;&lt;a class="footnote-backref" href="#fnref:montana" rev="footnote" title="Jump back to footnote 3 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</summary><category term="computer math"></category><category term="genetic algorithm"></category><category term="models"></category><category term="machine learning"></category></entry><entry><title>Autorouting PCBs</title><link href="http://blog.iank.org/autorouting-pcbs.html" rel="alternate"></link><updated>2013-08-11T18:30:00-04:00</updated><author><name>Ian Kilgore</name></author><id>tag:blog.iank.org,2013-08-11:autorouting-pcbs.html</id><summary type="html">&lt;h3&gt;Problem&lt;/h3&gt;
&lt;p&gt;&lt;a href="http://en.wikipedia.org/wiki/Routing_(electronic_design_automation)"&gt;Routing&lt;/a&gt;, in electronic design, is a difficult and often intractible problem. Usually it is done with at least some human intervention. Most Electronic Design Automation packages include sophisticated software tools to allow the routing process to be machine-assisted or, in some cases, entirely automatic. Below I investigate some of the simplest methods for solving this problem, and demonstrate a working (albeit trivial) example of an automated approach.&lt;/p&gt;
&lt;p&gt;The problem of routing deals with 'nets', which are lists of pins or pads which must be connected by some conductor. Also, different nets should not be electrically connected. This class of error is called a 'short'. Shorts with other nets can be avoided when routing a net by:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Simply routing around any existing routes which are in the way (as in Tron)&lt;/li&gt;
&lt;li&gt;Using multiple layers to allow routes to avoid each other 'vertically'. This requires placing &lt;a href="http://en.wikipedia.org/wiki/Via_(electronics)"&gt;vias&lt;/a&gt;, which introduces additional cost.&lt;/li&gt;
&lt;li&gt;As a last resort, a jumper wire can be introduced in order to complete a route.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Other design rules must be obeyed. In the case of printed circuit boards, fabrication processes have minimum trace widths, spacing tolerances, and so on. Wire length must be minimized and, depending on the domain, there are other electrical constraints to be considered.&lt;/p&gt;
&lt;h3&gt;Method&lt;/h3&gt;
&lt;p&gt;Several simple algorithms are described in [&lt;sup id="fnref:zhou"&gt;&lt;a class="footnote-ref" href="#fn:zhou" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt;] below. The Lee Algorithm is straightforward, and can be used to route nets with multiple nodes. Routing can also take place on a weighted grid. Instead of minimizing wire length (as if all weights were unity), we then attempt to find paths with minimum cost. In future problems I assign weights in order to discourage (but still allow, as a first pass) errors such as shorts or design rule violations. In the demonstration below, however, all weights are either unity or infinity (blocked cells, e.g. pads and already-routed tracks).&lt;/p&gt;
&lt;p&gt;This approach finds many possible paths from some source[s] to a destination node by wave propagation, then picks the lowest-cost path by tracing backwards. It may be useful to skip to the &lt;a href="#vis"&gt;visualization&lt;/a&gt; below before proceeding.&lt;/p&gt;
&lt;h4&gt;Routing a single net&lt;/h4&gt;
&lt;p&gt;Setting aside for a moment the problem of choosing the order in which nets should be routed, we consider the problem of finding the best (or lowest-cost) route to a grid cell $T$ from one or many cells $\vec{S}$ (In the case of a three-node net in which two nodes have already been routed, we may connect the remaining node to any point in $\vec{S}$).&lt;/p&gt;
&lt;p&gt;This approach finds many possible paths to $T$ from $\vec{S}$ by propagating a wave from $\vec{S}$. We begin by considering the neighbors of $\vec{S}$, and marking them with the cost to reach each cell.&lt;/p&gt;
&lt;p&gt;For each $S_i$ in $\vec{S}$:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Update cost to reach each neighbor, $N_j$ of $S_i$: $cost(N_j) = cost(S_i) + weight(N_j)$&lt;/li&gt;
&lt;li&gt;(Some $N_j$ may already be marked. If so, only update if the new cost is less than the current)&lt;/li&gt;
&lt;li&gt;Stop once we reach $T$. In the case of a weighted grid, we should proceed until the route surronds $T$, in case a lower-cost path can be realized by approaching from a different direction.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;An example of a propagated wave from $S$ to $T$ (labelled) is shown below. The deep red inclusions in the wave are cells with infinite weight (obstacles or pads belonging to different nets).&lt;/p&gt;
&lt;p&gt;&lt;a href="/images/waveprop.png"&gt;&lt;img alt="Wave from S to T showing many possible paths" src="/images/waveprop_t.png" /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Now that each cell has been marked with a cost, the total cost for each discovered path can be computed by the sum of the cost for each cell along the way. The lowest-cost path can be discovered more simply, by backtracing a path from $T$ to any $S$. (Simply follow the lowest-cost neighboring cell until an $S$ is reached).&lt;/p&gt;
&lt;h4&gt;Routing order&lt;/h4&gt;
&lt;p&gt;One way to decide the order in which to route nets is to "order the nets in the ascending order of the [number] of pins within their bounding boxes&lt;sup id="fnref:zhou"&gt;&lt;a class="footnote-ref" href="#fn:zhou" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt;." This seeks to avoid enclosing or intersecting other would-be routes by routing the least extensive nets first. In the example below, this approach is successful.&lt;/p&gt;
&lt;p&gt;In practice, this may not lead to the best order. Other approaches require many passes: route order is chosen in some random fashion and nets are heuristically routed and 'ripped up' until all nets are routed, all possibilities are exhausted, or some time limit is exceeded.&lt;/p&gt;
&lt;h3&gt;Demo&lt;/h3&gt;
&lt;p&gt;I constructed an approximate grid based on the PCB for this &lt;a href="http://www.learningelectronics.net/circuits/fridge-door-open-alarm-circuit-project.html"&gt;fridge "door open" alarm&lt;/a&gt; project. The first figure below is the PCB from that project (I did not create it). The second figure is like a topological approximation. I have not preserved the scale. The node colours represent net membership, i.e. all of the light red nodes must be connected to each other through the routing process. The rightmost figure shows the final routed PCB.&lt;/p&gt;
&lt;p&gt;&lt;a href="/images/orig.jpg"&gt;&lt;img alt="Original PCB layout" src="/images/orig_t.jpg" title="Original PCB layout" /&gt;&lt;/a&gt;
&lt;a href="/images/unrouted.png"&gt;&lt;img alt="My approximated model - unrouted" src="/images/unrouted_t.png" title="My approximated model - unrouted" /&gt;&lt;/a&gt;
&lt;a href="/images/routed.png"&gt;&lt;img alt="Routed" src="/images/routed_t.png" title="Routed" /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Below is an animation of this grid being routed by the method described above:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The routing order is determined by the number of pins w/in a net's bounding box (not shown)&lt;/li&gt;
&lt;li&gt;For each net (in order), until it is fully routed or unroutable:&lt;ul&gt;
&lt;li&gt;Pick a source grid cell, $S$, at random (or, if partially routed, use the entire routed portion as a source)&lt;/li&gt;
&lt;li&gt;Pick the closest destination, $T$. This is the single blue cell shown in the upper subplot&lt;/li&gt;
&lt;li&gt;Propagate wave from $S$ to $T$ across the weighted grid (Top Subplot)&lt;/li&gt;
&lt;li&gt;Backtrace a lowest-cost path (Bottom Subplot)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a id="vis"&gt;&lt;iframe id="ytplayer" type="text/html" width="640" height="390" src="http://www.youtube.com/embed/2kUMe5PkyCg?autoplay=0&amp;origin=http://blog.iank.org" frameborder="0" allowfullscreen&gt;&lt;/iframe&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Code&lt;/h3&gt;
&lt;p&gt;MATLAB code for this demo may be found on github: &lt;a href="https://github.com/iank/route1"&gt;iank/route1&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;References&lt;/h3&gt;
&lt;div class="footnote"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn:zhou"&gt;
&lt;p&gt;H. Zhou. &lt;em&gt;Northwestern University EECS357, Introduction to VLSI CAD. Lecture 6 [PDF Document]&lt;/em&gt;. Retrieved from: &lt;a href="http://users.eecs.northwestern.edu/~haizhou/357/lec6.pdf"&gt;http://users.eecs.northwestern.edu/~haizhou/357/lec6.pdf&lt;/a&gt;&amp;#160;&lt;a class="footnote-backref" href="#fnref:zhou" rev="footnote" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</summary><category term="computer math"></category><category term="EDA"></category><category term="routing"></category></entry><entry><title>Breaking reddit.com's CAPTCHA</title><link href="http://blog.iank.org/breaking-redditcoms-captcha.html" rel="alternate"></link><updated>2013-07-26T18:56:00-04:00</updated><author><name>Ian Kilgore</name></author><id>tag:blog.iank.org,2013-07-26:breaking-redditcoms-captcha.html</id><summary type="html">&lt;h3&gt;Problem&lt;/h3&gt;
&lt;p&gt;&lt;a href="http://en.wikipedia.org/wiki/CAPTCHA"&gt;CAPTCHAs&lt;/a&gt; are "a type of challenge-response test used in computing to determine whether or not the user is human." They are designed to be relatively easy for humans to solve, and difficult to automate. Some of them are very good, but the CAPTCHA system employed by &lt;a href="http://reddit.com/"&gt;reddit.com&lt;/a&gt; is, as of 2013-07-26, not state-of-the-art. Below, I attempt to solve this CAPTCHA automatically.&lt;/p&gt;
&lt;p&gt;A common approach to solving this kind of problem is to divide the problem into two parts: segmentation and recognition. First we attempt to divide the CAPTCHA into its single-character parts. Second, we use a classifier to match segments with labels. It has been shown [&lt;sup id="fnref:chellapilla"&gt;&lt;a class="footnote-ref" href="#fn:chellapilla" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt;] that automatic classifiers perform well on single-letter images, and that segmentation is the more difficult problem.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Example CAPTCHA (1)" src="/images/rmbc/ex1.png" title="Example CAPTCHA (1)" /&gt;
&lt;img alt="Example CAPTCHA (2)" src="/images/rmbc/ex2.png" title="Example CAPTCHA (2)" /&gt;&lt;/p&gt;
&lt;h3&gt;Method&lt;/h3&gt;
&lt;h4&gt;Data&lt;/h4&gt;
&lt;p&gt;One thousand CAPTCHA images were collected. Each image is 8-bit 120x50 grayscale. All images have a six-character uppercase alphabetic solution, e.g. JVYKVC and TEMIWX, above. Half of the data was held out as a validation set, and hand-labelled with the correct solution by a human volunteer, Adrian C. Only 489 of these images were human-readable. We use the remaining five hundred images for segmentation.&lt;/p&gt;
&lt;h4&gt;Segmentation&lt;/h4&gt;
&lt;p&gt;&lt;a href="/images/rmbc/segment4.png"&gt;&lt;img alt="Segmented CAPTCHA" src="/images/rmbc/segment4_t.png" title="Segmented CAPTCHA" /&gt;&lt;/a&gt;
&lt;a href="/images/rmbc/segment5.png"&gt;&lt;img alt="Segmented CAPTCHA" src="/images/rmbc/segment5_t.png" title="Segmented CAPTCHA" /&gt;&lt;/a&gt;
&lt;a href="/images/rmbc/segment6.png"&gt;&lt;img alt="Segmented CAPTCHA" src="/images/rmbc/segment6_t.png" title="Segmented CAPTCHA" /&gt;&lt;/a&gt;
&lt;a href="/images/rmbc/segment7.png"&gt;&lt;img alt="Segmented CAPTCHA" src="/images/rmbc/segment7_t.png" title="Segmented CAPTCHA" /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Reddit's CAPTCHA algorithm employs a distorted grid which intercepts and joins each character in an attempt to prevent easy segmentation. However, these images are 8-bit rather than binary, and the anti-segmentation feature is rendered at a lower intensity than the letters themselves. This is the key weakness in this CAPTCHA algorithm.&lt;/p&gt;
&lt;p&gt;By thresholding these images at a pixel value of 150 (chosen empirically), we remove much of this anti-segmentation grid, leaving noise. This also degrades the letters themselves at the edges, however, which leads to difficulty later on in the recognition phase. &lt;a href="http://en.wikipedia.org/wiki/Connected-component_labeling"&gt;Connected components&lt;/a&gt; are then labelled, and components with fewer than twenty pixels (again chosen empirically) are discarded.&lt;/p&gt;
&lt;p&gt;This process is shown visually in the four images above. Note that not every segmentation attempt is successful. See above a case above in which three letters remained joined by a particularly large remnant of a grid line. In some cases not pictured, letters are over-segmented, e.g. a 'W' is split into two 'V's, or an 'N' is incorrectly segmented at one of its vertices. Also, some noise components, especially at the borders, are still quite large and remain in the image. We deal with these in the next step.&lt;/p&gt;
&lt;h4&gt;Recognition&lt;/h4&gt;
&lt;p&gt;At this point we have done a reasonable, though not optimal job of segmenting these images. From the original five hundred training images, we now have 3,244 individual components, which I labelled by hand.&lt;/p&gt;
&lt;p&gt;Some of these components are letters, but some are incorrectly-segmented multiple-letter sequences, half-letters, or pure noise. I trained a classifier, LSPC [&lt;sup id="fnref:sugiyama"&gt;&lt;a class="footnote-ref" href="#fn:sugiyama" rel="footnote"&gt;2&lt;/a&gt;&lt;/sup&gt;] to distinguish four classes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Correctly-segmented letters&lt;/li&gt;
&lt;li&gt;Two characters incorrectly combined into one&lt;/li&gt;
&lt;li&gt;Three characters incorrectly combined into one&lt;/li&gt;
&lt;li&gt;Noise (non-letters, partial letters)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This classifier performs well, with a 3.58% misclassification rate (compared to a 16.77% misclassification rate if we simply always guess 'letter', the most probable case). In theory this classifier would allow us to attempt to fix the two- and three-character cases. In this example, I discard all non-letter components and proceed to the second classifier.&lt;/p&gt;
&lt;p&gt;The second classifier attempts to categorize an input into one of twenty six classes (corresponding to the letters of the alphabet). After trying several versions of this classifier, I achieved the best misclassification error (10.14%), with a stacked autoencoder generating features for each image which were then fed to LSPC. In practice I actually used simple LSPC on raw pixel features (template matching), which achieved a misclassification error of 12.76%. I found that when analyzed in context of the entire system (segmentation+recognition), this classifier slightly outperforms the deep autoencoder.&lt;/p&gt;
&lt;p&gt;This classifier assigns probability values to its guesses, so in the event that an image appears to have more than six segments, we take the most likely six. In the event that our segmentation process only finds five or fewer unique components, we abstain from guessing a solution (in practice, most interfaces have some feature to allow a user to request a new CAPTCHA, as they are occasionally unreadable for humans).&lt;/p&gt;
&lt;h3&gt;Results&lt;/h3&gt;
&lt;p&gt;On the held-out validation set of 489 images, this system guessed only 5.73% (28) correctly. However, we knew a priori (because segmentation had failed), that we could not guess a number of images. If we abstain in those cases and request a new CAPTCHA, the success rate rises to an even 10%.&lt;/p&gt;
&lt;p&gt;In a scenario where we have a limited number of incorrect attempts, but may request new CAPTCHAs without guessing, it is possible to achieve a success rate of 29% by only guessing on the 3% of the images we are most confident about.&lt;/p&gt;
&lt;p&gt;Raw output of this test run is &lt;a href="/images/rmbc/log.txt"&gt;available&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;References&lt;/h3&gt;
&lt;div class="footnote"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn:chellapilla"&gt;
&lt;p&gt;K. Chellapilla, K. Larson, P. Simard, and M. Czerwinski, "Computers Beat Humans at Single Character Recognition in Reading Based Human Interaction Proofs (HIPs)," in &lt;em&gt;Proceedings of the Third Conference on E-Mail and AntiSpam&lt;/em&gt;, 2005.&amp;#160;&lt;a class="footnote-backref" href="#fnref:chellapilla" rev="footnote" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:sugiyama"&gt;
&lt;p&gt;M. Sugiyama. "Superfast-Trainable Multi-Class Probabilistic Classifier by Least-Squares Posterior Fitting". &lt;em&gt;IEICE Transactions on Information and Systems&lt;/em&gt;, E93-D(10), pp. 2690‚Äì2701, 2010.&amp;#160;&lt;a class="footnote-backref" href="#fnref:sugiyama" rev="footnote" title="Jump back to footnote 2 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</summary><category term="computer math"></category><category term="OpenCV"></category><category term="CAPTCHA"></category><category term="LSPC"></category></entry><entry><title>PCA on X-Plane Images</title><link href="http://blog.iank.org/pca-on-x-plane-images.html" rel="alternate"></link><updated>2013-07-21T20:09:00-04:00</updated><author><name>Ian Kilgore</name></author><id>tag:blog.iank.org,2013-07-21:pca-on-x-plane-images.html</id><summary type="html">&lt;h3&gt;Problem&lt;/h3&gt;
&lt;p&gt;As a demonstration of a multivariate analysis technique I have formulated a classification task:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Given screenshots of a cockpit in the flight simulator &lt;a href="http://www.x-plane.com/"&gt;X-Plane&lt;/a&gt;, discriminate between left and right banking.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;a href="/images/pca/screenshot_49.png"&gt;&lt;img alt="Example Screenshot Indicating Right Bank" src="/images/pca/screenshot_49_thumb.png" title="Example Screenshot Indicating Right Bank" /&gt;&lt;/a&gt;
&lt;a href="/images/pca/screenshot_119.png"&gt;&lt;img alt="Example Screenshot Indicating Left Bank" src="/images/pca/screenshot_119_thumb.png" title="Example Screenshot Indicating Left Bank" /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Method&lt;/h3&gt;
&lt;h4&gt;Data and Preprocessing&lt;/h4&gt;
&lt;p&gt;$$n=101 \text{ screenshots}$$ were taken at various points during simulated left and right turns, then hand-labelled as either 'left' or 'right'. These screenshots are 1180x800 8-bit RGB images, which can be represented using $$1180 \cdot 800 \cdot 3 = 2,832,000 \text{ values}$$&lt;/p&gt;
&lt;p&gt;If we are to use these images as feature vector inputs to a supervised learner, we find that 2.8 million-dimensional vectors are too large for practical applications.&lt;/p&gt;
&lt;p&gt;As an initial step, we may remove some redundancy in these images by converting them to 118x80 grayscale:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;09:44 &amp;lt; ik&amp;gt; ik's principled guide to multivariate analysis: if the data is too big, just throw away a lot of it&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This leaves us with screenshots resembling the following low-resolution grayscale images. These images can be represented as 9440-dimensional feature vectors, which are still rather large.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Example Screenshot Indicating Right Bank" src="/images/pca/right_49.png" title="Example Screenshot Indicating Right Bank" /&gt;
&lt;img alt="Example Screenshot Indicating Left Bank" src="/images/pca/left_119.png" title="Example Screenshot Indicating Left Bank" /&gt;&lt;/p&gt;
&lt;p&gt;It is clear that these images still exhibit much redundancy. The cockpit interior, for instance, is mostly either constant across all images (the cowling and blank space between instruments), or noise (most of the instruments vary between screenshots but are not useful for determining bank direction). The sky is mostly featureless and the ground is noise (we do not care if we are looking at a runway or a pasture). The only element of these images we are interested in is the horizon (and possibly the artificial horizon instrument and the turn coordinator).&lt;/p&gt;
&lt;p&gt;I made this problem easy by selecting only screenshots where the horizon was visible (ie, some sky and some ground was visible in each picture). So the slope of the horizon is a sufficient statistic for our task. (Had this not been the case, we would want to focus on the artificial horizon instrument).&lt;/p&gt;
&lt;p&gt;We can, of course, write some heuristic to extract the important information from these images, but there is a general method.&lt;/p&gt;
&lt;h4&gt;Principal Component Analysis&lt;/h4&gt;
&lt;p&gt;Much has been written about &lt;a href="https://en.wikipedia.org/wiki/Principal_component_analysis"&gt;PCA&lt;/a&gt;, so this section will only summarize the technique as I have implemented it in the solving of this problem. Here, we use PCA for dimensionality reduction: By selecting only the first s principal components, we can transform our d-dimensional data X to a s-dimensional subspace while retaining most of the variance of the data (thereby discarding some correlated variables (ie, redundancy) and noise). Of course, d &amp;gt;&amp;gt; s.&lt;/p&gt;
&lt;p&gt;Given n observations of d-dimensional data X (the values of X are, in this case, pixel intensities represented as integers ranging from 0 to 255):&lt;/p&gt;
&lt;p&gt;$$\mathbf{X}_{n \times d}$$&lt;/p&gt;
&lt;p&gt;We take the mean of each column and subtract from the data:&lt;/p&gt;
&lt;p&gt;\begin{equation}
\mathbf{\Psi} = \frac{1}{n}\sum\limits_{i=1}^n \vec{x}_i
\end{equation}
\begin{equation}
\mathbf{\Phi} = \mathbf{X} - \mathbf{\Psi}
\end{equation}&lt;/p&gt;
&lt;p&gt;A covariance matrix is computed:
\begin{equation}
\mathbf{C} = \mathbf{\Phi}^\top\mathbf{\Phi}
\end{equation}&lt;/p&gt;
&lt;p&gt;Note that this covariance matrix can be very large (d-by-d or, in our case, 9440 by 9440). In practise, &lt;a href="https://en.wikipedia.org/wiki/Principal_component_analysis#The_NIPALS_method"&gt;other methods&lt;/a&gt; are used to find the first few principal components without computing the entire covariance matrix.&lt;/p&gt;
&lt;p&gt;We find the eigenvalues and eigenvectors of the covariance matrix such that:&lt;/p&gt;
&lt;p&gt;\begin{equation}
\mathbf{V}^{-1}\mathbf{C}\mathbf{V} = \mathbf{\Lambda}
\end{equation}&lt;/p&gt;
&lt;p&gt;where V is a matrix of d column vectors corresponding to the d eigenvectors of C, and Œõ is a diagonal matrix with the d corresponding eigenvalues on its diagonal.&lt;/p&gt;
&lt;p&gt;We can think of the high-eigenvalued eigenvectors as modelling the signal subspace in our data, and the low-eigenvalued eigenvectors as modelling the noise subspace. Alternatively we can think of the high-eigenvalued eigenvectors as &lt;em&gt;axes&lt;/em&gt; along which our data has much variance. If we sort the eigenvalues and plot them, we have:&lt;/p&gt;
&lt;p&gt;&lt;img alt="Eigenvalues of Covariance Matrix" src="/images/pca/values.png" title="Eigenvalues of Covariance Matrix" /&gt;&lt;/p&gt;
&lt;p&gt;Note that I have zoomed in on the first fifty or so eigenvalues so as to show some detail. In reality there are 9440 of them. In most applications, the contrast between high values and low values is not nearly so sharp. So we have a good cutoff point, and we see that there are relatively few high eigenvalues, suggesting that the data is mostly correlated.&lt;/p&gt;
&lt;p&gt;While it may be advisable to select a few more, I let s = 2 to allow for visualization. So we take the two highest-eigenvalued eigenvectors and create a matrix which we can use to transform our data:&lt;/p&gt;
&lt;p&gt;\begin{equation}
\mathbf{U}_{d \times 2} = [\begin{array}{cc} \vec{\lambda}_1 &amp;amp; \vec{\lambda}_2 \end{array}]
\end{equation}&lt;/p&gt;
&lt;p&gt;\begin{equation}
\mathbf{U}_{d \times 2} = [\begin{array}{cc} \vec{\lambda}_1 &amp;amp; \vec{\lambda}_2 \end{array}]
\end{equation}&lt;/p&gt;
&lt;p&gt;We may now project our data into this two-dimensional space and plot it:&lt;/p&gt;
&lt;p&gt;\begin{equation}
\mathbf{X}_f = (\mathbf{X} - \mathbf{\Psi})\times\mathbf{U}^\top
\end{equation}&lt;/p&gt;
&lt;p&gt;&lt;img alt="X-Plane screenshots mapped onto two-dimensional space" src="/images/pca/2value.png" title="X-Plane screenshots mapped onto two-dimensional space" /&gt;&lt;/p&gt;
&lt;p&gt;I have plotted data points corresponding to each class ('left', 'right') with different colours. So we see that even with only two principal components we can achieve fairly good separation (even a linear classifier would do well here).&lt;/p&gt;
&lt;h3&gt;Results&lt;/h3&gt;
&lt;p&gt;Returning to our original problem. Given n observations of d-dimensional data X (screenshots) we should like to predict the class labels Y corresponding to 'right' and 'left' bank:&lt;/p&gt;
&lt;p&gt;$$\mathbf{X}_{n \times d}, \; \vec{Y}_n$$&lt;/p&gt;
&lt;p&gt;Using &lt;a href="http://sugiyama-www.cs.titech.ac.jp/~sugi/2010/LSPC.pdf"&gt;LSPC&lt;/a&gt;, a fast non-linear supervised classifier, we may attempt to separate this data. I used 75 screenshots to train, and withheld 26 for testing.&lt;/p&gt;
&lt;p&gt;By training LSPC on these 75 screenshots (projected into two dimensions), we find functions which estimate the posterior probability that a screenshot is a member of class Y = 1 or 2.&lt;/p&gt;
&lt;p&gt;$$\text{find } \hat{P}(Y=1|x_i); \hat{P}(Y=2|x_i)$$&lt;/p&gt;
&lt;p&gt;The estimated posterior probabilities are plotted as a heatmap over the two-dimensional data (this plot actually shows the training data, not the withheld test data). We make our decision at P(Y|x) = 0.5&lt;/p&gt;
&lt;p&gt;&lt;img alt="Estimated posterior probability (decision boundary = 0.5)" src="/images/pca/boundary.png" title="&amp;quot;Estimated posterior probability (decisioun boundary = 0.5" /&gt;&lt;/p&gt;
&lt;p&gt;Using this model we estimate the class label for our 26 withheld examples and find that it correctly classified 25 of the 26 screenshots (corresponding to an error rate of about 3.85%).&lt;/p&gt;</summary><category term="computer math"></category><category term="PCA"></category><category term="machine learning"></category><category term="LSPC"></category></entry></feed>