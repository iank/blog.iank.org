<!doctype html>
<html class="no-js" lang="en">
	<head>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1.0" />

		<title>A Localized Path-Finding Genetic Algorithm - Ian Kilgore's blog
</title>
		<meta name="description" content="">
		<meta name="author" content="Ian Kilgore">

		<link rel="stylesheet" href="http://blog.iank.org/theme/css/foundation.css" />
                <link rel="alternate" href="http://blog.iank.org/feeds/all.rss.xml" type="application/rss+xml" title="blog.iank.org RSS feed" />

		<link rel="stylesheet" href="http://blog.iank.org/theme/css/pygment/monokai.css" />
		<link rel="stylesheet" href="http://blog.iank.org/theme/css/custom.css" />


		<script src="http://blog.iank.org/theme/js/modernizr.js"></script>

		<!-- Feeds -->
		<link href="http://blog.iank.org/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="Ian Kilgore's blog Atom Feed" />


		<!-- mathjax config similar to math.stackexchange -->
		<script type="text/x-mathjax-config">
		MathJax.Hub.Config({
			jax: ["input/TeX", "output/HTML-CSS"],
			tex2jax: {
				inlineMath: [ ['$', '$'] ],
				displayMath: [ ['$$', '$$']],
				processEscapes: true,
				skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
			},
			messageStyle: "none",
			"HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"] }
		});
		</script>
		<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
	</head>
	<body>
		<div class="off-canvas-wrap">
			<div class="inner-wrap">
				<!-- mobile top bar to activate nav -->
				<nav class="tab-bar show-for-small">
					<section class="left-small">
						<a class="left-off-canvas-toggle menu-icon" ><span></span></a>
					</section>

					<section class="middle tab-bar-section">
						<h1 class="title">Ian&nbsp;Kilgore's&nbsp;blog</h1>
					</section>
				</nav>

				<!-- mobile side bar nav -->
				<aside class="left-off-canvas-menu">
					<ul class="off-canvas-list">
						<li><a href="http://blog.iank.org">Home</a></li>
						<li><label>Categories</label></li>
							<li ><a href="http://blog.iank.org/category/computer-vision.html">computer vision</a></li>
							<li class="active"><a href="http://blog.iank.org/category/machine-learning.html">machine learning</a></li>
							<li ><a href="http://blog.iank.org/category/math.html">math</a></li>
							<li ><a href="http://blog.iank.org/category/misc.html">misc</a></li>

						<li><label>Places</label></li>
							<li><a href="http://blog.iank.org/">Blog</a></li>
							<li><a href="http://blog.iank.org/pages/contact.html">Contact</a></li>
							<li><a href="http://iank.org/">Home</a></li>
							<li><a href="http://iank.org/projects.html">Projects</a></li>



<!--						<li><label>Links</label></li>
 -->
					</ul>	
				</aside>

				<!-- top bar nav -->
				<nav class="top-bar hide-for-small-only" data-topbar>
					<ul class="title-area">
						<li class="name">
							<h1><a href="http://blog.iank.org/">Ian Kilgore's blog</a></h1>
						</li>
					</ul>

					<section class="top-bar-section">
						<ul class="left">
								<li ><a href="http://blog.iank.org/category/computer-vision.html">computer vision</a></li>
								<li class="active"><a href="http://blog.iank.org/category/machine-learning.html">machine learning</a></li>
								<li ><a href="http://blog.iank.org/category/math.html">math</a></li>
								<li ><a href="http://blog.iank.org/category/misc.html">misc</a></li>
						</ul>
					</section>
				</nav>

				<!-- Main Page Content and Sidebar -->
				<section class="main-section">
					<div class="row">
						<!-- Main Content -->
						<div class="medium-9 small-12 columns" role="content">
<article>
	<h2>A Localized Path-Finding Genetic Algorithm</h2>
	<h3>Localized Path-Finding</h3>
<p>Below I implement a genetic algorithm which attempts the following problem:</p>
<blockquote>
<p>Find a model which can, as an autonomous agent, traverse the lowest-cost path across some weighted map using only local information.</p>
</blockquote>
<p>If this agent had prior knowledge of the entire map, determining the best path across it would be an objective (and well-studied) matter. In the following I attempt to train an agent to solve this problem with limited (local) information. These agents make decisions based only on four numbers: the relative heights of the terrain one "move" away in each of four directions (i.e., they can see no further than they can move).</p>
<p>On a uniformly-weighted space the lowest-cost path is simply the shortest, but here cost may be a proxy for difficult or rough terrain, or an abstraction. Below I will discuss the formulation and implications of the cost function used.</p>
<h3>Terrain and Sample Problem</h3>
<p><a href="/images/erasmus/problem_ex.png"><img alt="Example Depth Map With Source, Destination, and Two Possible Paths" src="/images/erasmus/problem_ex_t.png" title="Example Depth Map With Source, Destination, and Two Possible Paths" /></a></p>
<p>The figure above shows one possible problem space. The grey levels in the image can be understood as a height map, with lighter pixels representing higher altitudes. The red circle is a starting position, and an agent must attempt to cross the vertical green line on the right border of the image. Shown in yellow and blue are two possible paths from source to destination.</p>
<p>A successful agent should strike a balance between the shortest path and one that involves the least amount of steep climbs or descents. It should attempt to follow altitude contours when possible, but occasionally climb (or descend) a hill for a significant shortcut.</p>
<p>Readers uninterested in the details of implementation may wish to skip to <a href="#results">results</a> below.</p>
<h3>Cost Function</h3>
<p>It is intuitive that the yellow, longer path is a worse solution than the blue, straightforward one. This notion can be made objective by computing a cost which is equal to the length of the path. I also discretize the problem: an agent only moves in quantum steps of length $\epsilon$, where $\epsilon$ is measured in pixels. This cost function is then proportional (or equal) to $N$, the number of steps required to complete the path:</p>
<p>\begin{equation}
C = N
\end{equation}</p>
<p>The shortest path (a straight line) is now always the best path, so this cost function must be augmented to take changes in altitude into account. The cost calculation becomes:</p>
<p>\begin{equation}
C = \sum\limits_{n=1}^N g_n^2 + \lambda N
\end{equation}</p>
<p>where&lt;</p>
<p>\begin{equation}
g_n =
\begin{cases}
\Delta_n, &amp; \text{if }\Delta_n \geq 0\
-\frac{\Delta_n}{2}, &amp; \text{if }\Delta_n &lt; 0
\end{cases}
\end{equation}</p>
<p>for each step $g_n$ along the path. $\Delta_n$ is the change in height for that step. This cost is a function of both path length and the amount of climbing and descending one must do to complete the path. Note that cost scales with $g_n$ squared, meaning that very steep climbs and descents are penalized more strongly than shallow ones. Also, the cost for a descent is less than for a climb, but still positive (consider driving a vehicle down a steep, unpaved slope).</p>
<p>The parameter $\lambda$ controls the trade-off in cost between path length and altitude change: when $\lambda$ is very large, the path length component dominates and shorter paths will be selected at the cost of climbing. When $\lambda$ is very small, paths which minimize climbing will be favoured.</p>
<p>Finally, many agents never find a complete path. A (very large) fixed-cost penalty, $Q$, is added to their total costs.</p>
<h3>Agent Model</h3>
<h4>Model Input</h4>
<p>I model an agent as a function which, at each step, decides which direction to move based on information about the relative height of its immediate surroundings. The input at each step, $\mathbf{x}$, is a vector of length $d$ of (an approximation of) the directional derivatives around the agent's current position:</p>
<p>\begin{equation}
x_i = \frac{h([x,y] + \epsilon\angle\theta_i)-h([x,y])}{\epsilon} \text{ for } i=1,...,d
\end{equation}</p>
<p>Here $h(x,y)$ represents the height at position $(x,y)$. The angles $\theta_i$ are spaced evenly along the unit circle. So the vector $\mathbf{x}$ is the difference in height between an agent's current position and $d$ surrounding locations which are $\epsilon$ units away. For a differentiable surface, the gradient of $h(x,y)$ is sufficient to describe it, but for this approximate model I have chosen $d=4$.</p>
<h4>Model Parameters and Output</h4>
<p>At each step the agent must decide a new direction in which to move. This should be an angle, $\phi$, between $\pi$ and $-\pi$. The model becomes a function $A$ of $\mathbf{x}$, parameterized by some unknown vector $\alpha$:</p>
<p>\begin{equation}
\hat{\phi} = A_\mathbf{\alpha}(\mathbf{x})
\end{equation}</p>
<p>The core of this model, $\mathbf{\alpha}^\top\mathbf{x}$, is a simple linear combination of the parameters, $\mathbf{\alpha}$, and the input vector $\mathbf{x}$. The output is then "squished" with a sigmoid function and normalized between $-\pi$ and $\pi$:</p>
<p>\begin{equation}
A_\mathbf{\alpha}(\mathbf{x}) = 2\pi\left(\frac{1}{1+exp(\mathbf{\alpha}^\top\mathbf{x})}-0.5\right)
\end{equation}</p>
<p>I show below that a model with only $d=4$ parameters is sufficient for reasonable performance as a path-finding agent. A genetic algorithm, below, is used to find near-optimal values for these four parameters.</p>
<h3>Genetic Algorithm</h3>
<p>A <a href="http://en.wikipedia.org/wiki/Genetic_algorithm">genetic algorithm</a> attempts to solve an optimization problem by mimicking evolution. Genetic algorithms are well-studied, so I will describe only my implementation for this problem. I represent each individual as a list of floating-point "genes" (in this case, each individual has four genes corresponding to the model parameters $\mathbf{\alpha}$.</p>
<ul>
<li>An initial population of $P=200$ individual agents is randomly generated. I initialize weights using a long-tailed t distribution. This encourages diversity in the gene pool by creating a few more relatively large weights (as opposed to a normal distribution) [<sup id="fnref:montana"><a class="footnote-ref" href="#fn:montana" rel="footnote">3</a></sup>].</li>
<li>Each agent is run and its total cost computed</li>
<li>The best individual from the previous generation is carried over unchanged. This is referred to as elitism, and prevents the algorithm from throwing away the most fit individual through crossover or mutation [<sup id="fnref:rudolph"><a class="footnote-ref" href="#fn:rudolph" rel="footnote">1</a></sup>]. It has also been shown to decrease convergence time [<sup id="fnref:zitzler"><a class="footnote-ref" href="#fn:zitzler" rel="footnote">2</a></sup>].</li>
<li>A new population is bred:<ul>
<li>Two parents are selected with probability proportional to the reciprocal of their associated cost</li>
<li>The two parents are combined using two-point crossover, creating a child individual</li>
<li>These children are mutated by adding a small random offset to each gene with a 4% probability.</li>
<li>This is repeated until 90% of the new generation has been created</li>
<li>The remaining 10% of the new generation are initialized randomly</li>
</ul>
</li>
</ul>
<h3>Results</h3>
<p><a name="results"></a></p>
<h4>GA vs Control</h4>
<p>In order to demonstrate that the genetic algorithm is productively solving this problem, I compare it to a control. The control algorithm keeps the best individual from the previous generation, as in the GA. Every other individual, however, is randomly generated. The following figures show that a genetic algorithm (first) outperforms a random search (second) of the parameter space. The cost function here has been tuned to discourage climbing in favour of longer, contour-following paths.</p>
<p><a href="/images/erasmus/gavs.png"><img alt="Path taken by best agent found by genetic algorithm" src="/images/erasmus/gavs_t.png" title="Path taken by best agent found by genetic algorithm" /></a>
<a href="/images/erasmus/rndvs.png"><img alt="Path taken by best agent found by random selection" src="/images/erasmus/rndvs_t.png" title="Path taken by best agent found by random selection" /></a></p>
<h4>Evolution of Best Path</h4>
<p>In the figures below, the best path for several different generations is evolved. The algorithm finds a global solution fairly quickly, and then optimizes certain local difficulties. The first image, below, shows the initial (random) best path, which does not reach the objective. After a few generations, a reasonable solution has been found but three problem areas (outlined in blue) remain. The next row of images focus on only the lower-right problem area. We see that the path, while initially confused, begins to straighten out after several generations.</p>
<p><a href="images/erasmus/evolution.txt">Text output from this experiment</a> is available. It is possible here to see how the percentage of the population which sucessfully completes any route grows as successful individuals are selected to reproduce.</p>
<p><a href="/images/erasmus/gen01_t.png"><img alt="Initial (random) solution" src="/images/erasmus/gen01_t.png" title="Initial (random) solution" /></a>
<a href="/images/erasmus/gen11_t.png"><img alt="Global (coarse) solution found after 11 generations. Local problem areas outlined in blue." src="/images/erasmus/gen11_t.png" title="Global (coarse) solution found after 11 generations. Local problem areas outlined in blue." /></a></p>
<p><a href="/images/erasmus/gen11_p1_t.png"><img alt="Local problem area w/in global/coarse solution" src="/images/erasmus/gen11_p1_t.png" title="Local problem area w/in global/coarse solution" /></a>
<a href="/images/erasmus/gen15_p2_t.png"><img alt="Iteration upon problem area" src="/images/erasmus/gen15_p2_t.png" title="Iteration upon problem area" /></a>
<a href="/images/erasmus/gen22_p3_t.png"><img alt="Iteration upon problem area" src="/images/erasmus/gen22_p3_t.png" title="Iteration upon problem area" /></a>
<a href="/images/erasmus/gen36_p4_t.png"><img alt="Iteration upon problem area" src="/images/erasmus/gen36_p4_t.png" title="Iteration upon problem area" /></a></p>
<h4>Step Cost and Differentiability</h4>
<p>Although the best path in the previous section eventually became somewhat smooth, its jagged nature can be improved upon. The jaggedness of that path can be attributed to two factors:</p>
<ul>
<li>The images in the previous section were generated using a low step cost $\lambda$. This low step cost does not serve well to discourage too-long paths.</li>
<li>The image used as a map is discontinuous (i.e. not differentiable) at the transitions between white and black. In this case the agent has no information about the upcoming cliff until it hits it. It cannot choose an intermediate angle and must proceed in a zig/zag fashion.</li>
</ul>
<p>By smoothing the image (by a 20x20 boxcar filter) and increasing the step cost, we can find a much better route through the image. From left to right:</p>
<ul>
<li>In the first figure below, the problem is demonstrated. The image is discontinuous, and $\lambda=0.001$.</li>
<li>In the second figure, the image has been smoothed, but the step cost remains $\lambda=0.001$.</li>
<li>Next, the step cost is increased to $\lambda=50$</li>
<li>Next, the step cost is increased to $\lambda=1000$, and we see a relatively smooth path.</li>
<li>Finally, we are shown a global view of the previous image (with $\lambda=1000$), showing the smoother path. Also note that some shortcuts have been taken.</li>
</ul>
<p><a href="/images/erasmus/soln4_t.png"><img alt="Zig-zag path due to low step cost and discontinuous image" src="/images/erasmus/soln4_t.png" title="Zig-zag path due to low step cost and discontinuous image" /></a>
<a href="/images/erasmus/soln1_t.png"><img alt="Problem is ameliorated by smoothing the image" src="/images/erasmus/soln1_t.png" title="Problem is ameliorated by smoothing the image" /></a>
<a href="/images/erasmus/soln2_t.png"><img alt="Step cost is increased to lambda=50 resulting in a shorter path" src="/images/erasmus/soln2_t.png" title="Step cost is increased to lambda=50 resulting in a shorter path" /></a>
<a href="/images/erasmus/soln3_t.png"><img alt="Further increase in step cost (lambda=1000) results in a shorter, smoother path" src="/images/erasmus/soln3_t.png" title="Further increase in step cost (lambda=1000) results in a shorter, smoother path" /></a>
<a href="/images/erasmus/soln3_global_t.png"><img alt="Global view of previous image" src="/images/erasmus/soln3_global_t.png" title="Global view of previous image" /></a></p>
<h4>Generalization</h4>
<p>A simple experiment shows that these agents have some limited capacity for generalization. An agent was trained on a perlin noise depth map using an initial position near the centre of the image. It proceeded to its goal while attempting to maintain the same altitude throughout. The same agent was then run starting at the far left of the image (at a different altitude) and then found a reasonable path to its goal, again maintaining a relatively uniform altitude throughout.</p>
<p><a href="/images/erasmus/bestroute_trained_t.png"><img alt="Best route found during training" src="/images/erasmus/bestroute_trained_t.png" title="Best route found during training" /></a>
<a href="/images/erasmus/bestroute_generalized_t.png"><img alt="Same agent released at a different starting position" src="/images/erasmus/bestroute_generalized_t.png" title="Same agent released at a different starting position" /></a></p>
<p>This capacity for generalization has limits. In the following example, there is a conduit through the image with a fork. One fork is a route through, and the other is not. Because these agents work using only local knowledge, it is impossible to determine a priori which path is best (It is impossible for even a truly intelligent agent to choose the correct path given only the information at hand).</p>
<p><a href="/images/erasmus/gen01_t.png"><img alt="Trained agent on forked path finds a way through" src="/images/erasmus/gen01_t.png" title="Trained agent on forked path finds a way through" /></a>
<a href="/images/erasmus/gen01_t.png"><img alt="Same agent with the forks reversed fails to find the best route" src="/images/erasmus/gen01_t.png" title="Same agent with the forks reversed fails to find the best route" /></a></p>
<h3>Code</h3>
<p>MATLAB code for this demo may be found on github: <a href="https://github.com/iank/erasmus">iank/erasmus</a></p>
<h3>References</h3>
<div class="footnote">
<hr />
<ol>
<li id="fn:rudolph">
<p>G. Rudolph. Evolutionary search for minimal elements in partially ordered ﬁnite sets. In V. W. Porto, N. Saravanan, D. Waagen, and A. E. Eiben, editors, <em>Evolutionary Programming VII, Proceedings of the 7th Annual Conference on Evolutionary Programming</em>, pages 345–353. Springer, Berlin, 1998.&#160;<a class="footnote-backref" href="#fnref:rudolph" rev="footnote" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
<li id="fn:zitzler">
<p>E. Zitzler, K. Deb, and L. Thiele. Comparison of Multiobjective Evolutionary Algorithms: Empirical Results. <em>Evolutionary Computation</em> 8.2 (2000): 173-195.&#160;<a class="footnote-backref" href="#fnref:zitzler" rev="footnote" title="Jump back to footnote 2 in the text">&#8617;</a></p>
</li>
<li id="fn:montana">
<p>D. Montana and L. Davis. Training Feedforward Neural Networks Using Genetic Algorithms. <em>IJCAI</em>, vol. 89 (1989): 762-767&#160;<a class="footnote-backref" href="#fnref:montana" rev="footnote" title="Jump back to footnote 3 in the text">&#8617;</a></p>
</li>
</ol>
</div>
	<hr/>
	<h6>Written by <a href="http://blog.iank.org/author/ian-kilgore.html">Ian Kilgore</a> in <a href="http://blog.iank.org/category/machine-learning.html">machine learning</a> on Sat 17 August 2013. Tags: <a href="http://blog.iank.org/tag/computer-math.html">computer math</a>, <a href="http://blog.iank.org/tag/genetic-algorithm.html">genetic algorithm</a>, <a href="http://blog.iank.org/tag/models.html">models</a>, <a href="http://blog.iank.org/tag/machine-learning.html">machine learning</a>, </h6>
</article>

<hr/>
						</div>
						<!-- End Main Content -->
						<!-- Sidebar -->
						<aside class="medium-3 hide-for-small-only columns">
							<div class="panel">
								<h5>Places</h5>
								<ul class="side-nav">
									<li><a href="http://blog.iank.org/">Blog</a></li>
									<li><a href="http://blog.iank.org/pages/contact.html">Contact</a></li>
									<li><a href="http://iank.org/">Home</a></li>
									<li><a href="http://iank.org/projects.html">Projects</a></li>
								</ul>
							</div>

							<div class="panel">
								<h5>Tags</h5>
								<ul class="tag-cloud">
										<li class="tag-4"><a href="http://blog.iank.org/tag/routing.html">routing</a></li>
										<li class="tag-4"><a href="http://blog.iank.org/tag/america.html">america</a></li>
										<li class="tag-4"><a href="http://blog.iank.org/tag/capitals.html">capitals</a></li>
										<li class="tag-4"><a href="http://blog.iank.org/tag/jokes.html">jokes</a></li>
										<li class="tag-4"><a href="http://blog.iank.org/tag/chaos.html">chaos</a></li>
										<li class="tag-2"><a href="http://blog.iank.org/tag/machine-learning.html">machine learning</a></li>
										<li class="tag-4"><a href="http://blog.iank.org/tag/hexagons.html">hexagons</a></li>
										<li class="tag-4"><a href="http://blog.iank.org/tag/nodemcu.html">NodeMCU</a></li>
										<li class="tag-2"><a href="http://blog.iank.org/tag/lspc.html">LSPC</a></li>
										<li class="tag-4"><a href="http://blog.iank.org/tag/topology.html">topology</a></li>
										<li class="tag-4"><a href="http://blog.iank.org/tag/chemistry.html">chemistry</a></li>
										<li class="tag-4"><a href="http://blog.iank.org/tag/genetic-algorithm.html">genetic algorithm</a></li>
										<li class="tag-2"><a href="http://blog.iank.org/tag/physics.html">physics</a></li>
										<li class="tag-2"><a href="http://blog.iank.org/tag/geometry.html">geometry</a></li>
										<li class="tag-4"><a href="http://blog.iank.org/tag/opencv.html">OpenCV</a></li>
										<li class="tag-4"><a href="http://blog.iank.org/tag/feature-selection.html">feature selection</a></li>
										<li class="tag-4"><a href="http://blog.iank.org/tag/captcha.html">CAPTCHA</a></li>
										<li class="tag-4"><a href="http://blog.iank.org/tag/talks.html">talks</a></li>
										<li class="tag-4"><a href="http://blog.iank.org/tag/ocr.html">OCR</a></li>
										<li class="tag-4"><a href="http://blog.iank.org/tag/freedom.html">freedom</a></li>
										<li class="tag-4"><a href="http://blog.iank.org/tag/research.html">research</a></li>
										<li class="tag-4"><a href="http://blog.iank.org/tag/lua.html">lua</a></li>
										<li class="tag-2"><a href="http://blog.iank.org/tag/math.html">math</a></li>
										<li class="tag-4"><a href="http://blog.iank.org/tag/hardware.html">hardware</a></li>
										<li class="tag-4"><a href="http://blog.iank.org/tag/models.html">models</a></li>
										<li class="tag-4"><a href="http://blog.iank.org/tag/robots.html">robots</a></li>
										<li class="tag-4"><a href="http://blog.iank.org/tag/latex.html">LaTeX</a></li>
										<li class="tag-4"><a href="http://blog.iank.org/tag/python.html">python</a></li>
										<li class="tag-4"><a href="http://blog.iank.org/tag/pca.html">PCA</a></li>
										<li class="tag-4"><a href="http://blog.iank.org/tag/matlab.html">MATLAB</a></li>
										<li class="tag-4"><a href="http://blog.iank.org/tag/nerds.html">nerds</a></li>
										<li class="tag-4"><a href="http://blog.iank.org/tag/kant.html">kant</a></li>
										<li class="tag-4"><a href="http://blog.iank.org/tag/eda.html">EDA</a></li>
										<li class="tag-0"><a href="http://blog.iank.org/tag/computer-math.html">computer math</a></li>
										<li class="tag-4"><a href="http://blog.iank.org/tag/thermite.html">thermite</a></li>
										<li class="tag-4"><a href="http://blog.iank.org/tag/experimental-data.html">experimental data</a></li>
										<li class="tag-4"><a href="http://blog.iank.org/tag/esp8266.html">ESP8266</a></li>
										<li class="tag-4"><a href="http://blog.iank.org/tag/feelings.html">feelings</a></li>
								</ul>
							</div>


<!--							<div class="panel">
								<h5>Links</h5>
								<ul class="side-nav">
								</ul> 
							</div> -->
						</aside>
						<!-- End Sidebar -->
					</div>

					<!-- Footer -->
					<footer class="row">
						<div class="medium-9 small-12">
							<hr/>
							<p class="text-center">Powered by <a href="http://getpelican.com">Pelican</a> and <a href="http://foundation.zurb.com/">Zurb Foundation</a>. Theme by <a href="http://hamaluik.com">Kenton Hamaluik</a>.</p>
						</div>
					</footer>
					<!-- End Footer -->
				</section>
				<a class="exit-off-canvas"></a>
			</div><!--off-canvas inner-->
		</div><!--off-canvas wrap-->

		<script src="http://blog.iank.org/theme/js/jquery.js"></script>
		<script src="http://blog.iank.org/theme/js/foundation.min.js"></script>
		<script>
			$(document).foundation();
		</script>
	</body>
</html>